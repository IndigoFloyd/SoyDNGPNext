{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efd3f3d",
   "metadata": {},
   "source": [
    "# draw_pic.ipynb Documentation\n",
    "This ipynb file is written for showing training result as SVG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c4ea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n",
      "1.24.3\n",
      "3.7.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70c970",
   "metadata": {},
   "source": [
    "## Variable\n",
    "\n",
    "```qualitative_trait_list``` : A list of all qualitative traits that the model has been trained on.\n",
    "\n",
    "```quantitative_trait_list``` : A list of all quantitative traits that the model has been trained on.\n",
    "\n",
    "```quantitative_dir_path``` : The parent folder path of the quantitative trait output file.\n",
    "\n",
    "```qualitative_dir_path``` : The parent folder path of the qualitative trait output file.\n",
    "\n",
    "```qualitative_trait_file``` : The qualitative trait contains the output file path of 5000 samples.\n",
    "\n",
    "```quantitative_trait_file``` : The quantitative trait contains the output file path of 5000 samples.\n",
    "\n",
    "```save_path``` : SVG image saving path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b125ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualitative_trait_list = ['ST','FC','P_DENS','POD'] \n",
    "quantitative_trait_list = ['protein','oil','SdWgt','Yield','R1','R8','Hgt']\n",
    "quantitative_dir_path = r\"out\\quantitative_trait\"\n",
    "qualitative_dir_path = r\"out\\qualitative_trait\"\n",
    "qualitative_trait_file=os.path.join(qualitative_dir_path,'5000_out.txt')\n",
    "quantitative_trait_file=os.path.join(quantitative_dir_path,'5000_out.txt')\n",
    "save_path = r\"result\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84e010",
   "metadata": {},
   "source": [
    "## Function\n",
    "\n",
    "### qualitative_trait(qualitative_trait_file, save_path, qualitative_trait_list)\n",
    "\n",
    "Show the Evaluation metrics of qualitative trait.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "qualitative_dir_path = ''\n",
    "qualitative_trait_file=os.path.join(qualitative_dir_path,'5000_out.txt')\n",
    "save_path=''\n",
    "qualitative_trait_list=''\n",
    "qualitative_trait(qualitative_trait_file,save_path,qualitative_trait_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd199ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pictures will be saved to result/trait_name_eval(or loss).svg.\n",
      "Now drawing ST.\n",
      "Now drawing FC.\n",
      "Now drawing P_DENS.\n",
      "Now drawing POD.\n"
     ]
    }
   ],
   "source": [
    "def qualitative_trait(qualitative_trait_file,save_path,qualitative_trait_list):\n",
    "    csv = open(qualitative_trait_file,'r')\n",
    "    lines = csv.readlines()\n",
    "    lines = lines[16:-2]\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "    train_loss =[ ]\n",
    "    test_loss =[ ]\n",
    "    acc = [ ]\n",
    "    recall = [ ]\n",
    "    f1_score = [ ]\n",
    "    pre_score = [ ]\n",
    "    len(lines)\n",
    "    epoch_list = [ i+1 for i in range(150) ]\n",
    "    print(f\"All pictures will be saved to {save_path}/trait_name_eval(or loss).svg.\")\n",
    "    for trait in qualitative_trait_list:\n",
    "        print(f\"Now drawing {trait}.\")\n",
    "        for epoch in range(len(lines)):\n",
    "            if f'{trait}' in lines[epoch] and ' | ' in lines[epoch] :\n",
    "                train_loss.append(float(lines[epoch].split(' | ')[1].split(',')[0].split(':')[1]))\n",
    "                test_loss.append(float(lines[epoch].split(' | ')[1].split(',')[1].split(':')[1]))\n",
    "                acc.append(float(lines[epoch].split(' | ')[1].split(',')[2].split(':')[1]))\n",
    "                recall.append(float(lines[epoch].split(' | ')[1].split(',')[3].split(':')[1]))\n",
    "                f1_score.append(float(lines[epoch].split(' | ')[1].split(',')[4].split(':')[1]))\n",
    "                pre_score.append(float(lines[epoch].split(' | ')[1].split(',')[5].split(':')[1]))\n",
    "        max_train,max_test,min_train,min_test = max(train_loss),max(test_loss),min(train_loss),min(test_loss)\n",
    "        plt.plot(epoch_list,train_loss,marker =None ,linewidth=1.0,label='train loss')\n",
    "        plt.plot(epoch_list,test_loss,marker=None,linewidth=1.0,label='test loss')\n",
    "        min_y = min(min_test,min_train)*0.8\n",
    "        max_y = max(max_train,max_test)*1.2\n",
    "        plt.ylim((0,max_y))\n",
    "        y_ticks = np.round((np.arange(min_y,max_y,abs(min_y - max_y)/ 6)),2)\n",
    "        plt.yticks(y_ticks)\n",
    "        plt.margins(y=0)\n",
    "        plt.legend(loc = 'best')\n",
    "        plt.title(f'CrossEntropy Loss of {trait}')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_loss.svg'),dpi = 400,format = 'svg')\n",
    "        plt.close()\n",
    "        max_acc,max_recall,max_f1,max_pre = max(acc),max(recall),max(f1_score),max(pre_score)\n",
    "        min_acc,min_recall,min_f1,min_pre = min(acc),min(recall),min(f1_score),min(pre_score)\n",
    "        range_min = min(min_acc,min_f1,min_recall,min_pre)*0.7\n",
    "        range_max = max(max_acc,max_f1,max_recall,max_pre)*1.2\n",
    "        plt.plot(epoch_list,acc,marker =None ,linewidth=1.0,label='accuracy')\n",
    "        plt.plot(epoch_list,recall,marker =None ,linewidth=1.0,label='recall')\n",
    "        plt.plot(epoch_list,f1_score,marker =None ,linewidth=1.0,label='f1 score')\n",
    "        plt.plot(epoch_list,pre_score,marker =None ,linewidth=1.0,label='precision')\n",
    "        plt.ylim((0,range_max))\n",
    "        y_ticks = np.round((np.arange(range_min,range_max,abs(range_min - range_max)/ 6)),2)\n",
    "        plt.yticks(y_ticks)\n",
    "        plt.margins(y=0)\n",
    "        plt.legend(loc='best')\n",
    "        plt.title(f'eval of {trait}')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_eval.svg'),dpi = 400)\n",
    "        plt.close()\n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "        acc =[]\n",
    "        recall=[]\n",
    "        f1_score = []\n",
    "        pre_score = [ ]\n",
    "        \n",
    "qualitative_trait(qualitative_trait_file,save_path,qualitative_trait_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b464e3",
   "metadata": {},
   "source": [
    "### quantitative_trait(quantitative_trait_file,save_path,quantitative_trait_list):\n",
    "\n",
    "Show the Evaluation metrics of quantitative trait.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "quantitative_dir_path = ''\n",
    "quantitative_trait_file=os.path.join(quantitative_dir_path,'5000_out.txt')\n",
    "save_path=''\n",
    "quantitative_trait_list=''\n",
    "quantitative_trait(quantitative_trait_file,save_path,quantitative_trait_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b27f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pictures will be saved to result/trait_name_eval(or loss).svg.\n",
      "Now drawing protein.\n",
      "Now drawing oil.\n",
      "Now drawing SdWgt.\n",
      "Now drawing Yield.\n",
      "Now drawing R1.\n",
      "Now drawing R8.\n",
      "Now drawing Hgt.\n"
     ]
    }
   ],
   "source": [
    "def quantitative_trait(quantitative_trait_file,save_path,quantitative_trait_list):\n",
    "    csv = open(quantitative_trait_file,'r')\n",
    "    lines = csv.readlines()\n",
    "    lines = lines[16:-2]\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "    train_loss =[ ]\n",
    "    test_loss =[ ]\n",
    "    r = [ ]\n",
    "    epoch_list = [ i+1 for i in range(150) ]\n",
    "    print(f\"All pictures will be saved to {save_path}/trait_name_eval(or loss).svg.\")\n",
    "    for trait in quantitative_trait_list:\n",
    "        print(f\"Now drawing {trait}.\")\n",
    "        for epoch in range(len(lines)):\n",
    "            if f'{trait}' in lines[epoch] and ' | ' in lines[epoch] :\n",
    "                train_loss.append(float(lines[epoch].split(' | ')[1].split(',')[0].split(':')[1]))\n",
    "                test_loss.append(float(lines[epoch].split(' | ')[1].split(',')[1].split(':')[1]))\n",
    "                r.append(float(lines[epoch].split(' | ')[1].split(',')[2].split(':')[1]))\n",
    "        plt.plot(epoch_list,train_loss,marker =None ,linewidth =1.0 ,label='train loss')\n",
    "        plt.plot(epoch_list,test_loss,marker=None,linewidth =1.0 ,label='test loss')\n",
    "        max_train,max_test,min_train,min_test = max(train_loss),max(test_loss),min(train_loss),min(test_loss)\n",
    "        plt.legend(loc = 'best')\n",
    "        min_y = min(min_test,min_train)*0.8\n",
    "        max_y = max(max_train,max_test)*1.2\n",
    "        plt.ylim((0,max_y))\n",
    "        y_ticks = np.round((np.arange(min_y,max_y,abs(min_y - max_y)/ 6)),2)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title(f'Mean Square  Loss of {trait}')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_loss.svg'),dpi = 600)\n",
    "        plt.close()\n",
    "        plt.plot(epoch_list,r,marker =None ,linewidth =1.0,label='r')\n",
    "        plt.title(f' Pearson correlation coefficient of {trait}')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_eval.svg'),dpi = 600)\n",
    "        plt.close()\n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "        r =[]\n",
    "        \n",
    "quantitative_trait(quantitative_trait_file,save_path,quantitative_trait_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7eb089",
   "metadata": {},
   "source": [
    "### qualitative_trait_compare(qualitative_dir_path,save_path,qualitative_trait_list)\n",
    "\n",
    "Compare the performance of qualitative trait models across different sample size gradients.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "qualitative_dir_path=''\n",
    "save_path=''\n",
    "qualitative_trait_list=''\n",
    "qualitative_trait_compare(qualitative_dir_path,save_path,qualitative_trait_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45030e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pictures will be saved to result/trait_name_evaluation.svg\n",
      "Now drawing ST.\n",
      "Now drawing FC.\n",
      "Now drawing P_DENS.\n",
      "Now drawing POD.\n"
     ]
    }
   ],
   "source": [
    "def qualitative_trait_compare(qualitative_dir_path,save_path,qualitative_trait_list):\n",
    "    files = os.listdir(qualitative_dir_path)\n",
    "    path_list = [os.path.join(qualitative_dir_path,file) for file in files]\n",
    "    epoch_list = [ i+1 for i in range(150) ]\n",
    "    print(f\"All pictures will be saved to {save_path}/trait_name_evaluation.svg\")\n",
    "    for trait in qualitative_trait_list:\n",
    "        print(f\"Now drawing {trait}.\")\n",
    "        acc_list = [ ]\n",
    "        recall_list = [ ]\n",
    "        f1_score_list = [ ]\n",
    "        test_loss_list = [ ]\n",
    "        pre_list = [ ]\n",
    "        for csv_path in path_list:\n",
    "            train_loss =[ ]\n",
    "            test_loss =[ ]\n",
    "            acc = [ ]\n",
    "            recall = [ ]\n",
    "            f1_score = [ ]\n",
    "            pre_score =[ ]\n",
    "            csv = open(csv_path,'r')\n",
    "            lines = csv.readlines()\n",
    "            lines = lines[16:-2]\n",
    "            lines = [line.rstrip() for line in lines]\n",
    "            for epoch in range(len(lines)):\n",
    "                if f'{trait}' in lines[epoch] and ' | ' in lines[epoch] :\n",
    "                    train_loss.append(float(lines[epoch].split(' | ')[1].split(',')[0].split(':')[1]))\n",
    "                    test_loss.append(float(lines[epoch].split(' | ')[1].split(',')[1].split(':')[1]))\n",
    "                    acc.append(float(lines[epoch].split(' | ')[1].split(',')[2].split(':')[1]))\n",
    "                    recall.append(float(lines[epoch].split(' | ')[1].split(',')[3].split(':')[1]))\n",
    "                    f1_score.append(float(lines[epoch].split(' | ')[1].split(',')[4].split(':')[1]))\n",
    "                    pre_score.append(float(lines[epoch].split(' | ')[1].split(',')[5].split(':')[1]))\n",
    "            test_loss_list.append(test_loss) \n",
    "            acc_list.append(acc)\n",
    "            recall_list.append(recall)\n",
    "            f1_score_list.append(f1_score)\n",
    "            pre_list.append(pre_score)\n",
    "        max_loss,min_loss = np.max(np.array(test_loss_list)),np.min(np.array(test_loss_list))\n",
    "        plt.plot(epoch_list,test_loss_list[0],marker =None ,linewidth=1.0,label='2000 samples')\n",
    "        plt.plot(epoch_list,test_loss_list[1],marker =None ,linewidth=1.0,label='5000 samples')\n",
    "        plt.plot(epoch_list,test_loss_list[2],marker =None ,linewidth=1.0,label='8000 samples')\n",
    "        plt.plot(epoch_list,test_loss_list[3],marker =None ,linewidth=1.0,label='10000 samples')\n",
    "        plt.ylim((0,max_loss*1.2))\n",
    "        y_ticks = np.round((np.arange(min_loss,max_loss,abs(min_loss - max_loss)/ 6)),2)\n",
    "        plt.legend(loc='best')\n",
    "        plt.title(f'CrossEntropyLoss of {trait}')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_CrossEntropyLoss.svg'),dpi = 600)\n",
    "        plt.close()\n",
    "\n",
    "        max_recall,min_recall = np.max(np.array(recall_list)),np.min(np.array(recall_list))\n",
    "        plt.plot(epoch_list,recall_list[0],marker =None ,linewidth=1.0,label='2000 samples')\n",
    "        plt.plot(epoch_list,recall_list[1],marker =None ,linewidth=1.0,label='5000 samples')\n",
    "        plt.plot(epoch_list,recall_list[2],marker =None ,linewidth=1.0,label='8000 samples')\n",
    "        plt.plot(epoch_list,recall_list[3],marker =None ,linewidth=1.0,label='10000 samples')\n",
    "        plt.legend(loc='best')\n",
    "        plt.ylim((0,max_recall*1.2))\n",
    "        y_ticks = np.round((np.arange(min_recall,max_recall,abs(min_recall - max_recall)/ 6)),2)\n",
    "        plt.title(f'Recall of {trait}')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_recall.svg'),dpi = 600)\n",
    "        plt.close()\n",
    "\n",
    "        max_acc,min_acc = np.max(np.array(acc_list)),np.min(np.array(acc_list))\n",
    "        plt.plot(epoch_list,acc_list[0],marker =None ,linewidth=1.0,label='2000 samples')\n",
    "        plt.plot(epoch_list,acc_list[1],marker =None ,linewidth=1.0,label='5000 samples')\n",
    "        plt.plot(epoch_list,acc_list[2],marker =None ,linewidth=1.0,label='8000 samples')\n",
    "        plt.plot(epoch_list,acc_list[3],marker =None ,linewidth=1.0,label='10000 samples')\n",
    "        plt.legend(loc='best')\n",
    "        plt.ylim((0,max_acc*1.2))\n",
    "        y_ticks = np.round((np.arange(min_acc,max_acc,abs(min_acc - max_acc)/ 6)),2)\n",
    "        plt.title(f'Accuracy of {trait}')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_acc.svg'),dpi = 600)\n",
    "        plt.close()\n",
    "\n",
    "        max_f1,min_f1 = np.max(np.array(f1_score_list)),np.min(np.array(f1_score_list))\n",
    "        plt.plot(epoch_list,f1_score_list[0],marker =None ,linewidth=1.0,label='2000 samples')\n",
    "        plt.plot(epoch_list,f1_score_list[1],marker =None ,linewidth=1.0,label='5000 samples')\n",
    "        plt.plot(epoch_list,f1_score_list[2],marker =None ,linewidth=1.0,label='8000 samples')\n",
    "        plt.plot(epoch_list,f1_score_list[3],marker =None ,linewidth=1.0,label='10000 samples')\n",
    "        plt.legend(loc='best')\n",
    "        plt.ylim((0,max_f1*1.2))\n",
    "        y_ticks = np.round((np.arange(min_f1,max_f1,abs(min_f1 - max_f1)/ 6)),2)\n",
    "        plt.title(f'F1 score of {trait}')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_f1_score.svg'),dpi = 600)\n",
    "        plt.close()\n",
    "\n",
    "        max_pre,min_pre = np.max(np.array(pre_list)),np.min(np.array(pre_list))\n",
    "        plt.plot(epoch_list,pre_list[0],marker =None ,linewidth=1.0,label='2000 samples')\n",
    "        plt.plot(epoch_list,pre_list[1],marker =None ,linewidth=1.0,label='5000 samples')\n",
    "        plt.plot(epoch_list,pre_list[2],marker =None ,linewidth=1.0,label='8000 samples')\n",
    "        plt.plot(epoch_list,pre_list[3],marker =None ,linewidth=1.0,label='10000 samples')\n",
    "        plt.legend(loc='best')\n",
    "        plt.ylim((0,max_pre*1.2))\n",
    "        y_ticks = np.round((np.arange(min_pre,max_pre,abs(min_pre - max_pre)/ 6)),2)\n",
    "        plt.title(f'Precision of {trait}')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_precision.svg'),dpi = 600)\n",
    "        plt.close()\n",
    "        csv.close()\n",
    "\n",
    "qualitative_trait_compare(qualitative_dir_path,save_path,qualitative_trait_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb357c",
   "metadata": {},
   "source": [
    "### quantitative_trait_compare(quantitative_dir_path,save_path,quantitative_trait_list)\n",
    "\n",
    "Compare the performance of quantitative trait models across different sample size gradients.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "quantitative_dir_path=''\n",
    "save_path=''\n",
    "quantitative_trait_list=''\n",
    "quantitative_trait_compare(quantitative_dir_path,save_path,quantitative_trait_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc4995cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pictures will be saved to result/trait_name_evaluation.svg\n",
      "Now drawing protein.\n",
      "Now drawing oil.\n",
      "Now drawing SdWgt.\n",
      "Now drawing Yield.\n",
      "Now drawing R1.\n",
      "Now drawing R8.\n",
      "Now drawing Hgt.\n"
     ]
    }
   ],
   "source": [
    "def quantitative_trait_compare(quantitative_dir_path,save_path,quantitative_trait_list):\n",
    "    files = os.listdir(quantitative_dir_path)\n",
    "    path_list = [os.path.join(quantitative_dir_path,file) for file in files]\n",
    "    epoch_list = [ i+1 for i in range(150) ]\n",
    "    print(f\"All pictures will be saved to {save_path}/trait_name_evaluation.svg\")\n",
    "    for trait in quantitative_trait_list:\n",
    "        print(f\"Now drawing {trait}.\")\n",
    "        acc_list = [ ] \n",
    "        recall_list = [ ]\n",
    "        f1_score_list = [ ]\n",
    "        test_loss_list = [ ] \n",
    "        for csv_path in path_list:\n",
    "            train_loss =[ ]\n",
    "            test_loss =[ ]\n",
    "            acc = [ ]\n",
    "            recall = [ ]\n",
    "            f1_score = [ ]\n",
    "            csv = open(csv_path,'r')\n",
    "            lines = csv.readlines()\n",
    "            lines = lines[16:-2]\n",
    "            lines = [line.rstrip() for line in lines]\n",
    "            for epoch in range(len(lines)):\n",
    "                if f'{trait}' in lines[epoch] and ' | ' in lines[epoch] :\n",
    "                    train_loss.append(float(lines[epoch].split(' | ')[1].split(',')[0].split(':')[1]))\n",
    "                    test_loss.append(float(lines[epoch].split(' | ')[1].split(',')[1].split(':')[1]))\n",
    "                    acc.append(float(lines[epoch].split(' | ')[1].split(',')[2].split(':')[1]))\n",
    "            test_loss_list.append(test_loss) \n",
    "            acc_list.append(acc)\n",
    "        max_loss,min_loss = np.max(np.array(test_loss_list)),np.min(np.array(test_loss_list))\n",
    "\n",
    "        plt.plot(epoch_list,test_loss_list[0],marker =None ,linewidth=1.0,label='2000 samples')\n",
    "        plt.plot(epoch_list,test_loss_list[1],marker =None ,linewidth=1.0,label='5000 samples')\n",
    "        plt.plot(epoch_list,test_loss_list[2],marker =None ,linewidth=1.0,label='8000 samples')\n",
    "        plt.plot(epoch_list,test_loss_list[3],marker =None ,linewidth=1.0,label='10000 samples')\n",
    "        plt.ylim((0,max_loss*1.05))\n",
    "        y_ticks = np.round((np.arange(min_loss,max_loss,abs(min_loss - max_loss)/ 6)),2)\n",
    "        plt.legend(loc='best')\n",
    "        plt.title(f'Mean Square Error of {trait}')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_MeanSquareError.svg'),dpi = 600)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        max_acc,min_acc = np.max(np.array(acc_list)),np.min(np.array(acc_list))\n",
    "        plt.plot(epoch_list,acc_list[0],marker =None ,linewidth=1.0,label='2000 samples')\n",
    "        plt.plot(epoch_list,acc_list[1],marker =None ,linewidth=1.0,label='5000 samples')\n",
    "        plt.plot(epoch_list,acc_list[2],marker =None ,linewidth=1.0,label='8000 samples')\n",
    "        plt.plot(epoch_list,acc_list[3],marker =None ,linewidth=1.0,label='10000 samples')\n",
    "        plt.legend(loc='best')\n",
    "        plt.ylim((0,max_acc*1.2))\n",
    "        y_ticks = np.round((np.arange(min_acc,max_acc,abs(min_acc - max_acc)/ 6)),2)\n",
    "        plt.title(f'Accuracy of {trait}')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.savefig(os.path.join(save_path,f'{trait}_r.svg'),dpi = 600)\n",
    "        plt.close()\n",
    "        csv.close()\n",
    "        \n",
    "quantitative_trait_compare(quantitative_dir_path,save_path,quantitative_trait_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
