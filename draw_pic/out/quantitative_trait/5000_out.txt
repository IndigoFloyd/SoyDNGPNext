True
*---------------convert_trait---------------*
protein
oil
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (13784, 6)
trait shape (1, 13784)
df shape (13784, 42195)
(5000, 32032) (8784, 32032)
train dataset already completed!
5000
test dataset already completed!
8784
protein epoch 1 |  train loss:0.19958814978599548,test loss:0.02594614401459694,r:0.33435861236982956
epoch 1 : weight has update
protein epoch 2 |  train loss:0.013221869245171547,test loss:0.017488589510321617,r:0.36273359403562155
epoch 2 : weight has update
protein epoch 3 |  train loss:0.012361599132418633,test loss:0.0182954091578722,r:0.26544200775199667
protein epoch 4 |  train loss:0.01215287484228611,test loss:0.04929817095398903,r:0.27648817216476856
protein epoch 5 |  train loss:0.012012223713099957,test loss:0.06790246814489365,r:0.34519897605888006
protein epoch 6 |  train loss:0.011788303963840008,test loss:0.056973595172166824,r:0.29365938910309985
protein epoch 7 |  train loss:0.011358172632753849,test loss:0.047572389245033264,r:0.35132537416480053
protein epoch 8 |  train loss:0.011283756233751774,test loss:0.021555140614509583,r:0.46270942714246904
epoch 8 : weight has update
protein epoch 9 |  train loss:0.011158467270433903,test loss:0.06151800602674484,r:0.4945850522589786
epoch 9 : weight has update
protein epoch 10 |  train loss:0.010019012726843357,test loss:0.028995061293244362,r:0.5162880665258825
epoch 10 : weight has update
protein epoch 11 |  train loss:0.009709986858069897,test loss:0.05557103082537651,r:0.4932528986345121
protein epoch 12 |  train loss:0.009142125956714153,test loss:0.015812179073691368,r:0.527527637323721
epoch 12 : weight has update
protein epoch 13 |  train loss:0.008811353705823421,test loss:0.02328004501760006,r:0.5224720242019036
protein epoch 14 |  train loss:0.008462771773338318,test loss:0.009331775829195976,r:0.5490647479085066
epoch 14 : weight has update
protein epoch 15 |  train loss:0.008279696106910706,test loss:0.008792968466877937,r:0.5656771764793921
epoch 15 : weight has update
protein epoch 16 |  train loss:0.007946133613586426,test loss:0.00859077274799347,r:0.5686246329375447
epoch 16 : weight has update
protein epoch 17 |  train loss:0.007849314250051975,test loss:0.007884331047534943,r:0.5777616097702406
epoch 17 : weight has update
protein epoch 18 |  train loss:0.0077700186520814896,test loss:0.009667388163506985,r:0.5820502819247547
epoch 18 : weight has update
protein epoch 19 |  train loss:0.007623871322721243,test loss:0.008695265278220177,r:0.5593055248086226
protein epoch 20 |  train loss:0.007511838339269161,test loss:0.009842226281762123,r:0.588124367347611
epoch 20 : weight has update
protein epoch 21 |  train loss:0.0074609313160181046,test loss:0.014800761826336384,r:0.576449726660987
protein epoch 22 |  train loss:0.007265124469995499,test loss:0.010078058578073978,r:0.5808440062263864
protein epoch 23 |  train loss:0.007293881382793188,test loss:0.007299461401998997,r:0.5936808700132828
epoch 23 : weight has update
protein epoch 24 |  train loss:0.007013207301497459,test loss:0.00798706617206335,r:0.5868294194265148
protein epoch 25 |  train loss:0.006978246849030256,test loss:0.006771608255803585,r:0.6068724610650719
epoch 25 : weight has update
protein epoch 26 |  train loss:0.006939293351024389,test loss:0.0071197920478880405,r:0.6036823000507205
protein epoch 27 |  train loss:0.006803952623158693,test loss:0.010629885829985142,r:0.5923243170243645
protein epoch 28 |  train loss:0.006997191812843084,test loss:0.007216931786388159,r:0.606707217928434
protein epoch 29 |  train loss:0.006788146682083607,test loss:0.006844243500381708,r:0.5994996826055298
protein epoch 30 |  train loss:0.006952183321118355,test loss:0.007240454200655222,r:0.5929952209276899
protein epoch 31 |  train loss:0.006885177921503782,test loss:0.006619707215577364,r:0.607342231980302
epoch 31 : weight has update
protein epoch 32 |  train loss:0.006831054575741291,test loss:0.00672090845182538,r:0.6107063116953729
epoch 32 : weight has update
protein epoch 33 |  train loss:0.006798187270760536,test loss:0.0071331835351884365,r:0.5791066323242336
protein epoch 34 |  train loss:0.007005427032709122,test loss:0.007690261583775282,r:0.5988471777351592
protein epoch 35 |  train loss:0.006913716439157724,test loss:0.008077957667410374,r:0.6001197208733089
protein epoch 36 |  train loss:0.006895990110933781,test loss:0.0069393739104270935,r:0.5985581711886124
protein epoch 37 |  train loss:0.006968214176595211,test loss:0.007419778034090996,r:0.5978457217448295
protein epoch 38 |  train loss:0.006786466576159,test loss:0.006775277201086283,r:0.6036490873515349
protein epoch 39 |  train loss:0.006693736184388399,test loss:0.00781699176877737,r:0.5954884409946591
protein epoch 40 |  train loss:0.006659764796495438,test loss:0.008323941379785538,r:0.6172118664517812
epoch 40 : weight has update
protein epoch 41 |  train loss:0.006504579912871122,test loss:0.00751433614641428,r:0.6136546067939621
protein epoch 42 |  train loss:0.006525043398141861,test loss:0.006542511284351349,r:0.6172467216609052
epoch 42 : weight has update
protein epoch 43 |  train loss:0.006442295387387276,test loss:0.006777912378311157,r:0.6193127887956925
epoch 43 : weight has update
protein epoch 44 |  train loss:0.0064320070669054985,test loss:0.006713822949677706,r:0.6121782678587554
protein epoch 45 |  train loss:0.006410461850464344,test loss:0.007326020393520594,r:0.6194626166399666
epoch 45 : weight has update
protein epoch 46 |  train loss:0.006327283568680286,test loss:0.006480979733169079,r:0.6263404589646206
epoch 46 : weight has update
protein epoch 47 |  train loss:0.006301145534962416,test loss:0.006353144068270922,r:0.6295817603963059
epoch 47 : weight has update
protein epoch 48 |  train loss:0.006130538415163755,test loss:0.0064160688780248165,r:0.6244388377673159
protein epoch 49 |  train loss:0.006056415382772684,test loss:0.0065354034304618835,r:0.6335565015040215
epoch 49 : weight has update
protein epoch 50 |  train loss:0.006078753620386124,test loss:0.008888213895261288,r:0.6334216928293279
protein epoch 51 |  train loss:0.005874558351933956,test loss:0.007364370860159397,r:0.6346518747920863
epoch 51 : weight has update
protein epoch 52 |  train loss:0.005944712553173304,test loss:0.006618047598749399,r:0.6360778711850118
epoch 52 : weight has update
protein epoch 53 |  train loss:0.005894703324884176,test loss:0.006247835699468851,r:0.6400221174874331
epoch 53 : weight has update
protein epoch 54 |  train loss:0.005958762019872665,test loss:0.006542061921209097,r:0.6332086175149075
protein epoch 55 |  train loss:0.00590644171461463,test loss:0.006346135400235653,r:0.6316685965547428
protein epoch 56 |  train loss:0.005775843746960163,test loss:0.006829526275396347,r:0.6297146883375491
protein epoch 57 |  train loss:0.0057785785757005215,test loss:0.006680841092020273,r:0.6272527578230084
protein epoch 58 |  train loss:0.005675134714692831,test loss:0.006209015846252441,r:0.6358750273393327
protein epoch 59 |  train loss:0.005692843347787857,test loss:0.006687558256089687,r:0.6312138731192779
protein epoch 60 |  train loss:0.00568762980401516,test loss:0.006454442162066698,r:0.6367224831001524
protein epoch 61 |  train loss:0.005675534252077341,test loss:0.006383451633155346,r:0.624849822019435
protein epoch 62 |  train loss:0.005597725976258516,test loss:0.006410938687622547,r:0.6386416199695728
protein epoch 63 |  train loss:0.005630722269415855,test loss:0.006306674797087908,r:0.6361479256953381
protein epoch 64 |  train loss:0.005482892971485853,test loss:0.006264982279390097,r:0.6379793298079338
protein epoch 65 |  train loss:0.0054998029954731464,test loss:0.006262415554374456,r:0.638548330110195
protein epoch 66 |  train loss:0.005401972681283951,test loss:0.0068599567748606205,r:0.6354314555212635
protein epoch 67 |  train loss:0.005460655316710472,test loss:0.0068020266480743885,r:0.6365490895899468
protein epoch 68 |  train loss:0.005258088931441307,test loss:0.006288010627031326,r:0.6411429482689054
epoch 68 : weight has update
protein epoch 69 |  train loss:0.005372368730604649,test loss:0.006276888772845268,r:0.6403530869825759
protein epoch 70 |  train loss:0.005288658197969198,test loss:0.006183288525789976,r:0.6397553049844871
protein epoch 71 |  train loss:0.005302624776959419,test loss:0.00649367505684495,r:0.6374560055707377
protein epoch 72 |  train loss:0.005340397823601961,test loss:0.006485459860414267,r:0.6421650870972975
epoch 72 : weight has update
protein epoch 73 |  train loss:0.005182590801268816,test loss:0.006963190156966448,r:0.6368378823799861
protein epoch 74 |  train loss:0.005235216114670038,test loss:0.00680706137791276,r:0.6421104085148301
protein epoch 75 |  train loss:0.005228763446211815,test loss:0.007124992553144693,r:0.6435416734006717
epoch 75 : weight has update
protein epoch 76 |  train loss:0.005231341812759638,test loss:0.006669746246188879,r:0.6432937329038763
protein epoch 77 |  train loss:0.005241612438112497,test loss:0.006218080408871174,r:0.6429819259094647
protein epoch 78 |  train loss:0.00514447595924139,test loss:0.00620588893070817,r:0.6397125558966565
protein epoch 79 |  train loss:0.005091242957860231,test loss:0.00651648361235857,r:0.6422567154861456
protein epoch 80 |  train loss:0.005047077778726816,test loss:0.006302254740148783,r:0.640745268183939
protein epoch 81 |  train loss:0.005010809283703566,test loss:0.006219686008989811,r:0.6442087894984484
epoch 81 : weight has update
protein epoch 82 |  train loss:0.005128674674779177,test loss:0.006177212577313185,r:0.6403684804946608
protein epoch 83 |  train loss:0.005104932468384504,test loss:0.0063338554464280605,r:0.6412268733712643
protein epoch 84 |  train loss:0.00498932646587491,test loss:0.0064932601526379585,r:0.6398108315742607
protein epoch 85 |  train loss:0.005096409469842911,test loss:0.006241783499717712,r:0.6336938580121567
protein epoch 86 |  train loss:0.00512989005073905,test loss:0.0063423584215343,r:0.6415350438180074
protein epoch 87 |  train loss:0.004840638022869825,test loss:0.006762953475117683,r:0.6294385507793342
protein epoch 88 |  train loss:0.004944313317537308,test loss:0.006319524720311165,r:0.6483928546038765
epoch 88 : weight has update
protein epoch 89 |  train loss:0.004928918089717627,test loss:0.006183805409818888,r:0.6400909604378519
protein epoch 90 |  train loss:0.004946940578520298,test loss:0.006197546608746052,r:0.6430969078148487
protein epoch 91 |  train loss:0.005056444555521011,test loss:0.006448021158576012,r:0.6481397708632489
protein epoch 92 |  train loss:0.004764228127896786,test loss:0.006714510731399059,r:0.6362466238199127
protein epoch 93 |  train loss:0.0046661049127578735,test loss:0.006563251838088036,r:0.6420754771279085
protein epoch 94 |  train loss:0.0049326615408062935,test loss:0.00683222571387887,r:0.649962867981699
epoch 94 : weight has update
protein epoch 95 |  train loss:0.004829435609281063,test loss:0.006138027645647526,r:0.6528013111102906
epoch 95 : weight has update
protein epoch 96 |  train loss:0.004806164186447859,test loss:0.006832880433648825,r:0.6392462611077581
protein epoch 97 |  train loss:0.00478406110778451,test loss:0.006137518677860498,r:0.6449327093732944
protein epoch 98 |  train loss:0.004903152585029602,test loss:0.006314094178378582,r:0.6403783912717608
protein epoch 99 |  train loss:0.004747438244521618,test loss:0.006076729856431484,r:0.6466766205006189
protein epoch 100 |  train loss:0.0048561799339950085,test loss:0.006208730861544609,r:0.6474526711779892
protein epoch 101 |  train loss:0.004784371238201857,test loss:0.006112541537731886,r:0.6443136291782117
protein epoch 102 |  train loss:0.004843668080866337,test loss:0.006227854639291763,r:0.6423313726923605
protein epoch 103 |  train loss:0.004817069973796606,test loss:0.006136872339993715,r:0.6415839913032079
protein epoch 104 |  train loss:0.004753580782562494,test loss:0.0062945070676505566,r:0.640260168041788
protein epoch 105 |  train loss:0.004652020987123251,test loss:0.006122363731265068,r:0.6434226054522213
protein epoch 106 |  train loss:0.004657573066651821,test loss:0.006409762427210808,r:0.6397661027059923
protein epoch 107 |  train loss:0.004697455558925867,test loss:0.006487658247351646,r:0.6411172107662153
protein epoch 108 |  train loss:0.004698607604950666,test loss:0.006595445331186056,r:0.6383660632653329
protein epoch 109 |  train loss:0.00486024608835578,test loss:0.006311140023171902,r:0.633633696837738
protein epoch 110 |  train loss:0.0047873686999082565,test loss:0.006512932945042849,r:0.6343720442914329
protein epoch 111 |  train loss:0.004884031601250172,test loss:0.006590975448489189,r:0.6473518182833081
protein epoch 112 |  train loss:0.004691243637353182,test loss:0.006243519019335508,r:0.6411898694366471
protein epoch 113 |  train loss:0.00464071286842227,test loss:0.006286030635237694,r:0.6371542362887103
protein epoch 114 |  train loss:0.004697631113231182,test loss:0.00649438239634037,r:0.6451920440524949
protein epoch 115 |  train loss:0.004723954480141401,test loss:0.0062178755179047585,r:0.6394014105185387
protein epoch 116 |  train loss:0.004650796297937632,test loss:0.006442324724048376,r:0.6408530632557077
protein epoch 117 |  train loss:0.004601406864821911,test loss:0.00612221285700798,r:0.6443574844917987
protein epoch 118 |  train loss:0.0045928615145385265,test loss:0.006167592480778694,r:0.6473850385224182
protein epoch 119 |  train loss:0.004612404853105545,test loss:0.006220406852662563,r:0.6417339534668495
protein epoch 120 |  train loss:0.0046370020136237144,test loss:0.006235549692064524,r:0.6384223968709818
protein epoch 121 |  train loss:0.004618573002517223,test loss:0.0066401418298482895,r:0.6387351612586241
protein epoch 122 |  train loss:0.0046179876662790775,test loss:0.006187134888023138,r:0.6379716974189332
protein epoch 123 |  train loss:0.0045720417983829975,test loss:0.006283555179834366,r:0.6406920852062897
protein epoch 124 |  train loss:0.00469908257946372,test loss:0.007221229840070009,r:0.63510719982185
protein epoch 125 |  train loss:0.004661965649574995,test loss:0.00694277323782444,r:0.6321921827271657
protein epoch 126 |  train loss:0.004623468965291977,test loss:0.006182922050356865,r:0.6431155414168722
protein epoch 127 |  train loss:0.004530326928943396,test loss:0.006175445392727852,r:0.6403795315149691
protein epoch 128 |  train loss:0.004557891748845577,test loss:0.006225760094821453,r:0.6388786504857176
protein epoch 129 |  train loss:0.004500850569456816,test loss:0.0063207512721419334,r:0.6369258151287273
protein epoch 130 |  train loss:0.004617456346750259,test loss:0.006278112530708313,r:0.6353182688064082
protein epoch 131 |  train loss:0.004615411628037691,test loss:0.006219689734280109,r:0.6405614592632122
protein epoch 132 |  train loss:0.0045805564150214195,test loss:0.00622060289606452,r:0.6404683775398724
protein epoch 133 |  train loss:0.004557841923087835,test loss:0.006216155830770731,r:0.64054263639237
protein epoch 134 |  train loss:0.004592377692461014,test loss:0.006136216223239899,r:0.6420338060585172
protein epoch 135 |  train loss:0.004571737255901098,test loss:0.006197783164680004,r:0.6429074162443362
protein epoch 136 |  train loss:0.004451771732419729,test loss:0.00617810245603323,r:0.6412193930562554
protein epoch 137 |  train loss:0.004455961752682924,test loss:0.006339726969599724,r:0.6433094785349427
protein epoch 138 |  train loss:0.004581319633871317,test loss:0.006897515617311001,r:0.635462222149869
protein epoch 139 |  train loss:0.004332144279032946,test loss:0.006186963524669409,r:0.6425333770620099
protein epoch 140 |  train loss:0.0045102317817509174,test loss:0.007179081439971924,r:0.6371538290123125
protein epoch 141 |  train loss:0.004541842732578516,test loss:0.00628956314176321,r:0.6402399863141388
protein epoch 142 |  train loss:0.004542372655123472,test loss:0.006032893899828196,r:0.6496500064394123
protein epoch 143 |  train loss:0.004495656117796898,test loss:0.006930117961019278,r:0.6401946627397642
protein epoch 144 |  train loss:0.004507912788540125,test loss:0.006150266621261835,r:0.6425517444949584
protein epoch 145 |  train loss:0.0045325676910579205,test loss:0.006166457198560238,r:0.6411785689860975
protein epoch 146 |  train loss:0.004417250864207745,test loss:0.006198923569172621,r:0.640069102890263
protein epoch 147 |  train loss:0.004362976644188166,test loss:0.006191963329911232,r:0.6418280911356917
protein epoch 148 |  train loss:0.004412270151078701,test loss:0.006135002244263887,r:0.6448256252980674
protein epoch 149 |  train loss:0.004522120114415884,test loss:0.006478238385170698,r:0.6359293707586906
protein epoch 150 |  train loss:0.004434322938323021,test loss:0.006312782876193523,r:0.6440684985048222
training has finished used time : 17074.283284664154
result has saved!
True
*---------------convert_trait---------------*
protein
oil
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (13784, 6)
trait shape (1, 13784)
df shape (13784, 42195)
(5000, 32032) (8784, 32032)
train dataset already completed!
5000
test dataset already completed!
8784
oil epoch 1 |  train loss:0.19514621794223785,test loss:0.08281785249710083,r:0.40602707407543986
epoch 1 : weight has update
oil epoch 2 |  train loss:0.015034441836178303,test loss:0.08250688016414642,r:0.16180607139714992
oil epoch 3 |  train loss:0.0139432018622756,test loss:0.21013417840003967,r:0.1809177543014417
oil epoch 4 |  train loss:0.014015786349773407,test loss:0.21640801429748535,r:0.146221454333986
oil epoch 5 |  train loss:0.01277600135654211,test loss:0.24546930193901062,r:0.14988088151227322
oil epoch 6 |  train loss:0.01183126587420702,test loss:0.23199081420898438,r:0.42379309312595154
epoch 6 : weight has update
oil epoch 7 |  train loss:0.011587042361497879,test loss:0.21157798171043396,r:0.5646676977836217
epoch 7 : weight has update
oil epoch 8 |  train loss:0.010512018576264381,test loss:0.1996614933013916,r:0.5324280973460114
oil epoch 9 |  train loss:0.009509720839560032,test loss:0.1864607036113739,r:0.49175748238615513
oil epoch 10 |  train loss:0.009588843211531639,test loss:0.18171103298664093,r:0.511936690489228
oil epoch 11 |  train loss:0.008826480247080326,test loss:0.1489720493555069,r:0.5072794248741562
oil epoch 12 |  train loss:0.008722672238945961,test loss:0.15246783196926117,r:0.3849951720808307
oil epoch 13 |  train loss:0.008360502310097218,test loss:0.13382965326309204,r:0.38745412381915956
oil epoch 14 |  train loss:0.007875554263591766,test loss:0.09124685078859329,r:0.5240644015383122
oil epoch 15 |  train loss:0.0074858590960502625,test loss:0.07617046684026718,r:0.5774201325695715
epoch 15 : weight has update
oil epoch 16 |  train loss:0.00726483715698123,test loss:0.10233620554208755,r:0.4606950305593893
oil epoch 17 |  train loss:0.007726907730102539,test loss:0.09180188924074173,r:0.4665103717028781
oil epoch 18 |  train loss:0.007094252854585648,test loss:0.06380829960107803,r:0.5287687401522682
oil epoch 19 |  train loss:0.006973385810852051,test loss:0.05956520140171051,r:0.5453014632183781
oil epoch 20 |  train loss:0.006693937350064516,test loss:0.024441609159111977,r:0.6545281420671607
epoch 20 : weight has update
oil epoch 21 |  train loss:0.006648102775216103,test loss:0.02013716846704483,r:0.6802327802625413
epoch 21 : weight has update
oil epoch 22 |  train loss:0.006865356117486954,test loss:0.04952238127589226,r:0.5308975884807375
oil epoch 23 |  train loss:0.006579673383384943,test loss:0.03085581585764885,r:0.635711497215246
oil epoch 24 |  train loss:0.006435658782720566,test loss:0.017509402707219124,r:0.67369928800456
oil epoch 25 |  train loss:0.006468548439443111,test loss:0.011217399500310421,r:0.6799162869523253
oil epoch 26 |  train loss:0.006278743036091328,test loss:0.01492694579064846,r:0.6972804481026799
epoch 26 : weight has update
oil epoch 27 |  train loss:0.006300423294305801,test loss:0.007797439582645893,r:0.7108872702842027
epoch 27 : weight has update
oil epoch 28 |  train loss:0.00639197276905179,test loss:0.010481921955943108,r:0.7101324858492503
oil epoch 29 |  train loss:0.00630166893824935,test loss:0.011459654197096825,r:0.688992970868139
oil epoch 30 |  train loss:0.006370008457452059,test loss:0.008239748887717724,r:0.7094037817866538
oil epoch 31 |  train loss:0.006222849246114492,test loss:0.011624466627836227,r:0.6994028561826875
oil epoch 32 |  train loss:0.006257920991629362,test loss:0.016470685601234436,r:0.659131568676353
oil epoch 33 |  train loss:0.0067453826777637005,test loss:0.00784054584801197,r:0.7018492684109626
oil epoch 34 |  train loss:0.006750691682100296,test loss:0.009235138073563576,r:0.7019320173888013
oil epoch 35 |  train loss:0.006364847533404827,test loss:0.009999921545386314,r:0.7010641193098783
oil epoch 36 |  train loss:0.006255213171243668,test loss:0.00832273531705141,r:0.720187638325657
epoch 36 : weight has update
oil epoch 37 |  train loss:0.006206560414284468,test loss:0.007871003821492195,r:0.7222335954538925
epoch 37 : weight has update
oil epoch 38 |  train loss:0.006254906766116619,test loss:0.0066905333660542965,r:0.7076119449322403
oil epoch 39 |  train loss:0.006267745513468981,test loss:0.009064597077667713,r:0.7141563275321499
oil epoch 40 |  train loss:0.0061174011789262295,test loss:0.006853471510112286,r:0.7258823804237301
epoch 40 : weight has update
oil epoch 41 |  train loss:0.0060029481537640095,test loss:0.006677387282252312,r:0.7202844750289743
oil epoch 42 |  train loss:0.005868395324796438,test loss:0.006779408548027277,r:0.7221335304717201
oil epoch 43 |  train loss:0.005901936907321215,test loss:0.006972671486437321,r:0.725021319720747
oil epoch 44 |  train loss:0.005830169189721346,test loss:0.006744961254298687,r:0.7206559127234625
oil epoch 45 |  train loss:0.00569247268140316,test loss:0.006208249367773533,r:0.730999534595588
epoch 45 : weight has update
oil epoch 46 |  train loss:0.005790217779576778,test loss:0.00800277665257454,r:0.7173699674609864
oil epoch 47 |  train loss:0.005475503858178854,test loss:0.00976257212460041,r:0.7292925448714662
oil epoch 48 |  train loss:0.005562277510762215,test loss:0.007360395975410938,r:0.7218115521432115
oil epoch 49 |  train loss:0.005572396796196699,test loss:0.006210595369338989,r:0.7339636387868418
epoch 49 : weight has update
oil epoch 50 |  train loss:0.0055923061445355415,test loss:0.00656717037782073,r:0.7287513985919732
oil epoch 51 |  train loss:0.0055127013474702835,test loss:0.00630552601069212,r:0.7285798361212699
oil epoch 52 |  train loss:0.005358400754630566,test loss:0.006439679302275181,r:0.7310960846193086
oil epoch 53 |  train loss:0.005477129947394133,test loss:0.006252008490264416,r:0.7316161816002087
oil epoch 54 |  train loss:0.0052986182272434235,test loss:0.007154360413551331,r:0.7317074566855343
oil epoch 55 |  train loss:0.005358243826776743,test loss:0.007589975371956825,r:0.7286106613802645
oil epoch 56 |  train loss:0.00547162676230073,test loss:0.006424377206712961,r:0.7370276285059488
epoch 56 : weight has update
oil epoch 57 |  train loss:0.005261449608951807,test loss:0.00613304041326046,r:0.7364686965300106
oil epoch 58 |  train loss:0.005304662510752678,test loss:0.006542984861880541,r:0.7284536370765712
oil epoch 59 |  train loss:0.005218252539634705,test loss:0.006748124957084656,r:0.7324282253783034
oil epoch 60 |  train loss:0.00523955374956131,test loss:0.006242954172194004,r:0.7323422518412346
oil epoch 61 |  train loss:0.005014773923903704,test loss:0.006269067991524935,r:0.7332294003485206
oil epoch 62 |  train loss:0.005135422106832266,test loss:0.00689119566231966,r:0.7367642784814027
oil epoch 63 |  train loss:0.005245388951152563,test loss:0.006232297979295254,r:0.7348850693203982
oil epoch 64 |  train loss:0.005052358843386173,test loss:0.006185740698128939,r:0.7342527358773405
oil epoch 65 |  train loss:0.00507759116590023,test loss:0.006905613467097282,r:0.7345227580973864
oil epoch 66 |  train loss:0.004946757573634386,test loss:0.006144173908978701,r:0.7363602808477518
oil epoch 67 |  train loss:0.0051193819381296635,test loss:0.007182982750236988,r:0.7296815521791331
oil epoch 68 |  train loss:0.00501595251262188,test loss:0.006869595963507891,r:0.7345477900073708
oil epoch 69 |  train loss:0.005106114316731691,test loss:0.0063926163129508495,r:0.7362022212056647
oil epoch 70 |  train loss:0.0049171666614711285,test loss:0.006764307618141174,r:0.733676341049619
oil epoch 71 |  train loss:0.005072563886642456,test loss:0.006284778472036123,r:0.7362607743940841
oil epoch 72 |  train loss:0.004895419348031282,test loss:0.006591284181922674,r:0.7335721290513659
oil epoch 73 |  train loss:0.0050211274065077305,test loss:0.006507154554128647,r:0.7378720798367392
epoch 73 : weight has update
oil epoch 74 |  train loss:0.004847255535423756,test loss:0.00706663029268384,r:0.7337481824627171
oil epoch 75 |  train loss:0.004910057410597801,test loss:0.007255767937749624,r:0.7325496590500202
oil epoch 76 |  train loss:0.004760651849210262,test loss:0.006477832328528166,r:0.7317777485199188
oil epoch 77 |  train loss:0.004909016657620668,test loss:0.006559510249644518,r:0.7317143211327515
oil epoch 78 |  train loss:0.004963208455592394,test loss:0.008121591992676258,r:0.7302225756159225
oil epoch 79 |  train loss:0.004771973937749863,test loss:0.007230750285089016,r:0.7278047990119934
oil epoch 80 |  train loss:0.004778706468641758,test loss:0.006571255158632994,r:0.7322543977023498
oil epoch 81 |  train loss:0.004905959125608206,test loss:0.00653082225471735,r:0.7328893778098117
oil epoch 82 |  train loss:0.004875305108726025,test loss:0.006368093192577362,r:0.7316759162298814
oil epoch 83 |  train loss:0.004935783334076405,test loss:0.006133046466857195,r:0.7363358282405699
oil epoch 84 |  train loss:0.004823683295398951,test loss:0.006140868179500103,r:0.7327441534536776
oil epoch 85 |  train loss:0.004836519248783588,test loss:0.006671746261417866,r:0.7348769980587739
oil epoch 86 |  train loss:0.0048120575957000256,test loss:0.009906456805765629,r:0.7356538462480418
oil epoch 87 |  train loss:0.004744980484247208,test loss:0.006550440564751625,r:0.7387338145189013
epoch 87 : weight has update
oil epoch 88 |  train loss:0.004758009221404791,test loss:0.006428579334169626,r:0.7351640912972384
oil epoch 89 |  train loss:0.0048583983443677425,test loss:0.007185636553913355,r:0.7314991685993062
oil epoch 90 |  train loss:0.004733144771307707,test loss:0.00643386784940958,r:0.7358625626231379
oil epoch 91 |  train loss:0.004686933010816574,test loss:0.006729689426720142,r:0.7373043156748634
oil epoch 92 |  train loss:0.00464030122384429,test loss:0.007714401464909315,r:0.7370579954996206
oil epoch 93 |  train loss:0.004623128101229668,test loss:0.006207849830389023,r:0.7328974324140616
oil epoch 94 |  train loss:0.004688641522079706,test loss:0.006229409482330084,r:0.7393287031882175
epoch 94 : weight has update
oil epoch 95 |  train loss:0.004675179719924927,test loss:0.006626160349696875,r:0.7374871819007981
oil epoch 96 |  train loss:0.004675815347582102,test loss:0.006012620870023966,r:0.7393728030100143
epoch 96 : weight has update
oil epoch 97 |  train loss:0.0046488563530147076,test loss:0.006061415188014507,r:0.739445327751161
epoch 97 : weight has update
oil epoch 98 |  train loss:0.0046543944627046585,test loss:0.007518336176872253,r:0.7378614672745932
oil epoch 99 |  train loss:0.004866553004831076,test loss:0.0069065699353814125,r:0.7374413884274476
oil epoch 100 |  train loss:0.004653287585824728,test loss:0.006243071053177118,r:0.736447583937649
oil epoch 101 |  train loss:0.004494835156947374,test loss:0.00700874300673604,r:0.7376254768803747
oil epoch 102 |  train loss:0.004640835337340832,test loss:0.006025906186550856,r:0.7385978056970931
oil epoch 103 |  train loss:0.0045635029673576355,test loss:0.006181647069752216,r:0.7372744469343575
oil epoch 104 |  train loss:0.004560759756714106,test loss:0.006188076455146074,r:0.736157453067834
oil epoch 105 |  train loss:0.004514363128691912,test loss:0.00635947659611702,r:0.7377319234331647
oil epoch 106 |  train loss:0.004533980041742325,test loss:0.006167787592858076,r:0.7368579282396885
oil epoch 107 |  train loss:0.004513107240200043,test loss:0.006092272698879242,r:0.7353076332858883
oil epoch 108 |  train loss:0.00463230861350894,test loss:0.006452098023146391,r:0.7356926266211083
oil epoch 109 |  train loss:0.004391778260469437,test loss:0.008459821343421936,r:0.7292887005895273
oil epoch 110 |  train loss:0.004582541063427925,test loss:0.0062209307216107845,r:0.7374427054475604
oil epoch 111 |  train loss:0.004561598878353834,test loss:0.007328285835683346,r:0.7353433191636434
oil epoch 112 |  train loss:0.00449338648468256,test loss:0.006017869804054499,r:0.7390282008734766
oil epoch 113 |  train loss:0.0044197035022079945,test loss:0.006905853748321533,r:0.7398981601471297
epoch 113 : weight has update
oil epoch 114 |  train loss:0.004512725863605738,test loss:0.0061911167576909065,r:0.7390760165690791
oil epoch 115 |  train loss:0.004467748571187258,test loss:0.0060790712013840675,r:0.7395973755075115
oil epoch 116 |  train loss:0.00455909688025713,test loss:0.00610914034768939,r:0.7402009339660001
epoch 116 : weight has update
oil epoch 117 |  train loss:0.004561769776046276,test loss:0.007444594521075487,r:0.7385340416929903
oil epoch 118 |  train loss:0.004550509620457888,test loss:0.006270929705351591,r:0.7396300079113346
oil epoch 119 |  train loss:0.00441703898832202,test loss:0.006439359858632088,r:0.7288656512794539
oil epoch 120 |  train loss:0.004407495725899935,test loss:0.006139915902167559,r:0.7388100258737028
oil epoch 121 |  train loss:0.004505493212491274,test loss:0.0064131575636565685,r:0.7370897516667001
oil epoch 122 |  train loss:0.0045201461762189865,test loss:0.006350902374833822,r:0.741896447613284
epoch 122 : weight has update
oil epoch 123 |  train loss:0.0044646128080785275,test loss:0.006462919991463423,r:0.7384712994917434
oil epoch 124 |  train loss:0.004577514715492725,test loss:0.006007924675941467,r:0.7399774544069186
oil epoch 125 |  train loss:0.004413957241922617,test loss:0.006146407686173916,r:0.7386294760572004
oil epoch 126 |  train loss:0.004442332778126001,test loss:0.007024197839200497,r:0.7390604942690924
oil epoch 127 |  train loss:0.004579779226332903,test loss:0.0065106297843158245,r:0.7378685763700452
oil epoch 128 |  train loss:0.004535210784524679,test loss:0.006660775281488895,r:0.7424875378031824
epoch 128 : weight has update
oil epoch 129 |  train loss:0.004396144300699234,test loss:0.005996620748192072,r:0.7413305297338545
oil epoch 130 |  train loss:0.004497637040913105,test loss:0.006200071424245834,r:0.7346061866273541
oil epoch 131 |  train loss:0.004457300528883934,test loss:0.006061496213078499,r:0.7402547642998649
oil epoch 132 |  train loss:0.004535513464361429,test loss:0.0064657023176550865,r:0.7374736973334551
oil epoch 133 |  train loss:0.004369884729385376,test loss:0.006110555958002806,r:0.7361265325333212
oil epoch 134 |  train loss:0.004320066422224045,test loss:0.006379549391567707,r:0.7381048446872597
oil epoch 135 |  train loss:0.004413128364831209,test loss:0.006345099303871393,r:0.7232160396203161
oil epoch 136 |  train loss:0.004335253499448299,test loss:0.006203887984156609,r:0.7389696901586824
oil epoch 137 |  train loss:0.004251653794199228,test loss:0.006042563822120428,r:0.7379539470995053
oil epoch 138 |  train loss:0.0043579270131886005,test loss:0.006195003632456064,r:0.7330808316504804
oil epoch 139 |  train loss:0.004552612546831369,test loss:0.006111151073127985,r:0.7365777030357853
oil epoch 140 |  train loss:0.004555729683488607,test loss:0.006302647292613983,r:0.7400240700664339
oil epoch 141 |  train loss:0.004285065922886133,test loss:0.006038650870323181,r:0.7377627934365145
oil epoch 142 |  train loss:0.004500472452491522,test loss:0.00609165383502841,r:0.7383557172906569
oil epoch 143 |  train loss:0.004456735216081142,test loss:0.006069077178835869,r:0.7374820757298555
oil epoch 144 |  train loss:0.004361441824585199,test loss:0.006312433630228043,r:0.7248708603391529
oil epoch 145 |  train loss:0.0044136131182312965,test loss:0.006364485248923302,r:0.7322535303861853
oil epoch 146 |  train loss:0.004446710459887981,test loss:0.005985970608890057,r:0.7437513749332977
epoch 146 : weight has update
oil epoch 147 |  train loss:0.004257082007825375,test loss:0.006328273564577103,r:0.7395675894900262
oil epoch 148 |  train loss:0.004413960501551628,test loss:0.00640818290412426,r:0.7417465228743421
oil epoch 149 |  train loss:0.0043456279672682285,test loss:0.006004801951348782,r:0.7398958272860251
oil epoch 150 |  train loss:0.004331293050199747,test loss:0.006217462942004204,r:0.7377711159131278
training has finished used time : 17208.74500989914
result has saved!
True
*---------------convert_trait---------------*
protein
oil
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (13784, 6)
trait shape (1, 13784)
df shape (13784, 42195)
(5000, 32032) (8784, 32032)
train dataset already completed!
5000
test dataset already completed!
8784
SdWgt epoch 1 |  train loss:0.2069692611694336,test loss:0.23660585284233093,r:0.6032504958487105
epoch 1 : weight has update
SdWgt epoch 2 |  train loss:0.022299055010080338,test loss:1.1330676078796387,r:0.6100874092642847
epoch 2 : weight has update
SdWgt epoch 3 |  train loss:0.02072564698755741,test loss:0.03703668713569641,r:0.30127774941570323
SdWgt epoch 4 |  train loss:0.018154721707105637,test loss:0.02360064536333084,r:0.6648745852440794
epoch 4 : weight has update
SdWgt epoch 5 |  train loss:0.015617451630532742,test loss:0.06763901561498642,r:0.2068073460251844
SdWgt epoch 6 |  train loss:0.013912370428442955,test loss:0.02539847232401371,r:0.3135747206912098
SdWgt epoch 7 |  train loss:0.012480951845645905,test loss:0.02138037234544754,r:0.49499087423905175
SdWgt epoch 8 |  train loss:0.011133802123367786,test loss:0.01857135258615017,r:0.5207523375290172
SdWgt epoch 9 |  train loss:0.00995774008333683,test loss:0.017140215262770653,r:0.5476524904168855
SdWgt epoch 10 |  train loss:0.009408831596374512,test loss:0.016001205891370773,r:0.6247592505246646
SdWgt epoch 11 |  train loss:0.008884122595191002,test loss:0.01665649190545082,r:0.6701296279678647
epoch 11 : weight has update
SdWgt epoch 12 |  train loss:0.008318115957081318,test loss:0.013605544343590736,r:0.7506936255429414
epoch 12 : weight has update
SdWgt epoch 13 |  train loss:0.0077768429182469845,test loss:0.011614043265581131,r:0.7721247969936883
epoch 13 : weight has update
SdWgt epoch 14 |  train loss:0.007635058369487524,test loss:0.014593014493584633,r:0.7637045633999052
SdWgt epoch 15 |  train loss:0.006950137671083212,test loss:0.010768096894025803,r:0.7784564193287775
epoch 15 : weight has update
SdWgt epoch 16 |  train loss:0.006807122379541397,test loss:0.011369430460035801,r:0.8167276346088442
epoch 16 : weight has update
SdWgt epoch 17 |  train loss:0.0065947105176746845,test loss:0.007258555851876736,r:0.836016013967565
epoch 17 : weight has update
SdWgt epoch 18 |  train loss:0.0063044847920536995,test loss:0.007364425342530012,r:0.8274806180353228
SdWgt epoch 19 |  train loss:0.005874131806194782,test loss:0.006989708635956049,r:0.8251735743800341
SdWgt epoch 20 |  train loss:0.006013821344822645,test loss:0.008667651563882828,r:0.8500926342994933
epoch 20 : weight has update
SdWgt epoch 21 |  train loss:0.005840027704834938,test loss:0.00976086687296629,r:0.8357539072304833
SdWgt epoch 22 |  train loss:0.00568340253084898,test loss:0.008810540661215782,r:0.8440693133983883
SdWgt epoch 23 |  train loss:0.005400518421083689,test loss:0.006013324949890375,r:0.8494318968114648
SdWgt epoch 24 |  train loss:0.0056779645383358,test loss:0.007459605112671852,r:0.8452724799159237
SdWgt epoch 25 |  train loss:0.005472361575812101,test loss:0.005864712875336409,r:0.8475077035362082
SdWgt epoch 26 |  train loss:0.00555986724793911,test loss:0.0071768080815672874,r:0.8488090142933961
SdWgt epoch 27 |  train loss:0.0055587412789464,test loss:0.008838082663714886,r:0.8473978744463029
SdWgt epoch 28 |  train loss:0.0056178877130150795,test loss:0.00553267914801836,r:0.8543504009645502
epoch 28 : weight has update
SdWgt epoch 29 |  train loss:0.005716682877391577,test loss:0.006670860573649406,r:0.8405210114284576
SdWgt epoch 30 |  train loss:0.00557789858430624,test loss:0.007136420346796513,r:0.8523817725171374
SdWgt epoch 31 |  train loss:0.0056762658059597015,test loss:0.006106921937316656,r:0.856918548252949
epoch 31 : weight has update
SdWgt epoch 32 |  train loss:0.00557510182261467,test loss:0.006059742067009211,r:0.8521827235895645
SdWgt epoch 33 |  train loss:0.0058732167817652225,test loss:0.006806080229580402,r:0.8545474941979888
SdWgt epoch 34 |  train loss:0.00579447764903307,test loss:0.005612265784293413,r:0.8602721645939028
epoch 34 : weight has update
SdWgt epoch 35 |  train loss:0.005627216771245003,test loss:0.005590342916548252,r:0.8538172729384933
SdWgt epoch 36 |  train loss:0.005788094829767942,test loss:0.005908177699893713,r:0.8539030085832839
SdWgt epoch 37 |  train loss:0.005807959474623203,test loss:0.008001267910003662,r:0.8545210672038517
SdWgt epoch 38 |  train loss:0.0058705504052340984,test loss:0.0053283884190022945,r:0.8603050559907353
epoch 38 : weight has update
SdWgt epoch 39 |  train loss:0.005631852429360151,test loss:0.006498351227492094,r:0.8592050570986318
SdWgt epoch 40 |  train loss:0.005421373527497053,test loss:0.006954152602702379,r:0.8570807918215118
SdWgt epoch 41 |  train loss:0.005540314596146345,test loss:0.0052572558633983135,r:0.8637355136705953
epoch 41 : weight has update
SdWgt epoch 42 |  train loss:0.005395329091697931,test loss:0.0059131416492164135,r:0.8674377876342994
epoch 42 : weight has update
SdWgt epoch 43 |  train loss:0.005488906987011433,test loss:0.006489411927759647,r:0.8706981748575103
epoch 43 : weight has update
SdWgt epoch 44 |  train loss:0.0055676973424851894,test loss:0.005409216973930597,r:0.8713060330317516
epoch 44 : weight has update
SdWgt epoch 45 |  train loss:0.0053340899758040905,test loss:0.009180158376693726,r:0.8658803301767873
SdWgt epoch 46 |  train loss:0.005158788058906794,test loss:0.004924975335597992,r:0.8725138207804494
epoch 46 : weight has update
SdWgt epoch 47 |  train loss:0.005165820010006428,test loss:0.005105610471218824,r:0.8693162584804033
SdWgt epoch 48 |  train loss:0.005126299802213907,test loss:0.0071523673832416534,r:0.8735582262091961
epoch 48 : weight has update
SdWgt epoch 49 |  train loss:0.005272628739476204,test loss:0.006175312679260969,r:0.8710023906984009
SdWgt epoch 50 |  train loss:0.005126407369971275,test loss:0.004888629540801048,r:0.8726526223025148
SdWgt epoch 51 |  train loss:0.005225008819252253,test loss:0.007189951371401548,r:0.863213600015988
SdWgt epoch 52 |  train loss:0.005049938801676035,test loss:0.005176730919629335,r:0.8734128436484646
SdWgt epoch 53 |  train loss:0.004875828046351671,test loss:0.008131391368806362,r:0.8656996860367295
SdWgt epoch 54 |  train loss:0.005023560952395201,test loss:0.00739146675914526,r:0.8744125474611867
epoch 54 : weight has update
SdWgt epoch 55 |  train loss:0.004975727293640375,test loss:0.00735961738973856,r:0.8739027597822221
SdWgt epoch 56 |  train loss:0.004918348975479603,test loss:0.004687509499490261,r:0.8772865309320518
epoch 56 : weight has update
SdWgt epoch 57 |  train loss:0.004856553394347429,test loss:0.006562195718288422,r:0.8689376188070631
SdWgt epoch 58 |  train loss:0.004980114754289389,test loss:0.0056740595027804375,r:0.8762711222102455
SdWgt epoch 59 |  train loss:0.0046270377933979034,test loss:0.005229838192462921,r:0.876456818175259
SdWgt epoch 60 |  train loss:0.004671935457736254,test loss:0.004991729743778706,r:0.8732272873111896
SdWgt epoch 61 |  train loss:0.004907825496047735,test loss:0.006443451624363661,r:0.8771794583426883
SdWgt epoch 62 |  train loss:0.004788242280483246,test loss:0.006433906499296427,r:0.8755508055520951
SdWgt epoch 63 |  train loss:0.0047604115679860115,test loss:0.004934082739055157,r:0.875589738614748
SdWgt epoch 64 |  train loss:0.004587233532220125,test loss:0.006201380398124456,r:0.8793264108439918
epoch 64 : weight has update
SdWgt epoch 65 |  train loss:0.0046306392177939415,test loss:0.004750077612698078,r:0.8763662174090446
SdWgt epoch 66 |  train loss:0.0045069679617881775,test loss:0.005460032261908054,r:0.8756883434801066
SdWgt epoch 67 |  train loss:0.004564279690384865,test loss:0.00473132124170661,r:0.8772196655012447
SdWgt epoch 68 |  train loss:0.004369732923805714,test loss:0.005775005556643009,r:0.8722446106904006
SdWgt epoch 69 |  train loss:0.0044026486575603485,test loss:0.004551330581307411,r:0.881011135900322
epoch 69 : weight has update
SdWgt epoch 70 |  train loss:0.004545519594103098,test loss:0.00497184693813324,r:0.8738613554824245
SdWgt epoch 71 |  train loss:0.004661915823817253,test loss:0.005517920944839716,r:0.8781747316424126
SdWgt epoch 72 |  train loss:0.004557551350444555,test loss:0.005728702526539564,r:0.8804123411726766
SdWgt epoch 73 |  train loss:0.004441720433533192,test loss:0.005250982474535704,r:0.8804126609796927
SdWgt epoch 74 |  train loss:0.004575393628329039,test loss:0.0059214127250015736,r:0.8749650191191428
SdWgt epoch 75 |  train loss:0.004448716528713703,test loss:0.005147241987287998,r:0.8803477357219658
SdWgt epoch 76 |  train loss:0.00438689487054944,test loss:0.004921152256429195,r:0.8793662797536635
SdWgt epoch 77 |  train loss:0.004617269150912762,test loss:0.005970207508653402,r:0.8743726847068175
SdWgt epoch 78 |  train loss:0.004348483867943287,test loss:0.006286391522735357,r:0.8787925816221942
SdWgt epoch 79 |  train loss:0.004402171354740858,test loss:0.00514560379087925,r:0.8778868087598195
SdWgt epoch 80 |  train loss:0.004326692782342434,test loss:0.004996044095605612,r:0.8749447581831462
SdWgt epoch 81 |  train loss:0.004381035454571247,test loss:0.00560828996822238,r:0.8781842059145646
SdWgt epoch 82 |  train loss:0.004383143037557602,test loss:0.004660289268940687,r:0.8816938867479852
epoch 82 : weight has update
SdWgt epoch 83 |  train loss:0.004300720989704132,test loss:0.005123555194586515,r:0.8779286181301292
SdWgt epoch 84 |  train loss:0.004253657069057226,test loss:0.004813062492758036,r:0.8772197624892111
SdWgt epoch 85 |  train loss:0.004293837584555149,test loss:0.005548205226659775,r:0.878400433186239
SdWgt epoch 86 |  train loss:0.004187117796391249,test loss:0.0058266762644052505,r:0.8771029984503464
SdWgt epoch 87 |  train loss:0.004252987913787365,test loss:0.005105039570480585,r:0.8808004299842692
SdWgt epoch 88 |  train loss:0.004371495917439461,test loss:0.005671222228556871,r:0.8815154919857525
SdWgt epoch 89 |  train loss:0.004259774461388588,test loss:0.007413370069116354,r:0.8808663196555813
SdWgt epoch 90 |  train loss:0.0043074265122413635,test loss:0.006193666253238916,r:0.877878815258938
SdWgt epoch 91 |  train loss:0.004214414861053228,test loss:0.005564295686781406,r:0.875905619455595
SdWgt epoch 92 |  train loss:0.004433217458426952,test loss:0.005214536562561989,r:0.8779750926008144
SdWgt epoch 93 |  train loss:0.004287531599402428,test loss:0.005086931400001049,r:0.881889218500928
epoch 93 : weight has update
SdWgt epoch 94 |  train loss:0.004317080602049828,test loss:0.005077757406979799,r:0.8773508295197723
SdWgt epoch 95 |  train loss:0.004151955712586641,test loss:0.004867713898420334,r:0.878863386627939
SdWgt epoch 96 |  train loss:0.0041833980940282345,test loss:0.006046321243047714,r:0.8797549488801575
SdWgt epoch 97 |  train loss:0.004289763048291206,test loss:0.004763342440128326,r:0.8797555299957159
SdWgt epoch 98 |  train loss:0.004242385271936655,test loss:0.005615067668259144,r:0.8809622385357753
SdWgt epoch 99 |  train loss:0.004162180237472057,test loss:0.005078666377812624,r:0.882215774729648
epoch 99 : weight has update
SdWgt epoch 100 |  train loss:0.0041244784370064735,test loss:0.005782710388302803,r:0.8749043404145557
SdWgt epoch 101 |  train loss:0.004257477354258299,test loss:0.006951728370040655,r:0.8765304534996424
SdWgt epoch 102 |  train loss:0.004182028118520975,test loss:0.005018723197281361,r:0.8778704093493174
SdWgt epoch 103 |  train loss:0.00430121086537838,test loss:0.004996540956199169,r:0.8800037808736187
SdWgt epoch 104 |  train loss:0.004224203061312437,test loss:0.00537834269925952,r:0.8791539085319583
SdWgt epoch 105 |  train loss:0.004159886389970779,test loss:0.0049241394735872746,r:0.8796717510782605
SdWgt epoch 106 |  train loss:0.004116802476346493,test loss:0.005543973296880722,r:0.8697512592373141
SdWgt epoch 107 |  train loss:0.004342302680015564,test loss:0.005185759160667658,r:0.8781928263850263
SdWgt epoch 108 |  train loss:0.004114056471735239,test loss:0.005202381405979395,r:0.8781110831452691
SdWgt epoch 109 |  train loss:0.004104954190552235,test loss:0.005131014622747898,r:0.877671497896598
SdWgt epoch 110 |  train loss:0.004168246872723103,test loss:0.004853969905525446,r:0.8781619082771172
SdWgt epoch 111 |  train loss:0.004117900971323252,test loss:0.004747055470943451,r:0.8830047207825216
epoch 111 : weight has update
SdWgt epoch 112 |  train loss:0.004137179348617792,test loss:0.004597237799316645,r:0.8802415224062017
SdWgt epoch 113 |  train loss:0.004066350869834423,test loss:0.005368110723793507,r:0.8791973268517244
SdWgt epoch 114 |  train loss:0.004226423799991608,test loss:0.0055365366861224174,r:0.8778038890225289
SdWgt epoch 115 |  train loss:0.004172034095972776,test loss:0.004911139607429504,r:0.8796017062364568
SdWgt epoch 116 |  train loss:0.0040667406283319,test loss:0.006232149433344603,r:0.8742449045823434
SdWgt epoch 117 |  train loss:0.004191302228718996,test loss:0.004956635180860758,r:0.8794580221993038
SdWgt epoch 118 |  train loss:0.004085591062903404,test loss:0.004732716828584671,r:0.8791691178365062
SdWgt epoch 119 |  train loss:0.004141369368880987,test loss:0.006142251193523407,r:0.8769237866237387
SdWgt epoch 120 |  train loss:0.004189270548522472,test loss:0.006074846722185612,r:0.8770371406882009
SdWgt epoch 121 |  train loss:0.004117385018616915,test loss:0.005071647465229034,r:0.879060080956137
SdWgt epoch 122 |  train loss:0.004118219017982483,test loss:0.006356008350849152,r:0.8711728362787333
SdWgt epoch 123 |  train loss:0.004066889639943838,test loss:0.005624055862426758,r:0.8719603650329022
SdWgt epoch 124 |  train loss:0.00402831519022584,test loss:0.004950962029397488,r:0.8767968030726415
SdWgt epoch 125 |  train loss:0.003996606450527906,test loss:0.00506407767534256,r:0.875937998684084
SdWgt epoch 126 |  train loss:0.0041777328588068485,test loss:0.006256876979023218,r:0.8776107355638447
SdWgt epoch 127 |  train loss:0.003991969395428896,test loss:0.004691766574978828,r:0.8783341030035268
SdWgt epoch 128 |  train loss:0.003901116084307432,test loss:0.006634622346609831,r:0.8738441151718329
SdWgt epoch 129 |  train loss:0.00426021683961153,test loss:0.00509435310959816,r:0.8802730467988733
SdWgt epoch 130 |  train loss:0.004048698581755161,test loss:0.006795987952500582,r:0.8743262649450264
SdWgt epoch 131 |  train loss:0.0039789979346096516,test loss:0.00598913012072444,r:0.880105818698123
SdWgt epoch 132 |  train loss:0.004099175799638033,test loss:0.005794535856693983,r:0.8761493080835004
SdWgt epoch 133 |  train loss:0.00418776273727417,test loss:0.006757210474461317,r:0.8810780396420097
SdWgt epoch 134 |  train loss:0.004066073801368475,test loss:0.005649355705827475,r:0.8804128245774367
SdWgt epoch 135 |  train loss:0.003978073131293058,test loss:0.00595327140763402,r:0.8802713254475503
SdWgt epoch 136 |  train loss:0.003960618283599615,test loss:0.005116127897053957,r:0.8806278887241387
SdWgt epoch 137 |  train loss:0.00400474201887846,test loss:0.005140883848071098,r:0.8812545524779132
SdWgt epoch 138 |  train loss:0.004103542771190405,test loss:0.005955446511507034,r:0.8799215305134714
SdWgt epoch 139 |  train loss:0.0039059955161064863,test loss:0.0050088101997971535,r:0.8793964777403173
SdWgt epoch 140 |  train loss:0.004145989194512367,test loss:0.0054262313060462475,r:0.8794066098599644
SdWgt epoch 141 |  train loss:0.004020825028419495,test loss:0.005758373066782951,r:0.8772928936557355
SdWgt epoch 142 |  train loss:0.003940989729017019,test loss:0.004899585619568825,r:0.8818612457722563
SdWgt epoch 143 |  train loss:0.004149699583649635,test loss:0.005290066823363304,r:0.8801686042383601
SdWgt epoch 144 |  train loss:0.0038244533352553844,test loss:0.006974911317229271,r:0.8725628624399017
SdWgt epoch 145 |  train loss:0.004172271583229303,test loss:0.005547945853322744,r:0.8765797153597077
SdWgt epoch 146 |  train loss:0.003974365536123514,test loss:0.0055114454589784145,r:0.875928954623834
SdWgt epoch 147 |  train loss:0.004047012887895107,test loss:0.005979306995868683,r:0.8765479107520489
SdWgt epoch 148 |  train loss:0.004073866177350283,test loss:0.0055515035055577755,r:0.8798645911079028
SdWgt epoch 149 |  train loss:0.003924681339412928,test loss:0.0050071668811142445,r:0.8796245387295506
SdWgt epoch 150 |  train loss:0.00415875855833292,test loss:0.0057807848788797855,r:0.8837911406891347
epoch 150 : weight has update
training has finished used time : 16615.327689409256
result has saved!
True
*---------------convert_trait---------------*
protein
oil
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (13784, 6)
trait shape (1, 13784)
df shape (13784, 42195)
(5000, 32032) (8784, 32032)
train dataset already completed!
5000
test dataset already completed!
8784
Yield epoch 1 |  train loss:0.15839418768882751,test loss:4.327458381652832,r:0.40829205638970717
epoch 1 : weight has update
Yield epoch 2 |  train loss:0.027574295178055763,test loss:2.5762245655059814,r:0.38525507996588726
Yield epoch 3 |  train loss:0.02633257769048214,test loss:1.9709384441375732,r:0.43916825373009827
epoch 3 : weight has update
Yield epoch 4 |  train loss:0.025758612900972366,test loss:0.19963109493255615,r:0.44988090376507045
epoch 4 : weight has update
Yield epoch 5 |  train loss:0.02372152917087078,test loss:0.1263761967420578,r:-0.006234417543783854
Yield epoch 6 |  train loss:0.022927720099687576,test loss:0.16750751435756683,r:0.5486807983639953
epoch 6 : weight has update
Yield epoch 7 |  train loss:0.020772626623511314,test loss:0.10990901291370392,r:0.5294285008364903
Yield epoch 8 |  train loss:0.020539524033665657,test loss:0.25113797187805176,r:0.6256994124549344
epoch 8 : weight has update
Yield epoch 9 |  train loss:0.019119538366794586,test loss:0.0852474719285965,r:0.6023748146978224
Yield epoch 10 |  train loss:0.0185695830732584,test loss:0.05830380320549011,r:0.6179722721022504
Yield epoch 11 |  train loss:0.017633996903896332,test loss:0.12057071179151535,r:0.6203600610809293
Yield epoch 12 |  train loss:0.01705189235508442,test loss:0.0507642887532711,r:0.6422974745958954
epoch 12 : weight has update
Yield epoch 13 |  train loss:0.016500256955623627,test loss:0.02234634757041931,r:0.6476453589256067
epoch 13 : weight has update
Yield epoch 14 |  train loss:0.016004906967282295,test loss:0.030691957101225853,r:0.6715434838603941
epoch 14 : weight has update
Yield epoch 15 |  train loss:0.015785198658704758,test loss:0.046270329505205154,r:0.6723334968730363
epoch 15 : weight has update
Yield epoch 16 |  train loss:0.015423513948917389,test loss:0.0359455831348896,r:0.6858284514401941
epoch 16 : weight has update
Yield epoch 17 |  train loss:0.014582895673811436,test loss:0.01583685167133808,r:0.686234654889361
epoch 17 : weight has update
Yield epoch 18 |  train loss:0.014540163800120354,test loss:0.023334428668022156,r:0.6643002487816734
Yield epoch 19 |  train loss:0.01385232899338007,test loss:0.0323919802904129,r:0.6901463549086514
epoch 19 : weight has update
Yield epoch 20 |  train loss:0.01379589457064867,test loss:0.04239606112241745,r:0.7039111867257816
epoch 20 : weight has update
Yield epoch 21 |  train loss:0.013682856224477291,test loss:0.022480802610516548,r:0.697180030704326
Yield epoch 22 |  train loss:0.014441174454987049,test loss:0.03563554957509041,r:0.7070560665971122
epoch 22 : weight has update
Yield epoch 23 |  train loss:0.013687068596482277,test loss:0.017865020781755447,r:0.709536333655473
epoch 23 : weight has update
Yield epoch 24 |  train loss:0.013356968760490417,test loss:0.022020062431693077,r:0.7059998247428555
Yield epoch 25 |  train loss:0.013454634696245193,test loss:0.01567710004746914,r:0.7193489095419632
epoch 25 : weight has update
Yield epoch 26 |  train loss:0.013243078254163265,test loss:0.016216745600104332,r:0.7023290251151116
Yield epoch 27 |  train loss:0.013323590159416199,test loss:0.020769154652953148,r:0.672725137850387
Yield epoch 28 |  train loss:0.01351903472095728,test loss:0.015310117974877357,r:0.7017137311383208
Yield epoch 29 |  train loss:0.01318363193422556,test loss:0.025552816689014435,r:0.7072788149490937
Yield epoch 30 |  train loss:0.013128857128322124,test loss:0.014777415432035923,r:0.7004320019889515
Yield epoch 31 |  train loss:0.012996604666113853,test loss:0.029203101992607117,r:0.7061047998252856
Yield epoch 32 |  train loss:0.013230385258793831,test loss:0.015391123481094837,r:0.7064202287657775
Yield epoch 33 |  train loss:0.013039221055805683,test loss:0.0243800301104784,r:0.6930921844244473
Yield epoch 34 |  train loss:0.013513321988284588,test loss:0.014985752291977406,r:0.6984839949328544
Yield epoch 35 |  train loss:0.012665534391999245,test loss:0.015712812542915344,r:0.700668362376903
Yield epoch 36 |  train loss:0.013116235844790936,test loss:0.014576714485883713,r:0.7032652752022829
Yield epoch 37 |  train loss:0.012704865075647831,test loss:0.02219238132238388,r:0.7089926276569223
Yield epoch 38 |  train loss:0.012624306604266167,test loss:0.023901959881186485,r:0.6812162317559685
Yield epoch 39 |  train loss:0.012644022703170776,test loss:0.01496011484414339,r:0.7163947056945634
Yield epoch 40 |  train loss:0.012858572416007519,test loss:0.015836182981729507,r:0.720738676148912
epoch 40 : weight has update
Yield epoch 41 |  train loss:0.012100527994334698,test loss:0.014505645260214806,r:0.7201457659376889
Yield epoch 42 |  train loss:0.012117739766836166,test loss:0.014124233275651932,r:0.7163137898031833
Yield epoch 43 |  train loss:0.012142048217356205,test loss:0.013360579498112202,r:0.7260327053929487
epoch 43 : weight has update
Yield epoch 44 |  train loss:0.011954966932535172,test loss:0.013244259171187878,r:0.7233914322790836
Yield epoch 45 |  train loss:0.011757586151361465,test loss:0.014090840704739094,r:0.7144191125734678
Yield epoch 46 |  train loss:0.011758320033550262,test loss:0.013839015737175941,r:0.7125987945325565
Yield epoch 47 |  train loss:0.011707194149494171,test loss:0.01440022699534893,r:0.7249071749674537
Yield epoch 48 |  train loss:0.011740900576114655,test loss:0.01352278795093298,r:0.7206666910412673
Yield epoch 49 |  train loss:0.011479022912681103,test loss:0.022536057978868484,r:0.7192620925324549
Yield epoch 50 |  train loss:0.011541926302015781,test loss:0.013203255832195282,r:0.7276236444257868
epoch 50 : weight has update
Yield epoch 51 |  train loss:0.011489859782159328,test loss:0.014349045231938362,r:0.7326604839153521
epoch 51 : weight has update
Yield epoch 52 |  train loss:0.01121297013014555,test loss:0.0152937863022089,r:0.7312800873363926
Yield epoch 53 |  train loss:0.011072537861764431,test loss:0.01332347746938467,r:0.7256006344893683
Yield epoch 54 |  train loss:0.011117964051663876,test loss:0.013771142810583115,r:0.7217540282026045
Yield epoch 55 |  train loss:0.011055750772356987,test loss:0.014318805187940598,r:0.7314093448099198
Yield epoch 56 |  train loss:0.01063031330704689,test loss:0.014307273551821709,r:0.7261707466185514
Yield epoch 57 |  train loss:0.010679474100470543,test loss:0.013171855360269547,r:0.7269533409781153
Yield epoch 58 |  train loss:0.010745109058916569,test loss:0.013262602500617504,r:0.7288388431171193
Yield epoch 59 |  train loss:0.010807163082063198,test loss:0.0176243856549263,r:0.7254817331767064
Yield epoch 60 |  train loss:0.0106892678886652,test loss:0.01904108002781868,r:0.7308417719802942
Yield epoch 61 |  train loss:0.010718521662056446,test loss:0.015382588841021061,r:0.7269019200004231
Yield epoch 62 |  train loss:0.010498791001737118,test loss:0.015242286957800388,r:0.7315459340211362
Yield epoch 63 |  train loss:0.01030102837830782,test loss:0.022800859063863754,r:0.7345271039877086
epoch 63 : weight has update
Yield epoch 64 |  train loss:0.01038004644215107,test loss:0.014309299178421497,r:0.7320717774065344
Yield epoch 65 |  train loss:0.010349756106734276,test loss:0.013480589725077152,r:0.7311084708920857
Yield epoch 66 |  train loss:0.010223710909485817,test loss:0.015852509066462517,r:0.7291710746635415
Yield epoch 67 |  train loss:0.010483586229383945,test loss:0.013188683427870274,r:0.7343339012993894
Yield epoch 68 |  train loss:0.010261195711791515,test loss:0.01447499729692936,r:0.7367335528205092
epoch 68 : weight has update
Yield epoch 69 |  train loss:0.010545031167566776,test loss:0.01693231426179409,r:0.736223895581027
Yield epoch 70 |  train loss:0.00991499051451683,test loss:0.013634522445499897,r:0.7351509174953432
Yield epoch 71 |  train loss:0.010111411102116108,test loss:0.013923725113272667,r:0.7333903074664255
Yield epoch 72 |  train loss:0.009942189790308475,test loss:0.014125649817287922,r:0.7326269355234104
Yield epoch 73 |  train loss:0.009793011471629143,test loss:0.014382192865014076,r:0.7329706626945374
Yield epoch 74 |  train loss:0.00984483677893877,test loss:0.013036821968853474,r:0.738254758002737
epoch 74 : weight has update
Yield epoch 75 |  train loss:0.009798371233046055,test loss:0.013411348685622215,r:0.7365272143167647
Yield epoch 76 |  train loss:0.009879297576844692,test loss:0.013031293638050556,r:0.7369508482769999
Yield epoch 77 |  train loss:0.010160885751247406,test loss:0.017260558903217316,r:0.7372279213845717
Yield epoch 78 |  train loss:0.009648703970015049,test loss:0.013843832537531853,r:0.731390245928316
Yield epoch 79 |  train loss:0.009831385686993599,test loss:0.013864042237401009,r:0.7349584555231812
Yield epoch 80 |  train loss:0.00978112779557705,test loss:0.013002883642911911,r:0.7337817669479472
Yield epoch 81 |  train loss:0.009687607176601887,test loss:0.013739603571593761,r:0.7362101918202092
Yield epoch 82 |  train loss:0.009805822744965553,test loss:0.013428173027932644,r:0.7365776769627781
Yield epoch 83 |  train loss:0.009760801680386066,test loss:0.013681168667972088,r:0.7341407834532271
Yield epoch 84 |  train loss:0.009601258672773838,test loss:0.013593641109764576,r:0.7380886273560507
Yield epoch 85 |  train loss:0.009528671391308308,test loss:0.01435582060366869,r:0.7361264090817103
Yield epoch 86 |  train loss:0.009820641949772835,test loss:0.014231602661311626,r:0.7351799480681869
Yield epoch 87 |  train loss:0.009516081772744656,test loss:0.012922604568302631,r:0.7371010043025964
Yield epoch 88 |  train loss:0.009318859316408634,test loss:0.013324890285730362,r:0.738514735047567
epoch 88 : weight has update
Yield epoch 89 |  train loss:0.00931745208799839,test loss:0.013431002385914326,r:0.7330066299212878
Yield epoch 90 |  train loss:0.009554785676300526,test loss:0.016833774745464325,r:0.7392170693516287
epoch 90 : weight has update
Yield epoch 91 |  train loss:0.00933102797716856,test loss:0.016978176310658455,r:0.7293224503793739
Yield epoch 92 |  train loss:0.00928059034049511,test loss:0.014457139186561108,r:0.7357467193688384
Yield epoch 93 |  train loss:0.009292110800743103,test loss:0.01641806773841381,r:0.7373796941155915
Yield epoch 94 |  train loss:0.009103880263864994,test loss:0.012945656664669514,r:0.7383590894277193
Yield epoch 95 |  train loss:0.009370259940624237,test loss:0.016266241669654846,r:0.7329609012701891
Yield epoch 96 |  train loss:0.009169816970825195,test loss:0.029273977503180504,r:0.7300282782666092
Yield epoch 97 |  train loss:0.009290740825235844,test loss:0.013728203251957893,r:0.7282909653201103
Yield epoch 98 |  train loss:0.009327375330030918,test loss:0.019895844161510468,r:0.735864150466688
Yield epoch 99 |  train loss:0.009297369979321957,test loss:0.013483919203281403,r:0.7369774385824448
Yield epoch 100 |  train loss:0.009080136194825172,test loss:0.01608435809612274,r:0.7406336668872397
epoch 100 : weight has update
Yield epoch 101 |  train loss:0.009278652258217335,test loss:0.013051072135567665,r:0.7391200501869551
Yield epoch 102 |  train loss:0.009136338718235493,test loss:0.013715766370296478,r:0.7357418374864354
Yield epoch 103 |  train loss:0.00935869850218296,test loss:0.0133768729865551,r:0.7337118696402941
Yield epoch 104 |  train loss:0.009106690064072609,test loss:0.013565036468207836,r:0.7387992713554371
Yield epoch 105 |  train loss:0.009002307429909706,test loss:0.014167647808790207,r:0.7340047642216557
Yield epoch 106 |  train loss:0.009298641234636307,test loss:0.01633531227707863,r:0.7392507766334587
Yield epoch 107 |  train loss:0.009026619605720043,test loss:0.014228874817490578,r:0.7308749614729564
Yield epoch 108 |  train loss:0.009349348954856396,test loss:0.012818689458072186,r:0.736738310549013
Yield epoch 109 |  train loss:0.00895265955477953,test loss:0.017185697332024574,r:0.735939942905141
Yield epoch 110 |  train loss:0.009186196140944958,test loss:0.013647266663610935,r:0.7317559900650392
Yield epoch 111 |  train loss:0.009097080677747726,test loss:0.014816297218203545,r:0.7359759281316194
Yield epoch 112 |  train loss:0.009135914966464043,test loss:0.013857750222086906,r:0.7355814841621402
Yield epoch 113 |  train loss:0.009411213919520378,test loss:0.014972680248320103,r:0.731217408918474
Yield epoch 114 |  train loss:0.008747400715947151,test loss:0.014202450402081013,r:0.735338226520287
Yield epoch 115 |  train loss:0.009025470353662968,test loss:0.012643867172300816,r:0.738314032957764
Yield epoch 116 |  train loss:0.008954794146120548,test loss:0.014039878733456135,r:0.7341800902562191
Yield epoch 117 |  train loss:0.009112018160521984,test loss:0.015047355554997921,r:0.7277692272446412
Yield epoch 118 |  train loss:0.009085215628147125,test loss:0.017441729083657265,r:0.7324832754781785
Yield epoch 119 |  train loss:0.008983777835965157,test loss:0.012944039888679981,r:0.7338975281888649
Yield epoch 120 |  train loss:0.008872075006365776,test loss:0.013967720791697502,r:0.7380529446513368
Yield epoch 121 |  train loss:0.00883939303457737,test loss:0.012920839712023735,r:0.7368020602136232
Yield epoch 122 |  train loss:0.008872962556779385,test loss:0.013384714722633362,r:0.7309241832202503
Yield epoch 123 |  train loss:0.008789902552962303,test loss:0.015323379077017307,r:0.7371289481518823
Yield epoch 124 |  train loss:0.008742978796362877,test loss:0.013694227673113346,r:0.7355833652758389
Yield epoch 125 |  train loss:0.008619586005806923,test loss:0.016277039423584938,r:0.724784698339856
Yield epoch 126 |  train loss:0.008888584561645985,test loss:0.02035156823694706,r:0.7343867252006512
Yield epoch 127 |  train loss:0.008947024121880531,test loss:0.01318395510315895,r:0.7329105379926174
Yield epoch 128 |  train loss:0.009039221331477165,test loss:0.012984300032258034,r:0.739401756552829
Yield epoch 129 |  train loss:0.008774071000516415,test loss:0.013667888008058071,r:0.7368035234700399
Yield epoch 130 |  train loss:0.008985168300569057,test loss:0.013752657920122147,r:0.7387043987129723
Yield epoch 131 |  train loss:0.008844302967190742,test loss:0.01260991021990776,r:0.7395202111708205
Yield epoch 132 |  train loss:0.00873634498566389,test loss:0.012911978177726269,r:0.7395932927329445
Yield epoch 133 |  train loss:0.008842011913657188,test loss:0.013383553363382816,r:0.7321984003867381
Yield epoch 134 |  train loss:0.008972053416073322,test loss:0.012804770842194557,r:0.7343485984314898
Yield epoch 135 |  train loss:0.008796511217951775,test loss:0.014244833961129189,r:0.7365294026674113
Yield epoch 136 |  train loss:0.00893249548971653,test loss:0.015363712795078754,r:0.7349289020926084
Yield epoch 137 |  train loss:0.008851337246596813,test loss:0.01527549047023058,r:0.73559116754188
Yield epoch 138 |  train loss:0.008552961982786655,test loss:0.014627356082201004,r:0.7284736997803738
Yield epoch 139 |  train loss:0.008675245568156242,test loss:0.013370238244533539,r:0.7325660667972261
Yield epoch 140 |  train loss:0.008612465113401413,test loss:0.013028650544583797,r:0.7369873819253175
Yield epoch 141 |  train loss:0.008760858327150345,test loss:0.012672453187406063,r:0.7392831403522242
Yield epoch 142 |  train loss:0.008971527218818665,test loss:0.013282379135489464,r:0.735890546107451
Yield epoch 143 |  train loss:0.008674824610352516,test loss:0.013031693175435066,r:0.733157270071494
Yield epoch 144 |  train loss:0.008772809989750385,test loss:0.01936611346900463,r:0.7370793401454113
Yield epoch 145 |  train loss:0.008749435655772686,test loss:0.013132079504430294,r:0.7288957969577861
Yield epoch 146 |  train loss:0.008686576038599014,test loss:0.0128600699827075,r:0.7391641374971244
Yield epoch 147 |  train loss:0.008659292943775654,test loss:0.014468802139163017,r:0.7389276136745605
Yield epoch 148 |  train loss:0.00860972236841917,test loss:0.012905576266348362,r:0.736415044286964
Yield epoch 149 |  train loss:0.008956200443208218,test loss:0.013443714939057827,r:0.7406775808067716
epoch 149 : weight has update
Yield epoch 150 |  train loss:0.008649679832160473,test loss:0.013427694328129292,r:0.7397879660639848
training has finished used time : 9559.044867038727
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (16308, 14)
5000
10365
df shape (20087, 42195)
shape train_df pos (32032, 20087)
shape train_df sample (5000, 32032)
(5000, 32032) (10365, 32032)
train dataset already completed!
5000
test dataset already completed!
10365
R1 epoch 1 |  train loss:0.18557044863700867,test loss:0.10052717477083206,r:0.2968226879037693
epoch 1 : weight has update
R1 epoch 2 |  train loss:0.022407958284020424,test loss:0.10701939463615417,r:0.29280006689598637
R1 epoch 3 |  train loss:0.021796071901917458,test loss:0.0845072865486145,r:0.3146682379906116
epoch 3 : weight has update
R1 epoch 4 |  train loss:0.021620582789182663,test loss:0.03750017285346985,r:0.30263856895038044
R1 epoch 5 |  train loss:0.02211637794971466,test loss:0.031188203021883965,r:0.2442724142966557
R1 epoch 6 |  train loss:0.020478155463933945,test loss:0.02098214440047741,r:0.19251286873199164
R1 epoch 7 |  train loss:0.02022111415863037,test loss:0.051264967769384384,r:0.3764265114426997
epoch 7 : weight has update
R1 epoch 8 |  train loss:0.019270332530140877,test loss:0.050896868109703064,r:0.16779802871972765
R1 epoch 9 |  train loss:0.01846175640821457,test loss:0.04087389260530472,r:0.4171600006915659
epoch 9 : weight has update
R1 epoch 10 |  train loss:0.017840348184108734,test loss:0.03797850385308266,r:0.45436245367304906
epoch 10 : weight has update
R1 epoch 11 |  train loss:0.016953764483332634,test loss:0.0357675664126873,r:0.42496159745817397
R1 epoch 12 |  train loss:0.016862688586115837,test loss:0.029317844659090042,r:0.41327200055774455
R1 epoch 13 |  train loss:0.01647370494902134,test loss:0.025432711467146873,r:0.5005029531167693
epoch 13 : weight has update
R1 epoch 14 |  train loss:0.016146479174494743,test loss:0.020870391279459,r:0.4942954761636295
R1 epoch 15 |  train loss:0.015521238557994366,test loss:0.02041875198483467,r:0.4726520887797913
R1 epoch 16 |  train loss:0.015277630649507046,test loss:0.021068980917334557,r:0.4394918225299358
R1 epoch 17 |  train loss:0.014942953363060951,test loss:0.015446814708411694,r:0.5236355993718158
epoch 17 : weight has update
R1 epoch 18 |  train loss:0.014819723553955555,test loss:0.015753962099552155,r:0.5215210839186432
R1 epoch 19 |  train loss:0.01484266109764576,test loss:0.016121936962008476,r:0.5238919633519916
epoch 19 : weight has update
R1 epoch 20 |  train loss:0.014442781917750835,test loss:0.015378306619822979,r:0.5260097267588357
epoch 20 : weight has update
R1 epoch 21 |  train loss:0.014513210393488407,test loss:0.018487760797142982,r:0.5313005160501157
epoch 21 : weight has update
R1 epoch 22 |  train loss:0.014342404901981354,test loss:0.01635361649096012,r:0.5253275947235281
R1 epoch 23 |  train loss:0.014033080078661442,test loss:0.014706161804497242,r:0.544050865141092
epoch 23 : weight has update
R1 epoch 24 |  train loss:0.01402612030506134,test loss:0.018241267651319504,r:0.5116677598210784
R1 epoch 25 |  train loss:0.014042257331311703,test loss:0.016155101358890533,r:0.5306581580400573
R1 epoch 26 |  train loss:0.013764281757175922,test loss:0.015879502519965172,r:0.5185875665640266
R1 epoch 27 |  train loss:0.014078452251851559,test loss:0.016718728467822075,r:0.5446093612845444
epoch 27 : weight has update
R1 epoch 28 |  train loss:0.013929706998169422,test loss:0.015390233136713505,r:0.5303160778221446
R1 epoch 29 |  train loss:0.014548243954777718,test loss:0.015368536114692688,r:0.5367653873941889
R1 epoch 30 |  train loss:0.014152474701404572,test loss:0.015800708904862404,r:0.5186267905592308
R1 epoch 31 |  train loss:0.014050495810806751,test loss:0.014812075532972813,r:0.5374550089986749
R1 epoch 32 |  train loss:0.013806539587676525,test loss:0.01540446002036333,r:0.5555224485491419
epoch 32 : weight has update
R1 epoch 33 |  train loss:0.014097091741859913,test loss:0.016660476103425026,r:0.5402052973932242
R1 epoch 34 |  train loss:0.013838440179824829,test loss:0.01580558903515339,r:0.5154132951071898
R1 epoch 35 |  train loss:0.014025786891579628,test loss:0.014624057337641716,r:0.5519093267535619
R1 epoch 36 |  train loss:0.01367809809744358,test loss:0.014635035768151283,r:0.5427348331751471
R1 epoch 37 |  train loss:0.013869763351976871,test loss:0.01807429827749729,r:0.4947777082508063
R1 epoch 38 |  train loss:0.01370224915444851,test loss:0.015190892852842808,r:0.5403241535867227
R1 epoch 39 |  train loss:0.013521558605134487,test loss:0.018167372792959213,r:0.5004271291143509
R1 epoch 40 |  train loss:0.013463418930768967,test loss:0.015178176574409008,r:0.5509333546700809
R1 epoch 41 |  train loss:0.013199886307120323,test loss:0.014653096906840801,r:0.550038607183164
R1 epoch 42 |  train loss:0.013090387918055058,test loss:0.014810199849307537,r:0.5426754735562023
R1 epoch 43 |  train loss:0.012667924165725708,test loss:0.014347027987241745,r:0.5542126367403604
R1 epoch 44 |  train loss:0.01279893983155489,test loss:0.014957539737224579,r:0.5603255532465158
epoch 44 : weight has update
R1 epoch 45 |  train loss:0.012809495441615582,test loss:0.014014730229973793,r:0.567867335534839
epoch 45 : weight has update
R1 epoch 46 |  train loss:0.012541770935058594,test loss:0.014318295754492283,r:0.5545726583940987
R1 epoch 47 |  train loss:0.012495939619839191,test loss:0.015406700782477856,r:0.5623255520208915
R1 epoch 48 |  train loss:0.012365905568003654,test loss:0.014507624320685863,r:0.570411638241584
epoch 48 : weight has update
R1 epoch 49 |  train loss:0.012392674572765827,test loss:0.015057843178510666,r:0.5668030937856584
R1 epoch 50 |  train loss:0.011919244192540646,test loss:0.014592218212783337,r:0.5641488266420408
R1 epoch 51 |  train loss:0.011810896918177605,test loss:0.01607082225382328,r:0.5668324103003378
R1 epoch 52 |  train loss:0.011801118031144142,test loss:0.014442026615142822,r:0.5779013861351147
epoch 52 : weight has update
R1 epoch 53 |  train loss:0.011734937317669392,test loss:0.01450298260897398,r:0.5637614087190057
R1 epoch 54 |  train loss:0.011723126284778118,test loss:0.014456527307629585,r:0.5722740740299198
R1 epoch 55 |  train loss:0.01156462263315916,test loss:0.01430165208876133,r:0.5746516039519689
R1 epoch 56 |  train loss:0.011546867899596691,test loss:0.01859680935740471,r:0.5714773646591974
R1 epoch 57 |  train loss:0.01147859450429678,test loss:0.015062540769577026,r:0.5728400896642678
R1 epoch 58 |  train loss:0.011392292566597462,test loss:0.014613097533583641,r:0.5589232786409284
R1 epoch 59 |  train loss:0.010998506098985672,test loss:0.016389483585953712,r:0.5738363240762212
R1 epoch 60 |  train loss:0.010917061008512974,test loss:0.013956406153738499,r:0.5780386692951691
epoch 60 : weight has update
R1 epoch 61 |  train loss:0.011065075173974037,test loss:0.014472505077719688,r:0.5665450227650076
R1 epoch 62 |  train loss:0.011015864089131355,test loss:0.01673910766839981,r:0.5777538505566674
R1 epoch 63 |  train loss:0.010937257669866085,test loss:0.015552878379821777,r:0.5784688484428707
epoch 63 : weight has update
R1 epoch 64 |  train loss:0.010809510014951229,test loss:0.014370373450219631,r:0.5732383608943078
R1 epoch 65 |  train loss:0.01081255916506052,test loss:0.015415558591485023,r:0.5778446487803526
R1 epoch 66 |  train loss:0.01106063649058342,test loss:0.015390031039714813,r:0.5770335121611014
R1 epoch 67 |  train loss:0.01052409689873457,test loss:0.015078775584697723,r:0.5725480863177812
R1 epoch 68 |  train loss:0.010496003553271294,test loss:0.017431264743208885,r:0.5719552184636155
R1 epoch 69 |  train loss:0.01060394011437893,test loss:0.014757794328033924,r:0.5836137265784714
epoch 69 : weight has update
R1 epoch 70 |  train loss:0.01050714123994112,test loss:0.014468429610133171,r:0.5747555342255656
R1 epoch 71 |  train loss:0.010210756212472916,test loss:0.015368337742984295,r:0.5804174989530568
R1 epoch 72 |  train loss:0.010399404913187027,test loss:0.015610001981258392,r:0.578712287525491
R1 epoch 73 |  train loss:0.010182850994169712,test loss:0.014963329769670963,r:0.5765517112979822
R1 epoch 74 |  train loss:0.010221259668469429,test loss:0.014402052387595177,r:0.5835225512376926
R1 epoch 75 |  train loss:0.01028435118496418,test loss:0.013795417733490467,r:0.575995810687745
R1 epoch 76 |  train loss:0.010248014703392982,test loss:0.014062237925827503,r:0.575454241525255
R1 epoch 77 |  train loss:0.010132880881428719,test loss:0.014926125295460224,r:0.5773361410640638
R1 epoch 78 |  train loss:0.009880932979285717,test loss:0.016113681718707085,r:0.5755551094969485
R1 epoch 79 |  train loss:0.01003433670848608,test loss:0.015123817138373852,r:0.5818561065101365
R1 epoch 80 |  train loss:0.009880473837256432,test loss:0.013828866183757782,r:0.5805470436226797
R1 epoch 81 |  train loss:0.01000863779336214,test loss:0.01486758142709732,r:0.5732752166521694
R1 epoch 82 |  train loss:0.009840757586061954,test loss:0.014636985957622528,r:0.5752737478815407
R1 epoch 83 |  train loss:0.009978908114135265,test loss:0.015225770883262157,r:0.5850415302961988
epoch 83 : weight has update
R1 epoch 84 |  train loss:0.009940147399902344,test loss:0.013616540469229221,r:0.5836165177603394
R1 epoch 85 |  train loss:0.00968372356146574,test loss:0.014621912501752377,r:0.5814099177416693
R1 epoch 86 |  train loss:0.009666796773672104,test loss:0.014220177195966244,r:0.5805179345703059
R1 epoch 87 |  train loss:0.009873594157397747,test loss:0.013926933519542217,r:0.5877704226747882
epoch 87 : weight has update
R1 epoch 88 |  train loss:0.009717167355120182,test loss:0.01623571291565895,r:0.5840971297654955
R1 epoch 89 |  train loss:0.00979255698621273,test loss:0.015266300179064274,r:0.5833615565932756
R1 epoch 90 |  train loss:0.00958356074988842,test loss:0.015208611264824867,r:0.583372235892579
R1 epoch 91 |  train loss:0.009716023690998554,test loss:0.015433703549206257,r:0.5777541769880344
R1 epoch 92 |  train loss:0.009378170594573021,test loss:0.014147067442536354,r:0.5795670607985969
R1 epoch 93 |  train loss:0.009475357830524445,test loss:0.016957705840468407,r:0.5862213102334933
R1 epoch 94 |  train loss:0.00945084635168314,test loss:0.014489434659481049,r:0.5733298723135304
R1 epoch 95 |  train loss:0.009829249233007431,test loss:0.015769626945257187,r:0.5775582753174899
R1 epoch 96 |  train loss:0.009568949230015278,test loss:0.014427782036364079,r:0.5750020591828261
R1 epoch 97 |  train loss:0.009739767760038376,test loss:0.014251469634473324,r:0.5785721022270647
R1 epoch 98 |  train loss:0.009422152303159237,test loss:0.014635084196925163,r:0.5800853363979979
R1 epoch 99 |  train loss:0.009592978283762932,test loss:0.0158750731498003,r:0.5791162541660428
R1 epoch 100 |  train loss:0.009214201010763645,test loss:0.015288327820599079,r:0.5656007839386661
R1 epoch 101 |  train loss:0.009358054026961327,test loss:0.01556315366178751,r:0.5776730202736303
R1 epoch 102 |  train loss:0.009309102781116962,test loss:0.014167848974466324,r:0.5657162131183903
R1 epoch 103 |  train loss:0.009535751305520535,test loss:0.016035033389925957,r:0.569059708302871
R1 epoch 104 |  train loss:0.009537589736282825,test loss:0.015098181553184986,r:0.563358309101915
R1 epoch 105 |  train loss:0.00931872334331274,test loss:0.016354944556951523,r:0.5750886527617255
R1 epoch 106 |  train loss:0.009400137700140476,test loss:0.014855950139462948,r:0.5766560982581064
R1 epoch 107 |  train loss:0.009270410984754562,test loss:0.014206718653440475,r:0.5791537090990011
R1 epoch 108 |  train loss:0.009136686101555824,test loss:0.013883931562304497,r:0.5743783207516667
R1 epoch 109 |  train loss:0.009145206771790981,test loss:0.015077181160449982,r:0.5842978694594401
R1 epoch 110 |  train loss:0.009166442789137363,test loss:0.014755455777049065,r:0.5818847071562229
R1 epoch 111 |  train loss:0.008751467801630497,test loss:0.014209775254130363,r:0.5813555157449969
R1 epoch 112 |  train loss:0.009093360975384712,test loss:0.016600873321294785,r:0.5641772917123385
R1 epoch 113 |  train loss:0.009009741246700287,test loss:0.01491468120366335,r:0.571495316304179
R1 epoch 114 |  train loss:0.009090350940823555,test loss:0.014086962677538395,r:0.572062299847338
R1 epoch 115 |  train loss:0.00909938383847475,test loss:0.014268123544752598,r:0.577580561729447
R1 epoch 116 |  train loss:0.009143825620412827,test loss:0.0137113556265831,r:0.5812441620347348
R1 epoch 117 |  train loss:0.00925589632242918,test loss:0.014655509032309055,r:0.5809657543944923
R1 epoch 118 |  train loss:0.009205835871398449,test loss:0.014115400612354279,r:0.5672373040705505
R1 epoch 119 |  train loss:0.009416693821549416,test loss:0.014431528747081757,r:0.5749546912713308
R1 epoch 120 |  train loss:0.00891316682100296,test loss:0.015545102767646313,r:0.578030769498253
R1 epoch 121 |  train loss:0.00944886077195406,test loss:0.01453161146491766,r:0.5684796406576766
R1 epoch 122 |  train loss:0.00904780626296997,test loss:0.015989158302545547,r:0.5781512884765762
R1 epoch 123 |  train loss:0.008952267467975616,test loss:0.015141560696065426,r:0.5613133264154596
R1 epoch 124 |  train loss:0.008811824023723602,test loss:0.01435768511146307,r:0.5724538004148425
R1 epoch 125 |  train loss:0.008932579308748245,test loss:0.014441655948758125,r:0.5828930612089622
R1 epoch 126 |  train loss:0.0087294802069664,test loss:0.014107992872595787,r:0.5732082059832428
R1 epoch 127 |  train loss:0.00885711144655943,test loss:0.014486088417470455,r:0.5737953441321093
R1 epoch 128 |  train loss:0.008655073121190071,test loss:0.014143229462206364,r:0.562859375004515
R1 epoch 129 |  train loss:0.008740637451410294,test loss:0.014288353733718395,r:0.5754488978349555
R1 epoch 130 |  train loss:0.008909541182219982,test loss:0.013920881785452366,r:0.5787464774614627
R1 epoch 131 |  train loss:0.008818302303552628,test loss:0.014823926612734795,r:0.5511662327680663
R1 epoch 132 |  train loss:0.008728454820811749,test loss:0.014897206798195839,r:0.5726084450487168
R1 epoch 133 |  train loss:0.00877011101692915,test loss:0.015011732466518879,r:0.5762004370276298
R1 epoch 134 |  train loss:0.008608849719166756,test loss:0.014183742925524712,r:0.578040202194373
R1 epoch 135 |  train loss:0.008694743737578392,test loss:0.014590238220989704,r:0.5782176717594296
R1 epoch 136 |  train loss:0.008617647923529148,test loss:0.014303885400295258,r:0.5698569956179813
R1 epoch 137 |  train loss:0.008823015727102757,test loss:0.014385338872671127,r:0.5772157858786329
R1 epoch 138 |  train loss:0.008758937008678913,test loss:0.014197426848113537,r:0.5661459025965814
R1 epoch 139 |  train loss:0.008930007927119732,test loss:0.013723785988986492,r:0.5799950154343949
R1 epoch 140 |  train loss:0.008597631938755512,test loss:0.013850863091647625,r:0.5798990248383424
R1 epoch 141 |  train loss:0.008739915676414967,test loss:0.015107638202607632,r:0.5714329715029964
R1 epoch 142 |  train loss:0.008863955736160278,test loss:0.014333799481391907,r:0.5627522545242967
R1 epoch 143 |  train loss:0.008446083404123783,test loss:0.014828135259449482,r:0.5604278150299244
R1 epoch 144 |  train loss:0.008668681606650352,test loss:0.014714447781443596,r:0.5736838490461238
R1 epoch 145 |  train loss:0.008673720993101597,test loss:0.014686927199363708,r:0.569034556505292
R1 epoch 146 |  train loss:0.008776726201176643,test loss:0.014560745097696781,r:0.5697967022910237
R1 epoch 147 |  train loss:0.008889720775187016,test loss:0.014058690518140793,r:0.5737981315118196
R1 epoch 148 |  train loss:0.00838528759777546,test loss:0.015905173495411873,r:0.572017348635145
R1 epoch 149 |  train loss:0.008658348582684994,test loss:0.01433775294572115,r:0.5676977994463541
R1 epoch 150 |  train loss:0.008596379309892654,test loss:0.01409179624170065,r:0.5679630001092499
training has finished used time : 8477.143856048584
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (16672, 14)
5000
10614
df shape (20087, 42195)
shape train_df pos (32032, 20087)
shape train_df sample (5000, 32032)
(5000, 32032) (10614, 32032)
train dataset already completed!
5000
test dataset already completed!
10614
R8 epoch 1 |  train loss:0.2805529534816742,test loss:0.13181208074092865,r:0.13831447122925172
epoch 1 : weight has update
R8 epoch 2 |  train loss:0.08482261747121811,test loss:0.17656859755516052,r:0.20340359283181278
epoch 2 : weight has update
R8 epoch 3 |  train loss:0.0832102969288826,test loss:0.09266790747642517,r:0.22117910417418207
epoch 3 : weight has update
R8 epoch 4 |  train loss:0.08203500509262085,test loss:0.3815373480319977,r:0.2183411626788294
R8 epoch 5 |  train loss:0.07915877550840378,test loss:0.42619800567626953,r:0.25105992074463257
epoch 5 : weight has update
R8 epoch 6 |  train loss:0.08124319463968277,test loss:0.19615383446216583,r:0.2532362175236593
epoch 6 : weight has update
R8 epoch 7 |  train loss:0.07910046726465225,test loss:0.12248312681913376,r:0.24568663925096362
R8 epoch 8 |  train loss:0.07793394476175308,test loss:0.6976470351219177,r:0.2801867044599025
epoch 8 : weight has update
R8 epoch 9 |  train loss:0.07727520167827606,test loss:0.7608173489570618,r:0.3009170466005643
epoch 9 : weight has update
R8 epoch 10 |  train loss:0.07447556406259537,test loss:0.23734892904758453,r:0.3147360241795177
epoch 10 : weight has update
R8 epoch 11 |  train loss:0.07381948083639145,test loss:0.14555266499519348,r:0.33651868852265304
epoch 11 : weight has update
R8 epoch 12 |  train loss:0.07216773927211761,test loss:0.11894666403532028,r:0.3468741688541827
epoch 12 : weight has update
R8 epoch 13 |  train loss:0.07029447704553604,test loss:0.19952139258384705,r:0.3462097214733655
R8 epoch 14 |  train loss:0.06999348849058151,test loss:0.16865801811218262,r:0.3772018662854435
epoch 14 : weight has update
R8 epoch 15 |  train loss:0.06903810799121857,test loss:0.09706993401050568,r:0.36965021900422346
R8 epoch 16 |  train loss:0.0675974190235138,test loss:0.07305826991796494,r:0.35594997013830265
R8 epoch 17 |  train loss:0.066620372235775,test loss:0.06501831114292145,r:0.3814656332965303
epoch 17 : weight has update
R8 epoch 18 |  train loss:0.06611569970846176,test loss:0.06679250299930573,r:0.3921949997765244
epoch 18 : weight has update
R8 epoch 19 |  train loss:0.06573695689439774,test loss:0.07025091350078583,r:0.3924037863072772
epoch 19 : weight has update
R8 epoch 20 |  train loss:0.06305970251560211,test loss:0.07718510925769806,r:0.40136832327796
epoch 20 : weight has update
R8 epoch 21 |  train loss:0.0632668063044548,test loss:0.09470297396183014,r:0.3947845774517839
R8 epoch 22 |  train loss:0.0622989647090435,test loss:0.06779327988624573,r:0.4013981533333086
epoch 22 : weight has update
R8 epoch 23 |  train loss:0.06161807104945183,test loss:0.06944679468870163,r:0.3115276150620263
R8 epoch 24 |  train loss:0.061358287930488586,test loss:0.07225199043750763,r:0.41076781660138106
epoch 24 : weight has update
R8 epoch 25 |  train loss:0.0602879635989666,test loss:0.2101048231124878,r:0.3832795252110148
R8 epoch 26 |  train loss:0.05940425768494606,test loss:0.08744646608829498,r:0.4006902580266125
R8 epoch 27 |  train loss:0.05834316834807396,test loss:0.06650879979133606,r:0.3690352415998762
R8 epoch 28 |  train loss:0.059970587491989136,test loss:0.1150413379073143,r:0.4050127337311527
R8 epoch 29 |  train loss:0.05862691253423691,test loss:0.0661378726363182,r:0.39717436147833574
R8 epoch 30 |  train loss:0.05806933715939522,test loss:0.06455326825380325,r:0.4045389749760016
R8 epoch 31 |  train loss:0.057399049401283264,test loss:0.0660458505153656,r:0.4024907420340082
R8 epoch 32 |  train loss:0.05553920567035675,test loss:0.06321168690919876,r:0.42685402434664865
epoch 32 : weight has update
R8 epoch 33 |  train loss:0.05618378147482872,test loss:0.07339329272508621,r:0.41247253161589503
R8 epoch 34 |  train loss:0.05700035020709038,test loss:0.06617429107427597,r:0.41388073267799874
R8 epoch 35 |  train loss:0.05586733669042587,test loss:0.06884623318910599,r:0.42247011785301186
R8 epoch 36 |  train loss:0.055430248379707336,test loss:0.08134514093399048,r:0.4287317199103763
epoch 36 : weight has update
R8 epoch 37 |  train loss:0.05376369506120682,test loss:0.134440079331398,r:0.43898864241053887
epoch 37 : weight has update
R8 epoch 38 |  train loss:0.0525272898375988,test loss:0.0762016549706459,r:0.43074101878937127
R8 epoch 39 |  train loss:0.051317695528268814,test loss:0.06756412982940674,r:0.42826505709271756
R8 epoch 40 |  train loss:0.051625967025756836,test loss:0.06518582999706268,r:0.42652380490907205
R8 epoch 41 |  train loss:0.051419973373413086,test loss:0.07490813732147217,r:0.4231112755699067
R8 epoch 42 |  train loss:0.05107932537794113,test loss:0.0624605193734169,r:0.4239024768269302
R8 epoch 43 |  train loss:0.05062616989016533,test loss:0.06381388008594513,r:0.4408697951335332
epoch 43 : weight has update
R8 epoch 44 |  train loss:0.049284547567367554,test loss:0.07943417131900787,r:0.43250731003634796
R8 epoch 45 |  train loss:0.049128759652376175,test loss:0.06565651297569275,r:0.4312483632069817
R8 epoch 46 |  train loss:0.048698198050260544,test loss:0.06379536539316177,r:0.4424875727374037
epoch 46 : weight has update
R8 epoch 47 |  train loss:0.04880984127521515,test loss:0.09306684881448746,r:0.43109310564375475
R8 epoch 48 |  train loss:0.04697534069418907,test loss:0.06394518166780472,r:0.4349562837629968
R8 epoch 49 |  train loss:0.04680376499891281,test loss:0.06801097840070724,r:0.4332064392956844
R8 epoch 50 |  train loss:0.04763263836503029,test loss:0.06663096696138382,r:0.44069674137900616
R8 epoch 51 |  train loss:0.045287687331438065,test loss:0.06865136325359344,r:0.44971902410488307
epoch 51 : weight has update
R8 epoch 52 |  train loss:0.045600149780511856,test loss:0.06451118737459183,r:0.43553755771084257
R8 epoch 53 |  train loss:0.04516597464680672,test loss:0.06207352131605148,r:0.44848480587285283
R8 epoch 54 |  train loss:0.04596996679902077,test loss:0.06374602019786835,r:0.4529077005145372
epoch 54 : weight has update
R8 epoch 55 |  train loss:0.04399724677205086,test loss:0.06715108454227448,r:0.4449520218881748
R8 epoch 56 |  train loss:0.044935207813978195,test loss:0.07504227012395859,r:0.4294092394262863
R8 epoch 57 |  train loss:0.04340272396802902,test loss:0.07888833433389664,r:0.4362214565818779
R8 epoch 58 |  train loss:0.043337754905223846,test loss:0.08071717619895935,r:0.41238403878977703
R8 epoch 59 |  train loss:0.04275709018111229,test loss:0.06960959732532501,r:0.4275283161464011
R8 epoch 60 |  train loss:0.04185973107814789,test loss:0.07018125057220459,r:0.43730021274446274
R8 epoch 61 |  train loss:0.04056452214717865,test loss:0.0715218260884285,r:0.4415398889787938
R8 epoch 62 |  train loss:0.04103577882051468,test loss:0.07033076137304306,r:0.42464619157096867
R8 epoch 63 |  train loss:0.03956175968050957,test loss:0.07574158906936646,r:0.42644642410339983
R8 epoch 64 |  train loss:0.04096715897321701,test loss:0.06712603569030762,r:0.4490107321030176
R8 epoch 65 |  train loss:0.04180962219834328,test loss:0.06689729541540146,r:0.44835393707135524
R8 epoch 66 |  train loss:0.04099414125084877,test loss:0.06700561940670013,r:0.4387263706393242
R8 epoch 67 |  train loss:0.0390670970082283,test loss:0.08812499791383743,r:0.43253254656865014
R8 epoch 68 |  train loss:0.039257634431123734,test loss:0.06504250317811966,r:0.43837278221300324
R8 epoch 69 |  train loss:0.040122777223587036,test loss:0.06350556761026382,r:0.43306841405462926
R8 epoch 70 |  train loss:0.039380595088005066,test loss:0.06989187747240067,r:0.44210734493641046
R8 epoch 71 |  train loss:0.039868731051683426,test loss:0.07638273388147354,r:0.43173567422562936
R8 epoch 72 |  train loss:0.03806997090578079,test loss:0.07302898168563843,r:0.43788808558749015
R8 epoch 73 |  train loss:0.03828888759016991,test loss:0.07022880762815475,r:0.4460530639773094
R8 epoch 74 |  train loss:0.038687001913785934,test loss:0.06430709362030029,r:0.4422211125851441
R8 epoch 75 |  train loss:0.03865402191877365,test loss:0.0662565529346466,r:0.43997489348526586
R8 epoch 76 |  train loss:0.039010509848594666,test loss:0.06674934178590775,r:0.4384863430214747
R8 epoch 77 |  train loss:0.037112560123205185,test loss:0.07722798734903336,r:0.43862921161960283
R8 epoch 78 |  train loss:0.03905778005719185,test loss:0.07078167796134949,r:0.43869137833811783
R8 epoch 79 |  train loss:0.03728030249476433,test loss:0.07179214805364609,r:0.4392586070107907
R8 epoch 80 |  train loss:0.0365186408162117,test loss:0.06562058627605438,r:0.4435447912863636
R8 epoch 81 |  train loss:0.038310758769512177,test loss:0.07342980057001114,r:0.42653986367681296
R8 epoch 82 |  train loss:0.03747483342885971,test loss:0.06805319339036942,r:0.43928803981120285
R8 epoch 83 |  train loss:0.03538808226585388,test loss:0.07485352456569672,r:0.41844980336259224
R8 epoch 84 |  train loss:0.03736023232340813,test loss:0.07400091737508774,r:0.42354937181091
R8 epoch 85 |  train loss:0.03737032786011696,test loss:0.08584534376859665,r:0.4242569681981173
R8 epoch 86 |  train loss:0.03634883090853691,test loss:0.06941289454698563,r:0.4318350783047881
R8 epoch 87 |  train loss:0.035665903240442276,test loss:0.07403885573148727,r:0.430764141909889
R8 epoch 88 |  train loss:0.035752635449171066,test loss:0.0701509416103363,r:0.4409967158456517
R8 epoch 89 |  train loss:0.03684372454881668,test loss:0.0763644352555275,r:0.42672474510341585
R8 epoch 90 |  train loss:0.03604383394122124,test loss:0.07058105617761612,r:0.43387922615553687
R8 epoch 91 |  train loss:0.035576436668634415,test loss:0.07333727926015854,r:0.43576783470110964
R8 epoch 92 |  train loss:0.034523215144872665,test loss:0.06905701011419296,r:0.42400890195282215
R8 epoch 93 |  train loss:0.035831570625305176,test loss:0.08219104260206223,r:0.4336204386650325
R8 epoch 94 |  train loss:0.03728274628520012,test loss:0.08713825047016144,r:0.4241645598060308
R8 epoch 95 |  train loss:0.03481396660208702,test loss:0.07073952257633209,r:0.4315993546111324
R8 epoch 96 |  train loss:0.03505290299654007,test loss:0.07281674444675446,r:0.4325497233380439
R8 epoch 97 |  train loss:0.03430848568677902,test loss:0.08331611007452011,r:0.41416489238287946
R8 epoch 98 |  train loss:0.03487835451960564,test loss:0.06969805061817169,r:0.43461255632089224
R8 epoch 99 |  train loss:0.03322630375623703,test loss:0.0774020329117775,r:0.44092214432363924
R8 epoch 100 |  train loss:0.03397015109658241,test loss:0.08602902293205261,r:0.42887718784161233
R8 epoch 101 |  train loss:0.03417019173502922,test loss:0.07594171166419983,r:0.42990598588101153
R8 epoch 102 |  train loss:0.033836524933576584,test loss:0.07764125615358353,r:0.44464301795763034
R8 epoch 103 |  train loss:0.03344377130270004,test loss:0.0771915540099144,r:0.4085177094601188
R8 epoch 104 |  train loss:0.03477287292480469,test loss:0.07173200696706772,r:0.435966909657707
R8 epoch 105 |  train loss:0.034146588295698166,test loss:0.08243978023529053,r:0.4131785674845292
R8 epoch 106 |  train loss:0.03209182247519493,test loss:0.07179046422243118,r:0.43574699208095136
R8 epoch 107 |  train loss:0.03398853912949562,test loss:0.0793159082531929,r:0.43098226688711977
R8 epoch 108 |  train loss:0.03387957438826561,test loss:0.07546629011631012,r:0.43173636307107455
R8 epoch 109 |  train loss:0.033362410962581635,test loss:0.07257454097270966,r:0.42388977590498855
R8 epoch 110 |  train loss:0.03249605372548103,test loss:0.09211306273937225,r:0.4140523295976137
R8 epoch 111 |  train loss:0.03414223715662956,test loss:0.06451790779829025,r:0.42852361685024787
R8 epoch 112 |  train loss:0.03361602872610092,test loss:0.06950442492961884,r:0.43425432846309664
R8 epoch 113 |  train loss:0.03328635171055794,test loss:0.07789966464042664,r:0.42329389375605453
R8 epoch 114 |  train loss:0.03345397487282753,test loss:0.06520813703536987,r:0.43371876387973035
R8 epoch 115 |  train loss:0.03262794390320778,test loss:0.0696970745921135,r:0.43717039067719643
R8 epoch 116 |  train loss:0.03299018740653992,test loss:0.0670507624745369,r:0.43732660768307874
R8 epoch 117 |  train loss:0.03231352940201759,test loss:0.0894654244184494,r:0.4300801805569666
R8 epoch 118 |  train loss:0.032904382795095444,test loss:0.08087700605392456,r:0.4237047051153063
R8 epoch 119 |  train loss:0.033226534724235535,test loss:0.07374753803014755,r:0.4313998838432662
R8 epoch 120 |  train loss:0.03372865542769432,test loss:0.0915466845035553,r:0.40271553959934614
R8 epoch 121 |  train loss:0.033533625304698944,test loss:0.08246965706348419,r:0.4200060613608934
R8 epoch 122 |  train loss:0.03217564523220062,test loss:0.07475803047418594,r:0.4153963260089595
R8 epoch 123 |  train loss:0.031767699867486954,test loss:0.06742127239704132,r:0.44200844630284647
R8 epoch 124 |  train loss:0.03150397166609764,test loss:0.0644972175359726,r:0.42624361361597146
R8 epoch 125 |  train loss:0.033255334943532944,test loss:0.0704236626625061,r:0.4359702211637052
R8 epoch 126 |  train loss:0.03212064132094383,test loss:0.09597593545913696,r:0.4186462824925653
R8 epoch 127 |  train loss:0.033157527446746826,test loss:0.07577154040336609,r:0.4219778430789037
R8 epoch 128 |  train loss:0.03145574778318405,test loss:0.07453081011772156,r:0.4297617055550085
R8 epoch 129 |  train loss:0.03188924118876457,test loss:0.07089616358280182,r:0.4322566834635523
R8 epoch 130 |  train loss:0.03305032476782799,test loss:0.07284464687108994,r:0.43135368024231113
R8 epoch 131 |  train loss:0.032741330564022064,test loss:0.06984937936067581,r:0.4239975532110207
R8 epoch 132 |  train loss:0.031340811401605606,test loss:0.07328681647777557,r:0.42574252625444026
R8 epoch 133 |  train loss:0.03233372047543526,test loss:0.07625044137239456,r:0.42874847942134614
R8 epoch 134 |  train loss:0.031037984415888786,test loss:0.07015746831893921,r:0.42036146677624237
R8 epoch 135 |  train loss:0.03126600757241249,test loss:0.0711670070886612,r:0.42184703156151687
R8 epoch 136 |  train loss:0.033454883843660355,test loss:0.06597771495580673,r:0.4322689403123038
R8 epoch 137 |  train loss:0.03168715536594391,test loss:0.07356543838977814,r:0.42784811242461657
R8 epoch 138 |  train loss:0.032150205224752426,test loss:0.08017299324274063,r:0.428006849223318
R8 epoch 139 |  train loss:0.03154103830456734,test loss:0.07586169242858887,r:0.4131065446140135
R8 epoch 140 |  train loss:0.03048780933022499,test loss:0.09441998600959778,r:0.39745316038617357
R8 epoch 141 |  train loss:0.03166218474507332,test loss:0.0794399231672287,r:0.3946882778485194
R8 epoch 142 |  train loss:0.03056614100933075,test loss:0.07787064462900162,r:0.4227485804266805
R8 epoch 143 |  train loss:0.03189373388886452,test loss:0.08460909873247147,r:0.42973585634965167
R8 epoch 144 |  train loss:0.03085661120712757,test loss:0.07825017720460892,r:0.43187185581917015
R8 epoch 145 |  train loss:0.030999338254332542,test loss:0.08101069182157516,r:0.4254003672563561
R8 epoch 146 |  train loss:0.03140430152416229,test loss:0.07254648953676224,r:0.4209287012516081
R8 epoch 147 |  train loss:0.03158712014555931,test loss:0.0759587287902832,r:0.42945363780941753
R8 epoch 148 |  train loss:0.03107934445142746,test loss:0.0838610902428627,r:0.42513979329315643
R8 epoch 149 |  train loss:0.031664151698350906,test loss:0.07992418855428696,r:0.4256735821010029
R8 epoch 150 |  train loss:0.031207019463181496,test loss:0.07636276632547379,r:0.4261676220703741
training has finished used time : 8639.650752067566
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (15765, 14)
5000
10765
df shape (20087, 42195)
shape train_df pos (32032, 20087)
shape train_df sample (5000, 32032)
(5000, 32032) (10765, 32032)
train dataset already completed!
5000
test dataset already completed!
10765
Hgt epoch 1 |  train loss:0.10421552509069443,test loss:0.009517130441963673,r:0.28625551004673283
epoch 1 : weight has update
Hgt epoch 2 |  train loss:0.010927231051027775,test loss:0.017914626747369766,r:0.47000168374191775
epoch 2 : weight has update
Hgt epoch 3 |  train loss:0.010566510260105133,test loss:0.02885846234858036,r:0.4896263524649545
epoch 3 : weight has update
Hgt epoch 4 |  train loss:0.010330237448215485,test loss:0.02572830766439438,r:0.5304903761995807
epoch 4 : weight has update
Hgt epoch 5 |  train loss:0.009911821223795414,test loss:0.015118669718503952,r:0.5478239330724891
epoch 5 : weight has update
Hgt epoch 6 |  train loss:0.009548097848892212,test loss:0.011937975883483887,r:0.5694277530960191
epoch 6 : weight has update
Hgt epoch 7 |  train loss:0.009212628938257694,test loss:0.07186787575483322,r:0.5851693152337022
epoch 7 : weight has update
Hgt epoch 8 |  train loss:0.008821994997560978,test loss:0.025126531720161438,r:0.5934642529619308
epoch 8 : weight has update
Hgt epoch 9 |  train loss:0.007963603362441063,test loss:0.09542088955640793,r:0.5897506860503656
Hgt epoch 10 |  train loss:0.007200584281235933,test loss:0.23970511555671692,r:0.5989257236267153
epoch 10 : weight has update
Hgt epoch 11 |  train loss:0.006745410151779652,test loss:0.010865841060876846,r:0.5677945718728117
Hgt epoch 12 |  train loss:0.00657332269474864,test loss:0.029723703861236572,r:0.5674505485421006
Hgt epoch 13 |  train loss:0.006329897791147232,test loss:0.010667513124644756,r:0.579880277396421
Hgt epoch 14 |  train loss:0.006112268660217524,test loss:0.009377779439091682,r:0.5779208353237569
Hgt epoch 15 |  train loss:0.005988802295178175,test loss:0.009315893054008484,r:0.587932689774722
Hgt epoch 16 |  train loss:0.00572750810533762,test loss:0.00929604284465313,r:0.6158320741991049
epoch 16 : weight has update
Hgt epoch 17 |  train loss:0.005699836649000645,test loss:0.009039616212248802,r:0.6156293809038448
Hgt epoch 18 |  train loss:0.005409077275544405,test loss:0.007714747451245785,r:0.6291192944483394
epoch 18 : weight has update
Hgt epoch 19 |  train loss:0.005319896154105663,test loss:0.008852855302393436,r:0.6138472074924595
Hgt epoch 20 |  train loss:0.005247434135526419,test loss:0.007825114764273167,r:0.6366805754740614
epoch 20 : weight has update
Hgt epoch 21 |  train loss:0.0049906764179468155,test loss:0.007607316132634878,r:0.6624980197332315
epoch 21 : weight has update
Hgt epoch 22 |  train loss:0.004985492210835218,test loss:0.005409924779087305,r:0.6755296063283456
epoch 22 : weight has update
Hgt epoch 23 |  train loss:0.0049172211438417435,test loss:0.007420239970088005,r:0.6820887612539241
epoch 23 : weight has update
Hgt epoch 24 |  train loss:0.004846404306590557,test loss:0.0061562564224004745,r:0.657499724975268
Hgt epoch 25 |  train loss:0.0048574525862932205,test loss:0.005142797715961933,r:0.6803286290340552
Hgt epoch 26 |  train loss:0.00491394754499197,test loss:0.005524701904505491,r:0.664381104743057
Hgt epoch 27 |  train loss:0.004850247409194708,test loss:0.006921623833477497,r:0.6935858019548893
epoch 27 : weight has update
Hgt epoch 28 |  train loss:0.00492394994944334,test loss:0.005694890394806862,r:0.6739794180922714
Hgt epoch 29 |  train loss:0.005048295017331839,test loss:0.005346245598047972,r:0.6710461221420398
Hgt epoch 30 |  train loss:0.005137506872415543,test loss:0.005117311608046293,r:0.6912552686551057
Hgt epoch 31 |  train loss:0.005062739364802837,test loss:0.005334161687642336,r:0.6781149583977862
Hgt epoch 32 |  train loss:0.005063195247203112,test loss:0.006769133731722832,r:0.6773412769149071
Hgt epoch 33 |  train loss:0.005069688428193331,test loss:0.005922763142734766,r:0.6993491526446577
epoch 33 : weight has update
Hgt epoch 34 |  train loss:0.004852418787777424,test loss:0.005085578188300133,r:0.7023775072236359
epoch 34 : weight has update
Hgt epoch 35 |  train loss:0.0051659788005054,test loss:0.00968015007674694,r:0.7004622876160678
Hgt epoch 36 |  train loss:0.004949555732309818,test loss:0.005275904666632414,r:0.7001365676381298
Hgt epoch 37 |  train loss:0.004804279189556837,test loss:0.005017909687012434,r:0.688840117884994
Hgt epoch 38 |  train loss:0.00491434196010232,test loss:0.005437443498522043,r:0.6945341473136779
Hgt epoch 39 |  train loss:0.004872160032391548,test loss:0.0051782820373773575,r:0.7101737439930841
epoch 39 : weight has update
Hgt epoch 40 |  train loss:0.004810959100723267,test loss:0.005376667249947786,r:0.6896631342859254
Hgt epoch 41 |  train loss:0.0049134413711726665,test loss:0.005463940091431141,r:0.7070426195178512
Hgt epoch 42 |  train loss:0.00473161693662405,test loss:0.0052686696872115135,r:0.7111982801417628
epoch 42 : weight has update
Hgt epoch 43 |  train loss:0.004682506434619427,test loss:0.004737299866974354,r:0.7099853760053434
Hgt epoch 44 |  train loss:0.004645838867872953,test loss:0.005334571003913879,r:0.696898022906295
Hgt epoch 45 |  train loss:0.004609271418303251,test loss:0.006053967867046595,r:0.7142951424311881
epoch 45 : weight has update
Hgt epoch 46 |  train loss:0.004696357529610395,test loss:0.004730965476483107,r:0.7161134504823924
epoch 46 : weight has update
Hgt epoch 47 |  train loss:0.004620365798473358,test loss:0.005906104110181332,r:0.7180215130767312
epoch 47 : weight has update
Hgt epoch 48 |  train loss:0.00454428605735302,test loss:0.005468261428177357,r:0.7186962426885658
epoch 48 : weight has update
Hgt epoch 49 |  train loss:0.0044958400540053844,test loss:0.004564347211271524,r:0.7270337328376392
epoch 49 : weight has update
Hgt epoch 50 |  train loss:0.0044294060207903385,test loss:0.004550036042928696,r:0.725129507680581
Hgt epoch 51 |  train loss:0.0043156445026397705,test loss:0.0052771614864468575,r:0.7175011099361718
Hgt epoch 52 |  train loss:0.004369376692920923,test loss:0.00530841713771224,r:0.7146872205932515
Hgt epoch 53 |  train loss:0.0043426090851426125,test loss:0.004649667534977198,r:0.7230642999924655
Hgt epoch 54 |  train loss:0.004144629463553429,test loss:0.004749855492264032,r:0.7241615748173231
Hgt epoch 55 |  train loss:0.004211457911878824,test loss:0.004563165362924337,r:0.7328282349934147
epoch 55 : weight has update
Hgt epoch 56 |  train loss:0.004162450321018696,test loss:0.005190512165427208,r:0.7159104961681803
Hgt epoch 57 |  train loss:0.004168606363236904,test loss:0.00494212144985795,r:0.7192376928377405
Hgt epoch 58 |  train loss:0.004091721028089523,test loss:0.004945534747093916,r:0.7309700919850796
Hgt epoch 59 |  train loss:0.004121755249798298,test loss:0.004517120774835348,r:0.7283265384113975
Hgt epoch 60 |  train loss:0.004164545796811581,test loss:0.004619421437382698,r:0.7358070625161435
epoch 60 : weight has update
Hgt epoch 61 |  train loss:0.004149355925619602,test loss:0.0046066767536103725,r:0.7246804681509381
Hgt epoch 62 |  train loss:0.004077160265296698,test loss:0.004584276117384434,r:0.7264327244933123
Hgt epoch 63 |  train loss:0.003956352360546589,test loss:0.006288845557719469,r:0.7202150847166443
Hgt epoch 64 |  train loss:0.004117144271731377,test loss:0.004590838216245174,r:0.72634341002738
Hgt epoch 65 |  train loss:0.003907916601747274,test loss:0.004587182309478521,r:0.7280184604697385
Hgt epoch 66 |  train loss:0.003982288762927055,test loss:0.004632764030247927,r:0.7255223343135623
Hgt epoch 67 |  train loss:0.003838582895696163,test loss:0.004504977725446224,r:0.7359392022908202
epoch 67 : weight has update
Hgt epoch 68 |  train loss:0.0038527657743543386,test loss:0.004839099477976561,r:0.732840899098064
Hgt epoch 69 |  train loss:0.0039202128536999226,test loss:0.004471198655664921,r:0.7404889091920058
epoch 69 : weight has update
Hgt epoch 70 |  train loss:0.0037946042139083147,test loss:0.005118022207170725,r:0.7302248580054825
Hgt epoch 71 |  train loss:0.0038067109417170286,test loss:0.004575185943394899,r:0.7220904322965273
Hgt epoch 72 |  train loss:0.0037769577465951443,test loss:0.004563042428344488,r:0.7307251023558828
Hgt epoch 73 |  train loss:0.003822749014943838,test loss:0.004543171264231205,r:0.7323450641858251
Hgt epoch 74 |  train loss:0.003744307439774275,test loss:0.004545369651168585,r:0.730454220350386
Hgt epoch 75 |  train loss:0.0038819178007543087,test loss:0.004537180531769991,r:0.7312452286729729
Hgt epoch 76 |  train loss:0.0038995787035673857,test loss:0.004572734702378511,r:0.7278419484340849
Hgt epoch 77 |  train loss:0.0038594326470047235,test loss:0.004560808651149273,r:0.7357322149257967
Hgt epoch 78 |  train loss:0.0035868326667696238,test loss:0.004495915025472641,r:0.7344884345279998
Hgt epoch 79 |  train loss:0.0037940728943794966,test loss:0.005019072443246841,r:0.7300087860149433
Hgt epoch 80 |  train loss:0.0037467677611857653,test loss:0.004916302859783173,r:0.7329778747427331
Hgt epoch 81 |  train loss:0.003796381177380681,test loss:0.004594392143189907,r:0.7331015785785082
Hgt epoch 82 |  train loss:0.0038197492249310017,test loss:0.004592265002429485,r:0.7399191426230824
Hgt epoch 83 |  train loss:0.0036710125859826803,test loss:0.004619807470589876,r:0.7356326070449958
Hgt epoch 84 |  train loss:0.0036301128566265106,test loss:0.004523467738181353,r:0.7298227661348862
Hgt epoch 85 |  train loss:0.0037396762054413557,test loss:0.0047106253914535046,r:0.7320917329794147
Hgt epoch 86 |  train loss:0.0037960598710924387,test loss:0.004492428619414568,r:0.7373487438703581
Hgt epoch 87 |  train loss:0.0036292735021561384,test loss:0.004507079720497131,r:0.7312524554598863
Hgt epoch 88 |  train loss:0.003682918380945921,test loss:0.004928926005959511,r:0.7409030023045435
epoch 88 : weight has update
Hgt epoch 89 |  train loss:0.003671764163300395,test loss:0.004842190071940422,r:0.7337571359977335
Hgt epoch 90 |  train loss:0.003595728427171707,test loss:0.004791815299540758,r:0.7289602787694253
Hgt epoch 91 |  train loss:0.0036026700399816036,test loss:0.004605207126587629,r:0.7364313244334271
Hgt epoch 92 |  train loss:0.003666133154183626,test loss:0.004781619179993868,r:0.7378285103950141
Hgt epoch 93 |  train loss:0.003497503465041518,test loss:0.004595560021698475,r:0.7343584871610352
Hgt epoch 94 |  train loss:0.003619613591581583,test loss:0.004546680487692356,r:0.7291505030988739
Hgt epoch 95 |  train loss:0.0035435399040579796,test loss:0.004690703470259905,r:0.7322647879047182
Hgt epoch 96 |  train loss:0.003591103944927454,test loss:0.0047438982874155045,r:0.7296354880429596
Hgt epoch 97 |  train loss:0.0036289687268435955,test loss:0.0044740187004208565,r:0.7353798733860053
Hgt epoch 98 |  train loss:0.003603260964155197,test loss:0.005054307170212269,r:0.7387769287826578
Hgt epoch 99 |  train loss:0.003625883487984538,test loss:0.004491440486162901,r:0.7306201452699747
Hgt epoch 100 |  train loss:0.003588438034057617,test loss:0.00463484413921833,r:0.7362954095006844
Hgt epoch 101 |  train loss:0.0035932513419538736,test loss:0.004648943431675434,r:0.7365438939479438
Hgt epoch 102 |  train loss:0.003391758305951953,test loss:0.004517664667218924,r:0.7332513857706344
Hgt epoch 103 |  train loss:0.003470516065135598,test loss:0.00499676913022995,r:0.7161809667219771
Hgt epoch 104 |  train loss:0.003605959005653858,test loss:0.005063632037490606,r:0.7351666807886503
Hgt epoch 105 |  train loss:0.0034960343036800623,test loss:0.004790531937032938,r:0.7292744530608712
Hgt epoch 106 |  train loss:0.0034885078202933073,test loss:0.004922792781144381,r:0.7334909693729417
Hgt epoch 107 |  train loss:0.0036343547981232405,test loss:0.004900889005511999,r:0.731179763122946
Hgt epoch 108 |  train loss:0.0035059519577771425,test loss:0.004569506738334894,r:0.7352219496916045
Hgt epoch 109 |  train loss:0.003431349527090788,test loss:0.00454212399199605,r:0.7390319639803014
Hgt epoch 110 |  train loss:0.0034115505404770374,test loss:0.004727403167635202,r:0.7236327358794221
Hgt epoch 111 |  train loss:0.003540604142472148,test loss:0.004537407774478197,r:0.7343165086698273
Hgt epoch 112 |  train loss:0.003561043180525303,test loss:0.0046280184760689735,r:0.7338911854684474
Hgt epoch 113 |  train loss:0.0035642534494400024,test loss:0.004518847446888685,r:0.7332876048588828
Hgt epoch 114 |  train loss:0.003434200305491686,test loss:0.004673636052757502,r:0.725673476064783
Hgt epoch 115 |  train loss:0.003559697885066271,test loss:0.004549578297883272,r:0.7391592129938015
Hgt epoch 116 |  train loss:0.0034428040962666273,test loss:0.004823864437639713,r:0.7406248250763116
Hgt epoch 117 |  train loss:0.0035344932693988085,test loss:0.004440466873347759,r:0.7398411362206375
Hgt epoch 118 |  train loss:0.00345884938724339,test loss:0.004450298845767975,r:0.7357349204140424
Hgt epoch 119 |  train loss:0.0034348624758422375,test loss:0.0047615645453333855,r:0.7388356123706008
Hgt epoch 120 |  train loss:0.0035596408415585756,test loss:0.004343237727880478,r:0.7404975320801153
Hgt epoch 121 |  train loss:0.0033926910255104303,test loss:0.004419852513819933,r:0.7330203016561085
Hgt epoch 122 |  train loss:0.003524140454828739,test loss:0.004488471429795027,r:0.7337076861621532
Hgt epoch 123 |  train loss:0.0033446447923779488,test loss:0.004751741886138916,r:0.7309006942184556
Hgt epoch 124 |  train loss:0.003447562223300338,test loss:0.004661271348595619,r:0.7374970262129734
Hgt epoch 125 |  train loss:0.00339736370369792,test loss:0.0045639690943062305,r:0.728427224606698
Hgt epoch 126 |  train loss:0.003477405058220029,test loss:0.004823496099561453,r:0.734771651571762
Hgt epoch 127 |  train loss:0.003367719938978553,test loss:0.004420589189976454,r:0.7338983408486663
Hgt epoch 128 |  train loss:0.003404707182198763,test loss:0.004421703051775694,r:0.7350826268272517
Hgt epoch 129 |  train loss:0.0034164809621870518,test loss:0.00475835707038641,r:0.7280539965505668
Hgt epoch 130 |  train loss:0.003419742453843355,test loss:0.00469693960621953,r:0.7283969885649632
Hgt epoch 131 |  train loss:0.0034481477923691273,test loss:0.004474795889109373,r:0.7366501824500438
Hgt epoch 132 |  train loss:0.003416043473407626,test loss:0.004377484321594238,r:0.7386863629953735
Hgt epoch 133 |  train loss:0.0035448537673801184,test loss:0.004629092290997505,r:0.739242178853021
Hgt epoch 134 |  train loss:0.0033668605610728264,test loss:0.004619666375219822,r:0.7337241701225814
Hgt epoch 135 |  train loss:0.0034136229660362005,test loss:0.004781362600624561,r:0.7351944115668444
Hgt epoch 136 |  train loss:0.0034196083433926105,test loss:0.004908775445073843,r:0.7389483127608708
Hgt epoch 137 |  train loss:0.0034088578540831804,test loss:0.004557592328637838,r:0.7340372781889447
Hgt epoch 138 |  train loss:0.003419704269617796,test loss:0.004399079829454422,r:0.7369949986900893
Hgt epoch 139 |  train loss:0.0034635744523257017,test loss:0.004624222405254841,r:0.7380627198758232
Hgt epoch 140 |  train loss:0.0031904152128845453,test loss:0.004584028385579586,r:0.7392353411237078
Hgt epoch 141 |  train loss:0.0033890511840581894,test loss:0.0043549868278205395,r:0.7381631340393028
Hgt epoch 142 |  train loss:0.003309729043394327,test loss:0.004354778677225113,r:0.7374725253970955
Hgt epoch 143 |  train loss:0.0034458336886018515,test loss:0.0045470865443348885,r:0.7308578658038289
Hgt epoch 144 |  train loss:0.0034722427371889353,test loss:0.004674883093684912,r:0.7402540017872509
Hgt epoch 145 |  train loss:0.003370179096236825,test loss:0.005072098225355148,r:0.7397249211241625
Hgt epoch 146 |  train loss:0.0032974272035062313,test loss:0.004398776683956385,r:0.737287256096062
Hgt epoch 147 |  train loss:0.0033838185481727123,test loss:0.004529837053269148,r:0.7386445632939197
Hgt epoch 148 |  train loss:0.0033744238317012787,test loss:0.004616826307028532,r:0.7397135191064795
Hgt epoch 149 |  train loss:0.0033275969326496124,test loss:0.0043496135622262955,r:0.7394960325077884
Hgt epoch 150 |  train loss:0.0034081086050719023,test loss:0.004391033668071032,r:0.7386095746903649
training has finished used time : 9240.583192110062
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (15398, 14)
5000
9306
df shape (20087, 42195)
shape train_df pos (32032, 20087)
shape train_df sample (5000, 32032)
(5000, 32032) (9306, 32032)
train dataset already completed!
5000
test dataset already completed!
9306
Palmitic epoch 1 |  train loss:0.19222120940685272,test loss:0.016142696142196655,r:0.06896922089328796
epoch 1 : weight has update
Palmitic epoch 2 |  train loss:0.006097689736634493,test loss:0.0047891344875097275,r:0.15738312413655473
epoch 2 : weight has update
Palmitic epoch 3 |  train loss:0.005534438882023096,test loss:0.014295917935669422,r:0.18174753220296627
epoch 3 : weight has update
Palmitic epoch 4 |  train loss:0.005642825737595558,test loss:0.017143703997135162,r:0.19724794388348896
epoch 4 : weight has update
Palmitic epoch 5 |  train loss:0.005172134842723608,test loss:0.024719495326280594,r:0.20852479079496872
epoch 5 : weight has update
Palmitic epoch 6 |  train loss:0.0054729171097278595,test loss:0.026313351467251778,r:0.19759252715546402
Palmitic epoch 7 |  train loss:0.005255602765828371,test loss:0.019976532086730003,r:0.20943019093018939
epoch 7 : weight has update
Palmitic epoch 8 |  train loss:0.0052208928391337395,test loss:0.016514264047145844,r:0.2062344818509846
Palmitic epoch 9 |  train loss:0.00489801773801446,test loss:0.010045086033642292,r:0.2027330651255491
Palmitic epoch 10 |  train loss:0.005139260087162256,test loss:0.014500691555440426,r:0.20475384999539584
Palmitic epoch 11 |  train loss:0.005082494579255581,test loss:0.01564636081457138,r:0.21069564627062912
epoch 11 : weight has update
Palmitic epoch 12 |  train loss:0.005046240519732237,test loss:0.011120312847197056,r:0.20202519911331104
Palmitic epoch 13 |  train loss:0.005004962906241417,test loss:0.012776675634086132,r:0.1997114715782108
Palmitic epoch 14 |  train loss:0.004787575453519821,test loss:0.008597270585596561,r:0.22271536055217186
epoch 14 : weight has update
Palmitic epoch 15 |  train loss:0.004918744787573814,test loss:0.008355384692549706,r:0.21343737615752695
Palmitic epoch 16 |  train loss:0.004892176482826471,test loss:0.009365953505039215,r:0.20401819694479711
Palmitic epoch 17 |  train loss:0.004759920760989189,test loss:0.01390871126204729,r:0.2007346401503856
Palmitic epoch 18 |  train loss:0.0046493313275277615,test loss:0.008342256769537926,r:0.2047838601581563
Palmitic epoch 19 |  train loss:0.0047879936173558235,test loss:0.01057188306003809,r:0.21417638144289902
Palmitic epoch 20 |  train loss:0.004657535348087549,test loss:0.0077930898405611515,r:0.2205859299181508
Palmitic epoch 21 |  train loss:0.004604849964380264,test loss:0.012715882621705532,r:0.22123104375071462
Palmitic epoch 22 |  train loss:0.004605695139616728,test loss:0.01602107100188732,r:0.2312920598423204
epoch 22 : weight has update
Palmitic epoch 23 |  train loss:0.004536481574177742,test loss:0.012124646455049515,r:0.253401371704056
epoch 23 : weight has update
Palmitic epoch 24 |  train loss:0.004576878156512976,test loss:0.010965012945234776,r:0.23338553410553323
Palmitic epoch 25 |  train loss:0.0044839526526629925,test loss:0.01332149002701044,r:0.2739074209494524
epoch 25 : weight has update
Palmitic epoch 26 |  train loss:0.004410531837493181,test loss:0.01335511077195406,r:0.30629951582005027
epoch 26 : weight has update
Palmitic epoch 27 |  train loss:0.004359619691967964,test loss:0.01226545125246048,r:0.285960831934212
Palmitic epoch 28 |  train loss:0.004304980393499136,test loss:0.00666791619732976,r:0.32498356091998887
epoch 28 : weight has update
Palmitic epoch 29 |  train loss:0.004217382520437241,test loss:0.005968838464468718,r:0.3364314499113081
epoch 29 : weight has update
Palmitic epoch 30 |  train loss:0.004194841254502535,test loss:0.006359335500746965,r:0.3412885748177701
epoch 30 : weight has update
Palmitic epoch 31 |  train loss:0.004164464771747589,test loss:0.005235976539552212,r:0.3420300886340586
epoch 31 : weight has update
Palmitic epoch 32 |  train loss:0.004141887649893761,test loss:0.005047047045081854,r:0.3407982941066988
Palmitic epoch 33 |  train loss:0.004022025037556887,test loss:0.00492780702188611,r:0.3034597751255407
Palmitic epoch 34 |  train loss:0.0040552495047450066,test loss:0.005323137156665325,r:0.287588708980307
Palmitic epoch 35 |  train loss:0.0039693331345915794,test loss:0.004097473341971636,r:0.36677708026638484
epoch 35 : weight has update
Palmitic epoch 36 |  train loss:0.003969309851527214,test loss:0.005396465305238962,r:0.1263533078956108
Palmitic epoch 37 |  train loss:0.003880932228639722,test loss:0.004335108678787947,r:0.2564206641235988
Palmitic epoch 38 |  train loss:0.003942111041396856,test loss:0.005107329227030277,r:0.34874602412609196
Palmitic epoch 39 |  train loss:0.003804184263572097,test loss:0.0043965778313577175,r:0.4021055714807292
epoch 39 : weight has update
Palmitic epoch 40 |  train loss:0.0038015658501535654,test loss:0.0066687543876469135,r:0.3836477457411812
Palmitic epoch 41 |  train loss:0.0037248986773192883,test loss:0.003933898638933897,r:0.38039506082576485
Palmitic epoch 42 |  train loss:0.003707057796418667,test loss:0.003898155875504017,r:0.40380404359667005
epoch 42 : weight has update
Palmitic epoch 43 |  train loss:0.003718511201441288,test loss:0.003943015821278095,r:0.42459293792859987
epoch 43 : weight has update
Palmitic epoch 44 |  train loss:0.003705106908455491,test loss:0.003856267547234893,r:0.4239185639975874
Palmitic epoch 45 |  train loss:0.0036160286981612444,test loss:0.0039043836295604706,r:0.42853668360923275
epoch 45 : weight has update
Palmitic epoch 46 |  train loss:0.003575856564566493,test loss:0.00371873308904469,r:0.43307691934062015
epoch 46 : weight has update
Palmitic epoch 47 |  train loss:0.00354929082095623,test loss:0.004481612239032984,r:0.4383460934617192
epoch 47 : weight has update
Palmitic epoch 48 |  train loss:0.003499702550470829,test loss:0.0038729466032236814,r:0.4414897481416287
epoch 48 : weight has update
Palmitic epoch 49 |  train loss:0.0034077870659530163,test loss:0.003991839475929737,r:0.4416561557729292
epoch 49 : weight has update
Palmitic epoch 50 |  train loss:0.0034677654039114714,test loss:0.0037445242051035166,r:0.4517010273257103
epoch 50 : weight has update
Palmitic epoch 51 |  train loss:0.0034280065447092056,test loss:0.004643687512725592,r:0.39313697188363045
Palmitic epoch 52 |  train loss:0.0033726999536156654,test loss:0.003687513992190361,r:0.4476009686852326
Palmitic epoch 53 |  train loss:0.0033810955937951803,test loss:0.0036054912488907576,r:0.4608037213062136
epoch 53 : weight has update
Palmitic epoch 54 |  train loss:0.0033423344139009714,test loss:0.004321812652051449,r:0.4419059907620452
Palmitic epoch 55 |  train loss:0.0033303475938737392,test loss:0.003903121454641223,r:0.4584989810742904
Palmitic epoch 56 |  train loss:0.0032832666765898466,test loss:0.003763968823477626,r:0.4572919399147447
Palmitic epoch 57 |  train loss:0.0032971722539514303,test loss:0.0036934898234903812,r:0.47160418276281996
epoch 57 : weight has update
Palmitic epoch 58 |  train loss:0.0032694132532924414,test loss:0.003800490405410528,r:0.47210144072907956
epoch 58 : weight has update
Palmitic epoch 59 |  train loss:0.003232539165765047,test loss:0.003759667044505477,r:0.4678023440489906
Palmitic epoch 60 |  train loss:0.003208784619346261,test loss:0.0038611169438809156,r:0.46246174525795086
Palmitic epoch 61 |  train loss:0.0032473462633788586,test loss:0.0038273141253739595,r:0.4590982541399363
Palmitic epoch 62 |  train loss:0.003131815465167165,test loss:0.0035016301553696394,r:0.48552996938396276
epoch 62 : weight has update
Palmitic epoch 63 |  train loss:0.0031959693878889084,test loss:0.0037518737372010946,r:0.47244395930742555
Palmitic epoch 64 |  train loss:0.003157754661515355,test loss:0.004691594745963812,r:0.44496155340964394
Palmitic epoch 65 |  train loss:0.0031415666453540325,test loss:0.00367011153139174,r:0.47694204178984917
Palmitic epoch 66 |  train loss:0.0030811915639787912,test loss:0.003698507323861122,r:0.48316613175907047
Palmitic epoch 67 |  train loss:0.003122469410300255,test loss:0.004159929230809212,r:0.45844638739330107
Palmitic epoch 68 |  train loss:0.003102497663348913,test loss:0.0040859654545784,r:0.4865897285519717
epoch 68 : weight has update
Palmitic epoch 69 |  train loss:0.003063417039811611,test loss:0.003966255579143763,r:0.48269915045798634
Palmitic epoch 70 |  train loss:0.0031056676525622606,test loss:0.0036887668538838625,r:0.47962875413143885
Palmitic epoch 71 |  train loss:0.0030574514530599117,test loss:0.0038501073140650988,r:0.47717978755125146
Palmitic epoch 72 |  train loss:0.0030745116528123617,test loss:0.003611040534451604,r:0.4680832546528451
Palmitic epoch 73 |  train loss:0.003034986089915037,test loss:0.004678991623222828,r:0.4821331070981998
Palmitic epoch 74 |  train loss:0.00302359601482749,test loss:0.003843082580715418,r:0.48220984281187096
Palmitic epoch 75 |  train loss:0.002980387769639492,test loss:0.003951467107981443,r:0.49258195118310094
epoch 75 : weight has update
Palmitic epoch 76 |  train loss:0.0030119409784674644,test loss:0.0035444325767457485,r:0.4756853081252277
Palmitic epoch 77 |  train loss:0.0029899387154728174,test loss:0.003967283293604851,r:0.4703886104707958
Palmitic epoch 78 |  train loss:0.0029633445665240288,test loss:0.0036755481269210577,r:0.4777702275217983
Palmitic epoch 79 |  train loss:0.0029485062696039677,test loss:0.0035426646936684847,r:0.47747015450788616
Palmitic epoch 80 |  train loss:0.002966191153973341,test loss:0.0038060673978179693,r:0.4863466274239188
Palmitic epoch 81 |  train loss:0.002940710633993149,test loss:0.0037152408622205257,r:0.48099486658009033
Palmitic epoch 82 |  train loss:0.0029432603623718023,test loss:0.0035247597843408585,r:0.48758507113288596
Palmitic epoch 83 |  train loss:0.002904798835515976,test loss:0.0035256980918347836,r:0.4790374186631345
Palmitic epoch 84 |  train loss:0.00290724472142756,test loss:0.003592479508370161,r:0.48651591302447766
Palmitic epoch 85 |  train loss:0.0028963186778128147,test loss:0.003550745779648423,r:0.48399372056099416
Palmitic epoch 86 |  train loss:0.0028761662542819977,test loss:0.004089896567165852,r:0.47474948044992776
Palmitic epoch 87 |  train loss:0.002845511306077242,test loss:0.004409645684063435,r:0.48826637214028595
Palmitic epoch 88 |  train loss:0.0029415020253509283,test loss:0.0035717319697141647,r:0.4748612096675626
Palmitic epoch 89 |  train loss:0.002899716142565012,test loss:0.003699326189234853,r:0.495198817266697
epoch 89 : weight has update
Palmitic epoch 90 |  train loss:0.002916086232289672,test loss:0.0036628693342208862,r:0.477650411312034
Palmitic epoch 91 |  train loss:0.002895427867770195,test loss:0.0035613873042166233,r:0.48066805802073004
Palmitic epoch 92 |  train loss:0.002872556447982788,test loss:0.003498312784358859,r:0.4829414640603352
Palmitic epoch 93 |  train loss:0.002807659562677145,test loss:0.0035493450704962015,r:0.4785517578647936
Palmitic epoch 94 |  train loss:0.0028211281169205904,test loss:0.0039974115788936615,r:0.4762778006086382
Palmitic epoch 95 |  train loss:0.0027744874823838472,test loss:0.003742663189768791,r:0.46776673176711475
Palmitic epoch 96 |  train loss:0.0028826151974499226,test loss:0.0035201667342334986,r:0.481269204957875
Palmitic epoch 97 |  train loss:0.002824959345161915,test loss:0.003622253891080618,r:0.4676938393602357
Palmitic epoch 98 |  train loss:0.002813526429235935,test loss:0.0038261099252849817,r:0.45990771251946105
Palmitic epoch 99 |  train loss:0.002793438732624054,test loss:0.003587869228795171,r:0.4846244842635635
Palmitic epoch 100 |  train loss:0.0027857166714966297,test loss:0.0035442698281258345,r:0.483597507547862
Palmitic epoch 101 |  train loss:0.0028347503393888474,test loss:0.0035814896691590548,r:0.48265549934206986
Palmitic epoch 102 |  train loss:0.0027658368926495314,test loss:0.003520021215081215,r:0.48266278706461857
Palmitic epoch 103 |  train loss:0.0027400683611631393,test loss:0.003669359954074025,r:0.4816370494153037
Palmitic epoch 104 |  train loss:0.002731174463406205,test loss:0.003908413462340832,r:0.480328184277099
Palmitic epoch 105 |  train loss:0.0027962960302829742,test loss:0.0038290054071694613,r:0.48389079840254795
Palmitic epoch 106 |  train loss:0.0028073368594050407,test loss:0.003589052939787507,r:0.48755166961650964
Palmitic epoch 107 |  train loss:0.0027618571184575558,test loss:0.00416354276239872,r:0.4899242782355025
Palmitic epoch 108 |  train loss:0.0027391451876610518,test loss:0.004197131842374802,r:0.4835432223207154
Palmitic epoch 109 |  train loss:0.0027229434344917536,test loss:0.003776836907491088,r:0.4841406208116842
Palmitic epoch 110 |  train loss:0.0027908391784876585,test loss:0.003569580614566803,r:0.4834363658620735
Palmitic epoch 111 |  train loss:0.002777376677840948,test loss:0.003926651086658239,r:0.48240593843956014
Palmitic epoch 112 |  train loss:0.002756224712356925,test loss:0.003641593735665083,r:0.47229096902526885
Palmitic epoch 113 |  train loss:0.002681180601939559,test loss:0.0036088430788367987,r:0.4680393150512741
Palmitic epoch 114 |  train loss:0.002727162791416049,test loss:0.003499001730233431,r:0.4847883766017967
Palmitic epoch 115 |  train loss:0.002773533808067441,test loss:0.0043053277768194675,r:0.47722864417990246
Palmitic epoch 116 |  train loss:0.0027033453807234764,test loss:0.003855781862512231,r:0.4825950814077281
Palmitic epoch 117 |  train loss:0.0027427978347986937,test loss:0.003596888156607747,r:0.4831932616295606
Palmitic epoch 118 |  train loss:0.0026702384930104017,test loss:0.0036601226311177015,r:0.4706890104755945
Palmitic epoch 119 |  train loss:0.002751840278506279,test loss:0.0035560803953558207,r:0.47419938999297945
Palmitic epoch 120 |  train loss:0.0026872740127146244,test loss:0.003557591000571847,r:0.4781548443871614
Palmitic epoch 121 |  train loss:0.002691245172172785,test loss:0.003509936388581991,r:0.4866513107455274
Palmitic epoch 122 |  train loss:0.0027153240516781807,test loss:0.003508892608806491,r:0.4806825276263147
Palmitic epoch 123 |  train loss:0.0026901268865913153,test loss:0.0036842268891632557,r:0.4735653765844317
Palmitic epoch 124 |  train loss:0.0026877569034695625,test loss:0.004080282989889383,r:0.4685624379454576
Palmitic epoch 125 |  train loss:0.0026573643554002047,test loss:0.003702679416164756,r:0.46811970906228495
Palmitic epoch 126 |  train loss:0.0026443267706781626,test loss:0.0035702891182154417,r:0.4770059539812899
Palmitic epoch 127 |  train loss:0.0027071672957390547,test loss:0.003602370386943221,r:0.47145940294882965
Palmitic epoch 128 |  train loss:0.002702089725062251,test loss:0.0035205150488764048,r:0.4782976122253722
Palmitic epoch 129 |  train loss:0.0026880474761128426,test loss:0.00383153953589499,r:0.4690020794673441
Palmitic epoch 130 |  train loss:0.0027098343707621098,test loss:0.003928234800696373,r:0.47918216677219755
Palmitic epoch 131 |  train loss:0.002700919983908534,test loss:0.003649139543995261,r:0.48279607917931344
Palmitic epoch 132 |  train loss:0.0026707963552325964,test loss:0.0036182506009936333,r:0.47541468374325613
Palmitic epoch 133 |  train loss:0.002693718299269676,test loss:0.003904446493834257,r:0.4751131900119014
Palmitic epoch 134 |  train loss:0.0026928826700896025,test loss:0.00369301182217896,r:0.47806544967129944
Palmitic epoch 135 |  train loss:0.0026741197798401117,test loss:0.0046330648474395275,r:0.46090214238782545
Palmitic epoch 136 |  train loss:0.002630241448059678,test loss:0.0035896331537514925,r:0.4660540377956714
Palmitic epoch 137 |  train loss:0.0026879606302827597,test loss:0.003737997030839324,r:0.4794172561099238
Palmitic epoch 138 |  train loss:0.002676883479580283,test loss:0.003725462593138218,r:0.4758295699220382
Palmitic epoch 139 |  train loss:0.0027667179238051176,test loss:0.003651464357972145,r:0.4487231208887929
Palmitic epoch 140 |  train loss:0.0026988207828253508,test loss:0.0035905251279473305,r:0.4706762194596051
Palmitic epoch 141 |  train loss:0.0026155211962759495,test loss:0.003504449501633644,r:0.48133858450577954
Palmitic epoch 142 |  train loss:0.002646207809448242,test loss:0.0036258932668715715,r:0.47014148490573604
Palmitic epoch 143 |  train loss:0.0026635664980858564,test loss:0.003720221109688282,r:0.46207531043745015
Palmitic epoch 144 |  train loss:0.0026701863389462233,test loss:0.003534301882609725,r:0.4787844270830775
Palmitic epoch 145 |  train loss:0.0026613189838826656,test loss:0.004622665233910084,r:0.46731690631240597
Palmitic epoch 146 |  train loss:0.0026383649092167616,test loss:0.00394176272675395,r:0.4582344195328836
Palmitic epoch 147 |  train loss:0.0026352526620030403,test loss:0.004129163455218077,r:0.4691876008943026
Palmitic epoch 148 |  train loss:0.002593293786048889,test loss:0.003734767436981201,r:0.45359182138445614
Palmitic epoch 149 |  train loss:0.002652469091117382,test loss:0.003728135721758008,r:0.4799218217142572
Palmitic epoch 150 |  train loss:0.002581197302788496,test loss:0.003577478928491473,r:0.4669075368133644
training has finished used time : 8474.771990060806
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (15398, 14)
5000
9306
df shape (20087, 42195)
shape train_df pos (32032, 20087)
shape train_df sample (5000, 32032)
(5000, 32032) (9306, 32032)
train dataset already completed!
5000
test dataset already completed!
9306
Steartic epoch 1 |  train loss:0.1452103555202484,test loss:0.018341965973377228,r:0.12339072632847076
epoch 1 : weight has update
Steartic epoch 2 |  train loss:0.005280565936118364,test loss:0.011451567523181438,r:0.1684553970002162
epoch 2 : weight has update
Steartic epoch 3 |  train loss:0.0050461990758776665,test loss:0.05008750408887863,r:0.22229269327896314
epoch 3 : weight has update
Steartic epoch 4 |  train loss:0.004941173363476992,test loss:0.08981094509363174,r:0.2595036113119119
epoch 4 : weight has update
Steartic epoch 5 |  train loss:0.004771933425217867,test loss:0.0039026690647006035,r:0.22498698222728983
Steartic epoch 6 |  train loss:0.004741903860121965,test loss:0.0327455997467041,r:0.26291642838710033
epoch 6 : weight has update
Steartic epoch 7 |  train loss:0.004726614337414503,test loss:0.05897001549601555,r:0.286494184878535
epoch 7 : weight has update
Steartic epoch 8 |  train loss:0.004687492735683918,test loss:0.00452934205532074,r:0.31050964847073337
epoch 8 : weight has update
Steartic epoch 9 |  train loss:0.004538928624242544,test loss:0.06785422563552856,r:0.3320533092934661
epoch 9 : weight has update
Steartic epoch 10 |  train loss:0.004496830049902201,test loss:0.03298499435186386,r:0.3413873719617761
epoch 10 : weight has update
Steartic epoch 11 |  train loss:0.004374121781438589,test loss:0.003840109333395958,r:0.37322417005776776
epoch 11 : weight has update
Steartic epoch 12 |  train loss:0.004300050437450409,test loss:0.013028565794229507,r:0.381858184785552
epoch 12 : weight has update
Steartic epoch 13 |  train loss:0.004248866345733404,test loss:0.021941984072327614,r:0.3814735376612929
Steartic epoch 14 |  train loss:0.004238992929458618,test loss:0.033865489065647125,r:0.38536000830885
epoch 14 : weight has update
Steartic epoch 15 |  train loss:0.004102959297597408,test loss:0.006437791511416435,r:0.21588224616161164
Steartic epoch 16 |  train loss:0.004056447651237249,test loss:0.004814337007701397,r:0.19138793459973802
Steartic epoch 17 |  train loss:0.003912688698619604,test loss:0.0079857362434268,r:-0.33894328827809944
Steartic epoch 18 |  train loss:0.0038532684557139874,test loss:0.0043649133294820786,r:-0.03782767106701341
Steartic epoch 19 |  train loss:0.0037810546346008778,test loss:0.004043521359562874,r:-0.1916142327858278
Steartic epoch 20 |  train loss:0.0036707594990730286,test loss:0.004070858005434275,r:0.2914438809368577
Steartic epoch 21 |  train loss:0.0035212431102991104,test loss:0.00467703677713871,r:0.43622869528143426
epoch 21 : weight has update
Steartic epoch 22 |  train loss:0.0035034664906561375,test loss:0.003968279343098402,r:0.4263089210818868
Steartic epoch 23 |  train loss:0.003399049397557974,test loss:0.00476539833471179,r:0.4823352845343705
epoch 23 : weight has update
Steartic epoch 24 |  train loss:0.003310822881758213,test loss:0.003756305668503046,r:0.4569702955898143
Steartic epoch 25 |  train loss:0.0033070144709199667,test loss:0.0035050681326538324,r:0.4875347352458374
epoch 25 : weight has update
Steartic epoch 26 |  train loss:0.0033007520250976086,test loss:0.003527875291183591,r:0.508652089923263
epoch 26 : weight has update
Steartic epoch 27 |  train loss:0.003278491087257862,test loss:0.003796254750341177,r:0.4424614353886087
Steartic epoch 28 |  train loss:0.0032870343420654535,test loss:0.0038115738425403833,r:0.5243504908465518
epoch 28 : weight has update
Steartic epoch 29 |  train loss:0.003238759469240904,test loss:0.005652050022035837,r:0.5141223586866007
Steartic epoch 30 |  train loss:0.003209116403013468,test loss:0.0033521600998938084,r:0.5281723735688844
epoch 30 : weight has update
Steartic epoch 31 |  train loss:0.003175057005137205,test loss:0.0031565416138619184,r:0.5120047387354854
Steartic epoch 32 |  train loss:0.0032249935902655125,test loss:0.002989604603499174,r:0.5216969877320433
Steartic epoch 33 |  train loss:0.003252366790547967,test loss:0.003253029892221093,r:0.48185737714783505
Steartic epoch 34 |  train loss:0.0033156147692352533,test loss:0.0031691440381109715,r:0.5238378624058215
Steartic epoch 35 |  train loss:0.003243062412366271,test loss:0.002958769677206874,r:0.5157692615281766
Steartic epoch 36 |  train loss:0.0032366730738431215,test loss:0.0029087646398693323,r:0.5249446582728751
Steartic epoch 37 |  train loss:0.003196026897057891,test loss:0.0029025347903370857,r:0.5327643757179406
epoch 37 : weight has update
Steartic epoch 38 |  train loss:0.0031488181557506323,test loss:0.00346383941359818,r:0.5255775568351481
Steartic epoch 39 |  train loss:0.003218281315639615,test loss:0.0029092361219227314,r:0.5342234640002648
epoch 39 : weight has update
Steartic epoch 40 |  train loss:0.003132786136120558,test loss:0.0029498571529984474,r:0.5180175136162072
Steartic epoch 41 |  train loss:0.003220030339434743,test loss:0.0029453160241246223,r:0.5395890945482772
epoch 41 : weight has update
Steartic epoch 42 |  train loss:0.0031438155565410852,test loss:0.0029883526731282473,r:0.5280687589626227
Steartic epoch 43 |  train loss:0.0031553078442811966,test loss:0.0028974590823054314,r:0.5360390902182258
Steartic epoch 44 |  train loss:0.0031014299020171165,test loss:0.0029822520446032286,r:0.5263333709828633
Steartic epoch 45 |  train loss:0.0031603816896677017,test loss:0.0029564700089395046,r:0.5321465260746276
Steartic epoch 46 |  train loss:0.003081787610426545,test loss:0.0029838557820767164,r:0.5204437175967771
Steartic epoch 47 |  train loss:0.0031648280564695597,test loss:0.0029106102883815765,r:0.5257697218786408
Steartic epoch 48 |  train loss:0.003074822947382927,test loss:0.0029495013877749443,r:0.5387497524843072
Steartic epoch 49 |  train loss:0.003110254183411598,test loss:0.0028274827636778355,r:0.5427247043665371
epoch 49 : weight has update
Steartic epoch 50 |  train loss:0.0029911405872553587,test loss:0.0029508781153708696,r:0.5379294643494561
Steartic epoch 51 |  train loss:0.0030473440419882536,test loss:0.0028984718956053257,r:0.5324618825467793
Steartic epoch 52 |  train loss:0.003025704761967063,test loss:0.002881470834836364,r:0.5321590929765239
Steartic epoch 53 |  train loss:0.003002125071361661,test loss:0.002958140568807721,r:0.5424960163317836
Steartic epoch 54 |  train loss:0.003000265918672085,test loss:0.0030402818229049444,r:0.5380269872181701
Steartic epoch 55 |  train loss:0.0029676982667297125,test loss:0.0029248767532408237,r:0.5428678673445473
epoch 55 : weight has update
Steartic epoch 56 |  train loss:0.002955035772174597,test loss:0.00325586786493659,r:0.5571238336921245
epoch 56 : weight has update
Steartic epoch 57 |  train loss:0.002942599356174469,test loss:0.0028178668580949306,r:0.5463588212875624
Steartic epoch 58 |  train loss:0.0028651792090386152,test loss:0.0028648111037909985,r:0.549908473643643
Steartic epoch 59 |  train loss:0.0029206578619778156,test loss:0.002841730834916234,r:0.5460793978712347
Steartic epoch 60 |  train loss:0.0029302940238267183,test loss:0.003032873384654522,r:0.5519562294043517
Steartic epoch 61 |  train loss:0.002907754387706518,test loss:0.002838453045114875,r:0.5440547691056584
Steartic epoch 62 |  train loss:0.002883146284148097,test loss:0.0029220900032669306,r:0.5448972179946653
Steartic epoch 63 |  train loss:0.0028835150878876448,test loss:0.003109150333330035,r:0.5510368273147139
Steartic epoch 64 |  train loss:0.00287988455966115,test loss:0.002748752711340785,r:0.5631912839863661
epoch 64 : weight has update
Steartic epoch 65 |  train loss:0.0029122643172740936,test loss:0.0028262685518711805,r:0.5551833957747113
Steartic epoch 66 |  train loss:0.0027568447403609753,test loss:0.0029640316497534513,r:0.5542103959793655
Steartic epoch 67 |  train loss:0.002807755721732974,test loss:0.002824250375851989,r:0.5575366929175324
Steartic epoch 68 |  train loss:0.0028244887944310904,test loss:0.002809541067108512,r:0.5516289398774743
Steartic epoch 69 |  train loss:0.0028010329697281122,test loss:0.003344160970300436,r:0.5346590330473717
Steartic epoch 70 |  train loss:0.0028370798099786043,test loss:0.0028311789501458406,r:0.5574261996234471
Steartic epoch 71 |  train loss:0.0028954120352864265,test loss:0.002891828306019306,r:0.5559037137943531
Steartic epoch 72 |  train loss:0.0027919532731175423,test loss:0.002915838733315468,r:0.555260451441673
Steartic epoch 73 |  train loss:0.002764776349067688,test loss:0.0029768759850412607,r:0.5607484268655912
Steartic epoch 74 |  train loss:0.002823379822075367,test loss:0.0030522572342306376,r:0.5582637082152399
Steartic epoch 75 |  train loss:0.002753068460151553,test loss:0.002897637663409114,r:0.5655436199079441
epoch 75 : weight has update
Steartic epoch 76 |  train loss:0.002768989186733961,test loss:0.002890312112867832,r:0.5515493543681094
Steartic epoch 77 |  train loss:0.0027773564215749502,test loss:0.0027847266755998135,r:0.554847640228197
Steartic epoch 78 |  train loss:0.0027503070887178183,test loss:0.0030453635845333338,r:0.5656316798515522
epoch 78 : weight has update
Steartic epoch 79 |  train loss:0.0027784721460193396,test loss:0.002805848605930805,r:0.5632266132925945
Steartic epoch 80 |  train loss:0.002723322482779622,test loss:0.0027232379652559757,r:0.5722780742120824
epoch 80 : weight has update
Steartic epoch 81 |  train loss:0.002778215566650033,test loss:0.002868794137611985,r:0.5611300820537746
Steartic epoch 82 |  train loss:0.0028166668489575386,test loss:0.002834389451891184,r:0.5595218458156472
Steartic epoch 83 |  train loss:0.0027141154278069735,test loss:0.0027636548038572073,r:0.5613177158782997
Steartic epoch 84 |  train loss:0.0026982396375387907,test loss:0.002777766901999712,r:0.5638721321596148
Steartic epoch 85 |  train loss:0.0027374413330107927,test loss:0.0029331943951547146,r:0.5522225339195175
Steartic epoch 86 |  train loss:0.0027623011264950037,test loss:0.0028204030822962523,r:0.5609778299299865
Steartic epoch 87 |  train loss:0.0027793936897069216,test loss:0.002767973579466343,r:0.5633729280547175
Steartic epoch 88 |  train loss:0.002684196690097451,test loss:0.002839550841599703,r:0.5665811439665802
Steartic epoch 89 |  train loss:0.002706770086660981,test loss:0.0027894903905689716,r:0.5521931681158306
Steartic epoch 90 |  train loss:0.0027242221403867006,test loss:0.0029531163163483143,r:0.5527996629246961
Steartic epoch 91 |  train loss:0.002648565685376525,test loss:0.0031534642912447453,r:0.5614149433365471
Steartic epoch 92 |  train loss:0.002721096621826291,test loss:0.002877592807635665,r:0.5635862260819013
Steartic epoch 93 |  train loss:0.0026561259292066097,test loss:0.0028175911866128445,r:0.5583642883156921
Steartic epoch 94 |  train loss:0.002620865823701024,test loss:0.002842382527887821,r:0.5429909251230425
Steartic epoch 95 |  train loss:0.0026314330752938986,test loss:0.00277185277082026,r:0.5562159690432277
Steartic epoch 96 |  train loss:0.0027085153851658106,test loss:0.002789231948554516,r:0.5609425875770887
Steartic epoch 97 |  train loss:0.002715718001127243,test loss:0.0027781326789408922,r:0.5639985653860113
Steartic epoch 98 |  train loss:0.0026404233649373055,test loss:0.0028124991804361343,r:0.5722361432786283
Steartic epoch 99 |  train loss:0.002635914832353592,test loss:0.0031798866111785173,r:0.568977617447455
Steartic epoch 100 |  train loss:0.002631472423672676,test loss:0.0035889854189008474,r:0.5476575409840664
Steartic epoch 101 |  train loss:0.0027182793710380793,test loss:0.0031263644341379404,r:0.5377411223078788
Steartic epoch 102 |  train loss:0.002640403574332595,test loss:0.0031723733991384506,r:0.5395209525804243
Steartic epoch 103 |  train loss:0.0026621136348694563,test loss:0.0027830912731587887,r:0.5566039000931265
Steartic epoch 104 |  train loss:0.0026313571725040674,test loss:0.0030246886890381575,r:0.5472810155022567
Steartic epoch 105 |  train loss:0.002659918973222375,test loss:0.002758484333753586,r:0.5656184558936763
Steartic epoch 106 |  train loss:0.002534937346354127,test loss:0.002762723481282592,r:0.5592146842350953
Steartic epoch 107 |  train loss:0.0026036479976028204,test loss:0.0027543201576918364,r:0.5636048587093627
Steartic epoch 108 |  train loss:0.0026238858699798584,test loss:0.002807156415656209,r:0.5620892612269922
Steartic epoch 109 |  train loss:0.0025373150128871202,test loss:0.002824470167979598,r:0.558475120470362
Steartic epoch 110 |  train loss:0.002606260357424617,test loss:0.002821877598762512,r:0.5567152014722963
Steartic epoch 111 |  train loss:0.00264118704944849,test loss:0.0029671520460397005,r:0.5532990417111605
Steartic epoch 112 |  train loss:0.0025993185117840767,test loss:0.0027977440040558577,r:0.5624925361519825
Steartic epoch 113 |  train loss:0.002547935349866748,test loss:0.0028951438143849373,r:0.5341308236498188
Steartic epoch 114 |  train loss:0.002641204046085477,test loss:0.0033964458853006363,r:0.5493696209501364
Steartic epoch 115 |  train loss:0.002636129502207041,test loss:0.0028470810502767563,r:0.5609343056127606
Steartic epoch 116 |  train loss:0.002592309843748808,test loss:0.0028993580490350723,r:0.5651707297078336
Steartic epoch 117 |  train loss:0.0026264458429068327,test loss:0.002868685871362686,r:0.5589834702824377
Steartic epoch 118 |  train loss:0.002533066552132368,test loss:0.002804703311994672,r:0.5478191775389639
Steartic epoch 119 |  train loss:0.002641870640218258,test loss:0.0029605915769934654,r:0.558140436083837
Steartic epoch 120 |  train loss:0.002600927371531725,test loss:0.0029358328320086002,r:0.5602160233180495
Steartic epoch 121 |  train loss:0.002649147529155016,test loss:0.002697431482374668,r:0.5720481298342189
Steartic epoch 122 |  train loss:0.002446336904540658,test loss:0.003071006154641509,r:0.5130522592482695
Steartic epoch 123 |  train loss:0.002573978854343295,test loss:0.002782432595267892,r:0.5653587329679165
Steartic epoch 124 |  train loss:0.0025355196557939053,test loss:0.0027356715872883797,r:0.5714558557894142
Steartic epoch 125 |  train loss:0.002575803082436323,test loss:0.0028600727673619986,r:0.5674399175613574
Steartic epoch 126 |  train loss:0.002477155765518546,test loss:0.0030395009089261293,r:0.5588365285251541
Steartic epoch 127 |  train loss:0.002537116874009371,test loss:0.0030212439596652985,r:0.5542574163370725
Steartic epoch 128 |  train loss:0.002526277909055352,test loss:0.003167579649016261,r:0.5316816241140457
Steartic epoch 129 |  train loss:0.0025472950655966997,test loss:0.002865615300834179,r:0.5619284554694403
Steartic epoch 130 |  train loss:0.0026065208949148655,test loss:0.003068499732762575,r:0.5622848966232392
Steartic epoch 131 |  train loss:0.002488429192453623,test loss:0.0027501469012349844,r:0.5601784930791713
Steartic epoch 132 |  train loss:0.002517910674214363,test loss:0.002866672817617655,r:0.5569112381677643
Steartic epoch 133 |  train loss:0.0025564138777554035,test loss:0.0027945011388510466,r:0.5637167515467876
Steartic epoch 134 |  train loss:0.0026337187737226486,test loss:0.0027217038441449404,r:0.5664919845233755
Steartic epoch 135 |  train loss:0.0025841540191322565,test loss:0.0028396975249052048,r:0.5677554632982668
Steartic epoch 136 |  train loss:0.0025149418506771326,test loss:0.0028251383919268847,r:0.560025208876304
Steartic epoch 137 |  train loss:0.0025210308376699686,test loss:0.002924674190580845,r:0.5619873690519362
Steartic epoch 138 |  train loss:0.0025252068880945444,test loss:0.0032069270964711905,r:0.5528599808081427
Steartic epoch 139 |  train loss:0.002617360558360815,test loss:0.0029714256525039673,r:0.5730628505073527
epoch 139 : weight has update
Steartic epoch 140 |  train loss:0.0025389117654412985,test loss:0.0027899497654289007,r:0.5643803057323399
Steartic epoch 141 |  train loss:0.002618103288114071,test loss:0.0029294274281710386,r:0.5614986491948515
Steartic epoch 142 |  train loss:0.0025081068743020296,test loss:0.002766702324151993,r:0.5620434046048712
Steartic epoch 143 |  train loss:0.0025177267380058765,test loss:0.0031990220304578543,r:0.569139739796368
Steartic epoch 144 |  train loss:0.002474529203027487,test loss:0.0029793751891702414,r:0.5149561982316194
Steartic epoch 145 |  train loss:0.002577903913334012,test loss:0.0027861669659614563,r:0.5547661395567225
Steartic epoch 146 |  train loss:0.0024771220050752163,test loss:0.0028737233951687813,r:0.563926529804442
Steartic epoch 147 |  train loss:0.002524419454857707,test loss:0.0030131160747259855,r:0.5376421599313376
Steartic epoch 148 |  train loss:0.0025641690008342266,test loss:0.0027453394141048193,r:0.5648150824966222
Steartic epoch 149 |  train loss:0.002491812454536557,test loss:0.002733385656028986,r:0.567701064115848
Steartic epoch 150 |  train loss:0.0024822817649692297,test loss:0.002943025203421712,r:0.5619998794722317
training has finished used time : 8389.10647201538
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (15398, 14)
5000
9306
df shape (20087, 42195)
shape train_df pos (32032, 20087)
shape train_df sample (5000, 32032)
(5000, 32032) (9306, 32032)
train dataset already completed!
5000
test dataset already completed!
9306
Oleic epoch 1 |  train loss:0.15494592487812042,test loss:0.012904263101518154,r:0.08274120397752686
epoch 1 : weight has update
Oleic epoch 2 |  train loss:0.007078166119754314,test loss:0.013840517029166222,r:0.11333456518553686
epoch 2 : weight has update
Oleic epoch 3 |  train loss:0.006790400017052889,test loss:0.024680843576788902,r:0.15949329494264483
epoch 3 : weight has update
Oleic epoch 4 |  train loss:0.00657978281378746,test loss:0.04036731272935867,r:0.1962069377178746
epoch 4 : weight has update
Oleic epoch 5 |  train loss:0.006732412148267031,test loss:0.028594525530934334,r:0.2104849237159187
epoch 5 : weight has update
Oleic epoch 6 |  train loss:0.006459185853600502,test loss:0.039986610412597656,r:0.17380053866256842
Oleic epoch 7 |  train loss:0.006523618008941412,test loss:0.038038983941078186,r:0.0365006840319968
Oleic epoch 8 |  train loss:0.0063230423256754875,test loss:0.03277130052447319,r:-0.0007066317614455939
Oleic epoch 9 |  train loss:0.006217969581484795,test loss:0.026028918102383614,r:0.0008620762826793347
Oleic epoch 10 |  train loss:0.006139835342764854,test loss:0.014456762932240963,r:-0.06932356890204253
Oleic epoch 11 |  train loss:0.005982280243188143,test loss:0.01615125685930252,r:0.010424396816646642
Oleic epoch 12 |  train loss:0.005881194025278091,test loss:0.012343740090727806,r:0.07509951317143966
Oleic epoch 13 |  train loss:0.0058527784422039986,test loss:0.010086879134178162,r:0.007650131419787419
Oleic epoch 14 |  train loss:0.005735916085541248,test loss:0.008985706605017185,r:0.20102468659112688
Oleic epoch 15 |  train loss:0.005645740311592817,test loss:0.008112845942378044,r:0.15288435329760108
Oleic epoch 16 |  train loss:0.005620293784886599,test loss:0.007389451377093792,r:0.16648244938257384
Oleic epoch 17 |  train loss:0.005494348704814911,test loss:0.0072301654145121574,r:-0.21975983664411014
Oleic epoch 18 |  train loss:0.0054291486740112305,test loss:0.006905909162014723,r:-0.14350019419898769
Oleic epoch 19 |  train loss:0.005225420463830233,test loss:0.010944432578980923,r:-0.08158452601387405
Oleic epoch 20 |  train loss:0.005160383880138397,test loss:0.010395330376923084,r:0.032297369521409866
Oleic epoch 21 |  train loss:0.0050876508466899395,test loss:0.0062236362136900425,r:-0.07763226653090799
Oleic epoch 22 |  train loss:0.0049803671427071095,test loss:0.006976455915719271,r:0.14684048259347243
Oleic epoch 23 |  train loss:0.004846942611038685,test loss:0.006389958783984184,r:-0.02639456999209188
Oleic epoch 24 |  train loss:0.004849135875701904,test loss:0.01071042101830244,r:0.37396233451199823
epoch 24 : weight has update
Oleic epoch 25 |  train loss:0.004724218510091305,test loss:0.007941113784909248,r:0.2854262117521094
Oleic epoch 26 |  train loss:0.0047788373194634914,test loss:0.006328280549496412,r:0.3645736441611057
Oleic epoch 27 |  train loss:0.004776702728122473,test loss:0.00619501480832696,r:0.3861652156160047
epoch 27 : weight has update
Oleic epoch 28 |  train loss:0.00470218900591135,test loss:0.005850186571478844,r:0.3867607321526924
epoch 28 : weight has update
Oleic epoch 29 |  train loss:0.004873957019299269,test loss:0.006743535865098238,r:0.2483184254250443
Oleic epoch 30 |  train loss:0.004743106663227081,test loss:0.005232763476669788,r:0.4583035275201952
epoch 30 : weight has update
Oleic epoch 31 |  train loss:0.004660315811634064,test loss:0.005363980308175087,r:0.3932287152454539
Oleic epoch 32 |  train loss:0.004703619051724672,test loss:0.0047296578995883465,r:0.4639903385053592
epoch 32 : weight has update
Oleic epoch 33 |  train loss:0.004767437465488911,test loss:0.005235920660197735,r:0.4494597288658455
Oleic epoch 34 |  train loss:0.004673589486628771,test loss:0.004834678024053574,r:0.4620088877834408
Oleic epoch 35 |  train loss:0.004766862839460373,test loss:0.005996966268867254,r:0.41666735977014685
Oleic epoch 36 |  train loss:0.004710041452199221,test loss:0.00465913163498044,r:0.46805052580140977
epoch 36 : weight has update
Oleic epoch 37 |  train loss:0.004664851818233728,test loss:0.007359889801591635,r:0.45440507291845705
Oleic epoch 38 |  train loss:0.004616381134837866,test loss:0.005191151052713394,r:0.4781302261026507
epoch 38 : weight has update
Oleic epoch 39 |  train loss:0.004712329711765051,test loss:0.004862723872065544,r:0.47975880636319007
epoch 39 : weight has update
Oleic epoch 40 |  train loss:0.0046327305026352406,test loss:0.004803329240530729,r:0.46641521626436666
Oleic epoch 41 |  train loss:0.0045827412977814674,test loss:0.004738739691674709,r:0.48514548250344985
epoch 41 : weight has update
Oleic epoch 42 |  train loss:0.004620040766894817,test loss:0.00470734341070056,r:0.500106621786659
epoch 42 : weight has update
Oleic epoch 43 |  train loss:0.004526031669229269,test loss:0.007233940996229649,r:0.4818520728721838
Oleic epoch 44 |  train loss:0.0046092551201581955,test loss:0.004887608345597982,r:0.4956404517815344
Oleic epoch 45 |  train loss:0.004510749597102404,test loss:0.004433807916939259,r:0.5091133973419765
epoch 45 : weight has update
Oleic epoch 46 |  train loss:0.004484610166400671,test loss:0.0047981590032577515,r:0.4875709300589576
Oleic epoch 47 |  train loss:0.004403871949762106,test loss:0.004771172534674406,r:0.5022546330584536
Oleic epoch 48 |  train loss:0.004397374112159014,test loss:0.004630072042346001,r:0.48213794528460235
Oleic epoch 49 |  train loss:0.00434037996456027,test loss:0.0073236762546002865,r:0.5143349667902976
epoch 49 : weight has update
Oleic epoch 50 |  train loss:0.004405603744089603,test loss:0.004527178127318621,r:0.5052650499815311
Oleic epoch 51 |  train loss:0.004284678492695093,test loss:0.00465025519952178,r:0.522654257649311
epoch 51 : weight has update
Oleic epoch 52 |  train loss:0.004268491640686989,test loss:0.004645312670618296,r:0.5100681061984528
Oleic epoch 53 |  train loss:0.004247502889484167,test loss:0.005523488391190767,r:0.5136542204066653
Oleic epoch 54 |  train loss:0.004191932734102011,test loss:0.004382655490189791,r:0.5193202182064142
Oleic epoch 55 |  train loss:0.004180755000561476,test loss:0.004575533792376518,r:0.5216392879940123
Oleic epoch 56 |  train loss:0.004150251857936382,test loss:0.004362999461591244,r:0.5212492197369257
Oleic epoch 57 |  train loss:0.004103614948689938,test loss:0.004290103912353516,r:0.5269732622934793
epoch 57 : weight has update
Oleic epoch 58 |  train loss:0.004106894601136446,test loss:0.004563531372696161,r:0.5120537685241011
Oleic epoch 59 |  train loss:0.004068155772984028,test loss:0.004418250173330307,r:0.5196382810064448
