True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (17086, 18)
trait shape (1, 17086)
df shape (20087, 42195)
(5000, 32032) (12086, 32032)
train dataset already completed!
5000
test dataset already completed!
12086
MG epoch 1 | train loss:2.329192638397217,test loss:5.691605567932129,acc:0.09009807504873295,recall:0.09521531100478463,f1:0.015661854205385243,pre:0.008576499645578594
epoch 1 : weight has update
MG epoch 2 | train loss:1.991871953010559,test loss:3.136936664581299,acc:0.21868299220272905,recall:0.0965654648882107,f1:0.04741515420925612,pre:0.05831089391798929
epoch 2 : weight has update
MG epoch 3 | train loss:1.7507504224777222,test loss:2.2955362796783447,acc:0.11482090643274853,recall:0.10549738724039529,f1:0.042245568801033063,pre:0.06763598234872836
MG epoch 4 | train loss:1.6484825611114502,test loss:1.8374061584472656,acc:0.3112390350877193,recall:0.19119478589490457,f1:0.1227609970595937,pre:0.18029423982931753
epoch 4 : weight has update
MG epoch 5 | train loss:1.5670926570892334,test loss:1.8397631645202637,acc:0.3226303606237817,recall:0.2225080188843206,f1:0.16529610071229028,pre:0.20845249898541357
epoch 5 : weight has update
MG epoch 6 | train loss:1.5381525754928589,test loss:1.6392680406570435,acc:0.3925804093567251,recall:0.30624191545485213,f1:0.244798683493403,pre:0.29238562744980956
epoch 6 : weight has update
MG epoch 7 | train loss:1.5281517505645752,test loss:1.6571791172027588,acc:0.3949774610136452,recall:0.2995343182445417,f1:0.23381987949753133,pre:0.2594890665568188
MG epoch 8 | train loss:1.465137243270874,test loss:3.263850212097168,acc:0.15610380116959063,recall:0.1263780095542745,f1:0.06708935972895885,pre:0.10791334434667693
MG epoch 9 | train loss:1.4206345081329346,test loss:1.5356014966964722,acc:0.43414961013645226,recall:0.3597442297946356,f1:0.3259470043306308,pre:0.38717436892495105
epoch 9 : weight has update
MG epoch 10 | train loss:1.3919538259506226,test loss:1.4383609294891357,acc:0.43382066276803116,recall:0.3471803496463743,f1:0.2952753300752501,pre:0.3754584335256966
MG epoch 11 | train loss:1.3795312643051147,test loss:1.5757029056549072,acc:0.4389102095516569,recall:0.3664111914337578,f1:0.3348264465179895,pre:0.39916784299159613
epoch 11 : weight has update
MG epoch 12 | train loss:1.3527801036834717,test loss:2.347222089767456,acc:0.32694627192982456,recall:0.26543387841376614,f1:0.1883063030309838,pre:0.2128546970209051
MG epoch 13 | train loss:1.3533198833465576,test loss:1.7854681015014648,acc:0.371744030214425,recall:0.2891533299768591,f1:0.2277502000545611,pre:0.263990172705417
MG epoch 14 | train loss:1.3301583528518677,test loss:1.8464266061782837,acc:0.3296600877192982,recall:0.2247749547787946,f1:0.18274645292603803,pre:0.24373790959734942
MG epoch 15 | train loss:1.3482227325439453,test loss:2.0330841541290283,acc:0.33883101851851855,recall:0.27835756215025664,f1:0.19318587792433206,pre:0.23187936981052154
MG epoch 16 | train loss:1.326715111732483,test loss:1.3232645988464355,acc:0.4812195419103314,recall:0.40149716938935986,f1:0.37335592414691937,pre:0.43662325766356413
epoch 16 : weight has update
MG epoch 17 | train loss:1.2998663187026978,test loss:1.260669469833374,acc:0.5057048001949318,recall:0.44335008941011705,f1:0.4270261355383439,pre:0.4762399706429818
epoch 17 : weight has update
MG epoch 18 | train loss:1.2958265542984009,test loss:1.604473352432251,acc:0.397337962962963,recall:0.3388722165239936,f1:0.2734819205853771,pre:0.3137982263541777
MG epoch 19 | train loss:1.283414363861084,test loss:3.0533881187438965,acc:0.21679459064327486,recall:0.22983775794994746,f1:0.14085012061683055,pre:0.1511614333915936
MG epoch 20 | train loss:1.2925766706466675,test loss:1.3542537689208984,acc:0.4628898635477583,recall:0.405627987459345,f1:0.3652573141373295,pre:0.41817381080801164
MG epoch 21 | train loss:1.2976430654525757,test loss:1.388244390487671,acc:0.4634381091617934,recall:0.3899270598009627,f1:0.33542390347991524,pre:0.37707637445497527
MG epoch 22 | train loss:1.2670942544937134,test loss:2.4682490825653076,acc:0.31175377680311894,recall:0.24772101680278816,f1:0.16897052052700876,pre:0.14144746161988536
MG epoch 23 | train loss:1.2541348934173584,test loss:1.5730431079864502,acc:0.4182565789473684,recall:0.35283327889914257,f1:0.29153874353254783,pre:0.35538500894461067
MG epoch 24 | train loss:1.237818956375122,test loss:1.3239046335220337,acc:0.4885690789473684,recall:0.43118971677469115,f1:0.38868939791409934,pre:0.43424875562729764
MG epoch 25 | train loss:1.240399956703186,test loss:1.4176968336105347,acc:0.4488395467836257,recall:0.3649514482777494,f1:0.3070907578164134,pre:0.40803333271677733
MG epoch 26 | train loss:1.238348364830017,test loss:1.2855467796325684,acc:0.49458150584795324,recall:0.4401205467375961,f1:0.40534302099812486,pre:0.4526862031903501
MG epoch 27 | train loss:1.2194803953170776,test loss:1.7381796836853027,acc:0.3866288986354776,recall:0.31643113318705907,f1:0.2429739321840139,pre:0.30490866549169415
MG epoch 28 | train loss:1.23284113407135,test loss:1.2297582626342773,acc:0.5116471734892788,recall:0.46706919562667926,f1:0.4499706231243617,pre:0.479856942259855
epoch 28 : weight has update
MG epoch 29 | train loss:1.2105519771575928,test loss:2.012831687927246,acc:0.3388797514619883,recall:0.29318561261563614,f1:0.20314210518347722,pre:0.22691470152896437
MG epoch 30 | train loss:1.2071536779403687,test loss:1.3396795988082886,acc:0.475462962962963,recall:0.4022805720557198,f1:0.3619371287866745,pre:0.43196315621831094
MG epoch 31 | train loss:1.2066025733947754,test loss:1.6505509614944458,acc:0.4198221247563353,recall:0.34237311323185515,f1:0.28466191543173974,pre:0.33227195330441717
MG epoch 32 | train loss:1.1972951889038086,test loss:1.2494211196899414,acc:0.5067951998050683,recall:0.4439457490533833,f1:0.41717556948402296,pre:0.4481366763145442
MG epoch 33 | train loss:1.1833031177520752,test loss:1.9175044298171997,acc:0.3480384990253411,recall:0.2764436665296725,f1:0.20120131555794418,pre:0.21983295172349993
MG epoch 34 | train loss:1.187403917312622,test loss:1.3585134744644165,acc:0.4641660575048733,recall:0.3920092423445061,f1:0.3477736343872535,pre:0.4142517402236164
MG epoch 35 | train loss:1.1727226972579956,test loss:1.2040878534317017,acc:0.5262335526315789,recall:0.48863906121624795,f1:0.4708491237036854,pre:0.5017934547509292
epoch 35 : weight has update
MG epoch 36 | train loss:1.1803218126296997,test loss:1.4264148473739624,acc:0.4479166666666667,recall:0.4030442965182084,f1:0.35383454349572324,pre:0.42432087329588186
MG epoch 37 | train loss:1.1715508699417114,test loss:1.4700344800949097,acc:0.4455196150097466,recall:0.38550545190833785,f1:0.32975383649597584,pre:0.40038814149932234
MG epoch 38 | train loss:1.1628873348236084,test loss:1.302822232246399,acc:0.48492933723196885,recall:0.4131291693424249,f1:0.38981051574821485,pre:0.4713870313883099
MG epoch 39 | train loss:1.1696034669876099,test loss:1.4027926921844482,acc:0.444806895711501,recall:0.3932296741830563,f1:0.3504217393094938,pre:0.44642800126213966
MG epoch 40 | train loss:1.1522811651229858,test loss:1.3638871908187866,acc:0.4739522417153996,recall:0.423346044894415,f1:0.3839533007369406,pre:0.46514886235247566
MG epoch 41 | train loss:1.1642029285430908,test loss:1.864236831665039,acc:0.3649579678362573,recall:0.310974983988356,f1:0.21267345912110558,pre:0.22077513318136952
MG epoch 42 | train loss:1.1546190977096558,test loss:1.2412577867507935,acc:0.5108644005847953,recall:0.45568008175561,f1:0.4293064640898985,pre:0.4967104869094624
MG epoch 43 | train loss:1.1539071798324585,test loss:1.8041772842407227,acc:0.36933784113060425,recall:0.3211413844255273,f1:0.25278089553384475,pre:0.3278705042260635
MG epoch 44 | train loss:1.1562933921813965,test loss:1.3451507091522217,acc:0.47090034113060425,recall:0.41983732695805415,f1:0.3692864860661163,pre:0.43881161649296074
MG epoch 45 | train loss:1.145001769065857,test loss:1.176676630973816,acc:0.5310550682261208,recall:0.48690519720218467,f1:0.47430342030916767,pre:0.5286330253687006
epoch 45 : weight has update
MG epoch 46 | train loss:1.1431348323822021,test loss:1.199830174446106,acc:0.5286976120857699,recall:0.4861352272676846,f1:0.4635630513614355,pre:0.5032458514473507
MG epoch 47 | train loss:1.1350294351577759,test loss:1.3131258487701416,acc:0.4802509746588694,recall:0.43527920521954444,f1:0.3998310671940236,pre:0.4846026992695963
MG epoch 48 | train loss:1.14851713180542,test loss:1.24910306930542,acc:0.5041118421052632,recall:0.4320412008808893,f1:0.4163693715660072,pre:0.49177092896489927
MG epoch 49 | train loss:1.1269418001174927,test loss:1.1758846044540405,acc:0.5365314327485381,recall:0.5023872940695255,f1:0.48157168222940344,pre:0.5106195714468376
epoch 49 : weight has update
MG epoch 50 | train loss:1.1365090608596802,test loss:1.3951159715652466,acc:0.4722344054580897,recall:0.4153649741037147,f1:0.37100530251148306,pre:0.44925138130017633
MG epoch 51 | train loss:1.123967170715332,test loss:2.9652597904205322,acc:0.17407102826510723,recall:0.15325263082552493,f1:0.09716895528235076,pre:0.14532575157225647
MG epoch 52 | train loss:1.1190369129180908,test loss:1.2590336799621582,acc:0.5130969785575049,recall:0.47291960034829555,f1:0.45283911750337585,pre:0.5160796219539631
MG epoch 53 | train loss:1.133257269859314,test loss:1.2403675317764282,acc:0.5060032894736842,recall:0.4513658754344493,f1:0.4276242406275364,pre:0.5103291905898839
MG epoch 54 | train loss:1.137023687362671,test loss:1.3059724569320679,acc:0.4856786062378168,recall:0.42413492786497903,f1:0.38794133834041344,pre:0.4578275579619099
MG epoch 55 | train loss:1.1209439039230347,test loss:1.1935186386108398,acc:0.5379325048732944,recall:0.4755100861190349,f1:0.46875823819640944,pre:0.5267258114223871
MG epoch 56 | train loss:1.1126697063446045,test loss:1.19319486618042,acc:0.5243116471734893,recall:0.4862518650003193,f1:0.4626681165368924,pre:0.49154445443909855
MG epoch 57 | train loss:1.13555109500885,test loss:1.235907793045044,acc:0.5144706384015594,recall:0.45388603603366867,f1:0.43030136936529395,pre:0.48880956517691226
MG epoch 58 | train loss:1.1173207759857178,test loss:1.1700140237808228,acc:0.5337658382066276,recall:0.49608721984783355,f1:0.48064321137425475,pre:0.5187635298622162
MG epoch 59 | train loss:1.1157861948013306,test loss:1.216410756111145,acc:0.527774731968811,recall:0.482745225792792,f1:0.47043246502806385,pre:0.5215420137739073
MG epoch 60 | train loss:1.1166452169418335,test loss:1.2530924081802368,acc:0.505765716374269,recall:0.4533702037318983,f1:0.41943484767513295,pre:0.47118370535379134
MG epoch 61 | train loss:1.1032543182373047,test loss:1.1874035596847534,acc:0.5476973684210527,recall:0.49799770569081514,f1:0.4953431182785354,pre:0.5393634859300562
epoch 61 : weight has update
MG epoch 62 | train loss:1.0833909511566162,test loss:1.3698962926864624,acc:0.47089120370370374,recall:0.4221270969738895,f1:0.38272884257190626,pre:0.4690510607704119
MG epoch 63 | train loss:1.1019277572631836,test loss:1.2935867309570312,acc:0.49568104288499026,recall:0.4461913014794919,f1:0.4139587752524838,pre:0.47689291023591757
MG epoch 64 | train loss:1.1184954643249512,test loss:1.175929069519043,acc:0.5412402534113061,recall:0.49688157579821707,f1:0.485597096478998,pre:0.5225265922967487
MG epoch 65 | train loss:1.1167317628860474,test loss:2.115286111831665,acc:0.3343171296296296,recall:0.2807263291317846,f1:0.20847832420698892,pre:0.24891207928051656
MG epoch 66 | train loss:1.0998854637145996,test loss:1.1806772947311401,acc:0.5350633528265107,recall:0.4838331119111696,f1:0.46397625799333647,pre:0.5198163153306185
MG epoch 67 | train loss:1.1046253442764282,test loss:1.2674741744995117,acc:0.5044925682261209,recall:0.45764183972427425,f1:0.43758627967626385,pre:0.5076609948114503
MG epoch 68 | train loss:1.1216243505477905,test loss:1.3586959838867188,acc:0.4787615740740741,recall:0.42760228169905895,f1:0.39249476998234606,pre:0.4681691791341771
MG epoch 69 | train loss:1.0938719511032104,test loss:1.184402585029602,acc:0.5330287524366472,recall:0.48839058387382184,f1:0.48002446512696795,pre:0.5225346714136201
MG epoch 70 | train loss:1.0925171375274658,test loss:1.6792303323745728,acc:0.3848501461988304,recall:0.3156388990578544,f1:0.2783717364295459,pre:0.41078753952149083
MG epoch 71 | train loss:1.100083351135254,test loss:1.1666297912597656,acc:0.5465551900584795,recall:0.5100737311671965,f1:0.5006783963105464,pre:0.533582997094526
epoch 71 : weight has update
MG epoch 72 | train loss:1.1051493883132935,test loss:1.2049692869186401,acc:0.5308570906432749,recall:0.48207725228479753,f1:0.46888148230591986,pre:0.5145706878680034
MG epoch 73 | train loss:1.1005033254623413,test loss:1.2633123397827148,acc:0.5052022417153996,recall:0.4641404540682034,f1:0.435110248397021,pre:0.49864477934612517
MG epoch 74 | train loss:1.08613121509552,test loss:1.3808255195617676,acc:0.46017909356725145,recall:0.4092065263493471,f1:0.36811638517588174,pre:0.4554353354158739
MG epoch 75 | train loss:1.0969520807266235,test loss:1.2478994131088257,acc:0.519191642300195,recall:0.49434299098487106,f1:0.4778350253976348,pre:0.5207585420591161
MG epoch 76 | train loss:1.0794730186462402,test loss:1.3051981925964355,acc:0.4949957358674464,recall:0.4417825405845879,f1:0.41395980336051535,pre:0.4704835469870664
MG epoch 77 | train loss:1.1037917137145996,test loss:1.1854764223098755,acc:0.5397813109161793,recall:0.4875342274868706,f1:0.46505678687722196,pre:0.5008408825442376
MG epoch 78 | train loss:1.0865904092788696,test loss:1.296949028968811,acc:0.4921875,recall:0.44041712216888046,f1:0.42087453684207204,pre:0.49872709475872956
MG epoch 79 | train loss:1.0852575302124023,test loss:1.1721547842025757,acc:0.5417945906432748,recall:0.5181547287921143,f1:0.501373130952815,pre:0.5239722296355539
MG epoch 80 | train loss:1.0819417238235474,test loss:1.374938726425171,acc:0.4743421052631579,recall:0.43055957802641587,f1:0.3955277768013052,pre:0.5010410263854218
MG epoch 81 | train loss:1.0842759609222412,test loss:1.618617057800293,acc:0.41085830896686165,recall:0.36753396656873094,f1:0.3085189587334311,pre:0.44411550317139664
MG epoch 82 | train loss:1.0774399042129517,test loss:1.2922651767730713,acc:0.4990344785575049,recall:0.4453693585551998,f1:0.42128525177477716,pre:0.518014296248306
MG epoch 83 | train loss:1.0836982727050781,test loss:1.5731470584869385,acc:0.4317647417153996,recall:0.38453088110209643,f1:0.3448365796653883,pre:0.4415060281823911
MG epoch 84 | train loss:1.0946789979934692,test loss:1.5849467515945435,acc:0.43223684210526314,recall:0.3905207439950098,f1:0.3396665713406574,pre:0.42130274523540934
MG epoch 85 | train loss:1.0725443363189697,test loss:1.3514394760131836,acc:0.4813230994152047,recall:0.43701783022144614,f1:0.39935712782833904,pre:0.4951422721437605
MG epoch 86 | train loss:1.0941441059112549,test loss:1.1508220434188843,acc:0.5489522417153996,recall:0.5140729950652592,f1:0.5051817141977016,pre:0.5258466799777277
epoch 86 : weight has update
MG epoch 87 | train loss:1.0800302028656006,test loss:1.350096583366394,acc:0.47624573586744634,recall:0.4220711260510191,f1:0.38978335252344076,pre:0.48719419018693305
MG epoch 88 | train loss:1.0806117057800293,test loss:1.1931747198104858,acc:0.5294194688109162,recall:0.4907826310989331,f1:0.4761073315684048,pre:0.5149615135840201
MG epoch 89 | train loss:1.0792512893676758,test loss:1.4613243341445923,acc:0.4459703947368421,recall:0.40763923927548606,f1:0.35910999977565483,pre:0.4881899582662405
MG epoch 90 | train loss:1.068413257598877,test loss:1.4619898796081543,acc:0.43958942495126707,recall:0.40924505972008257,f1:0.3481467244164979,pre:0.44909876996870246
MG epoch 91 | train loss:1.0800977945327759,test loss:1.5305203199386597,acc:0.45098988791423006,recall:0.4137751817215945,f1:0.36474801502739645,pre:0.44729457549856233
MG epoch 92 | train loss:1.0736106634140015,test loss:1.203165054321289,acc:0.5347557261208576,recall:0.49637114253661513,f1:0.4822044521468154,pre:0.5334395439062604
MG epoch 93 | train loss:1.0692894458770752,test loss:1.2140717506408691,acc:0.5258436890838206,recall:0.48005645384441664,f1:0.4604678597442386,pre:0.5072906737807628
MG epoch 94 | train loss:1.058680534362793,test loss:1.449661135673523,acc:0.45758711013645226,recall:0.3903807275948497,f1:0.34862959149838774,pre:0.44809640905605214
MG epoch 95 | train loss:1.0782124996185303,test loss:1.312691569328308,acc:0.4947063840155945,recall:0.4404104137008012,f1:0.42807120890793793,pre:0.5227848486510737
MG epoch 96 | train loss:1.076591968536377,test loss:1.3124674558639526,acc:0.4894858674463937,recall:0.4351447147507657,f1:0.4130095137133253,pre:0.5172530345055232
MG epoch 97 | train loss:1.0864222049713135,test loss:1.4155399799346924,acc:0.4521899366471735,recall:0.4039357399784287,f1:0.3515343351793499,pre:0.46838229884853977
MG epoch 98 | train loss:1.068934679031372,test loss:1.290443778038025,acc:0.4973897417153996,recall:0.4494032742349289,f1:0.427275977146292,pre:0.5041625451207985
MG epoch 99 | train loss:1.072650671005249,test loss:1.21048903465271,acc:0.5264589424951267,recall:0.479063654310578,f1:0.4562870311914526,pre:0.5028512358381649
MG epoch 100 | train loss:1.0783090591430664,test loss:1.2411167621612549,acc:0.5161245126705652,recall:0.4816393279471902,f1:0.4540265351165908,pre:0.5057216989964815
MG epoch 101 | train loss:1.0655968189239502,test loss:1.1761709451675415,acc:0.5474506578947368,recall:0.5011225233684731,f1:0.49551231211264474,pre:0.5417757977761153
MG epoch 102 | train loss:1.0670926570892334,test loss:1.2618954181671143,acc:0.5149762426900585,recall:0.4711816288619939,f1:0.45089350208799184,pre:0.5010747958348786
MG epoch 103 | train loss:1.0633299350738525,test loss:1.1588661670684814,acc:0.5462993421052632,recall:0.5164160677159988,f1:0.5070105870611692,pre:0.5422427313278112
epoch 103 : weight has update
MG epoch 104 | train loss:1.0647603273391724,test loss:1.3003838062286377,acc:0.4891142787524366,recall:0.4329889251557003,f1:0.40398052061549056,pre:0.504179290870482
MG epoch 105 | train loss:1.0659172534942627,test loss:1.2757172584533691,acc:0.5286366959064328,recall:0.4981643307487489,f1:0.4793725314679713,pre:0.5227762148481271
MG epoch 106 | train loss:1.067553162574768,test loss:1.4492695331573486,acc:0.45747441520467835,recall:0.4196352152954036,f1:0.36971914568627534,pre:0.4725971396447957
MG epoch 107 | train loss:1.0823734998703003,test loss:1.1826472282409668,acc:0.5280427631578948,recall:0.476089779545181,f1:0.46063601296349743,pre:0.516662392016638
MG epoch 108 | train loss:1.0669994354248047,test loss:1.4460641145706177,acc:0.4397417153996101,recall:0.3965414040510439,f1:0.3632695127307672,pre:0.48503359710006533
MG epoch 109 | train loss:1.076352596282959,test loss:1.573981761932373,acc:0.40896381578947366,recall:0.37810931330277137,f1:0.3109664830685615,pre:0.42925956973244983
MG epoch 110 | train loss:1.0486218929290771,test loss:1.22295343875885,acc:0.5173824317738791,recall:0.46270657238546486,f1:0.4523772072635043,pre:0.514133315722877
MG epoch 111 | train loss:1.0590319633483887,test loss:1.2939801216125488,acc:0.4948099415204678,recall:0.45259230742053336,f1:0.4196134464312149,pre:0.5069332823029695
MG epoch 112 | train loss:1.0791690349578857,test loss:1.25839364528656,acc:0.5024579678362573,recall:0.4410519667051355,f1:0.4259174476818355,pre:0.5070167775828788
MG epoch 113 | train loss:1.0687943696975708,test loss:1.194745421409607,acc:0.5254203216374269,recall:0.48783516960815954,f1:0.4721066796532339,pre:0.5179484913504431
MG epoch 114 | train loss:1.0620946884155273,test loss:1.1760960817337036,acc:0.5395955165692008,recall:0.49498044759470256,f1:0.47931552082096984,pre:0.5168551773037948
MG epoch 115 | train loss:1.0656229257583618,test loss:1.2041444778442383,acc:0.5481786062378168,recall:0.5084698668022788,f1:0.4997184188297885,pre:0.527768326567264
MG epoch 116 | train loss:1.0627292394638062,test loss:1.204878807067871,acc:0.5249177631578947,recall:0.4843354452169758,f1:0.4512688406862565,pre:0.5023981786180466
MG epoch 117 | train loss:1.0535805225372314,test loss:1.358754277229309,acc:0.4802540204678362,recall:0.45040572110456517,f1:0.41627081180345016,pre:0.5011513891389318
MG epoch 118 | train loss:1.0681148767471313,test loss:1.212488055229187,acc:0.5255847953216375,recall:0.4882368784500868,f1:0.46101981926830476,pre:0.5271696224859739
MG epoch 119 | train loss:1.0755294561386108,test loss:1.2189481258392334,acc:0.5317099171539961,recall:0.4823978394845773,f1:0.47422249240240305,pre:0.5309933340357033
MG epoch 120 | train loss:1.0407572984695435,test loss:1.26658296585083,acc:0.5102095516569201,recall:0.47806461634249453,f1:0.45630701917261646,pre:0.5245906265106617
MG epoch 121 | train loss:1.0562410354614258,test loss:1.1577634811401367,acc:0.5465034113060429,recall:0.5166223722097835,f1:0.5039557734896198,pre:0.5344662416216932
MG epoch 122 | train loss:1.0423614978790283,test loss:1.227049469947815,acc:0.523900462962963,recall:0.47637307273595086,f1:0.45965736969676435,pre:0.5100554767364716
MG epoch 123 | train loss:1.0518864393234253,test loss:1.1865630149841309,acc:0.5349384746588695,recall:0.4903356879307103,f1:0.48266766371867115,pre:0.528934010857544
MG epoch 124 | train loss:1.0558011531829834,test loss:1.1712044477462769,acc:0.5386299951267056,recall:0.49754855602675674,f1:0.4897238919994639,pre:0.5275389120643823
MG epoch 125 | train loss:1.052451729774475,test loss:1.5612562894821167,acc:0.4055129142300195,recall:0.360647575005483,f1:0.29466399890559236,pre:0.4018271189093793
MG epoch 126 | train loss:1.0617300271987915,test loss:1.2849373817443848,acc:0.5047697368421052,recall:0.46909984776053604,f1:0.44385824205381735,pre:0.5141051115284987
MG epoch 127 | train loss:1.0541653633117676,test loss:1.2788374423980713,acc:0.5108339424951267,recall:0.462860229733637,f1:0.4473643175649251,pre:0.5180463837026158
MG epoch 128 | train loss:1.0682936906814575,test loss:1.1889828443527222,acc:0.5326571637426901,recall:0.47684197497408504,f1:0.45446128124309404,pre:0.49543196163840886
MG epoch 129 | train loss:1.054414987564087,test loss:1.3550868034362793,acc:0.4888980263157895,recall:0.45543502945310477,f1:0.42667467259229364,pre:0.5219159402110608
MG epoch 130 | train loss:1.0470737218856812,test loss:1.2848514318466187,acc:0.49592775341130607,recall:0.4717511818225328,f1:0.45590347611957116,pre:0.526114280189976
MG epoch 131 | train loss:1.0282375812530518,test loss:1.295947551727295,acc:0.49565363060428846,recall:0.46957878423485877,f1:0.4417097170107036,pre:0.5134807261764174
MG epoch 132 | train loss:1.0488471984863281,test loss:1.2513062953948975,acc:0.5153569688109162,recall:0.47773112080839397,f1:0.469045601604745,pre:0.5377608926668733
MG epoch 133 | train loss:1.0455801486968994,test loss:1.2197022438049316,acc:0.528103679337232,recall:0.49228482118228883,f1:0.4712892293648288,pre:0.5100404789006349
MG epoch 134 | train loss:1.0503517389297485,test loss:1.2727711200714111,acc:0.5111111111111112,recall:0.49227228118499256,f1:0.4684021545667444,pre:0.5315535750987844
MG epoch 135 | train loss:1.0456860065460205,test loss:1.1508980989456177,acc:0.5496588693957115,recall:0.5025523382916478,f1:0.49575964759985724,pre:0.5484979266936211
MG epoch 136 | train loss:1.0331782102584839,test loss:1.5600653886795044,acc:0.4399792884990253,recall:0.3935119371854157,f1:0.3410957217923369,pre:0.4331655586883622
MG epoch 137 | train loss:1.0262975692749023,test loss:1.1832354068756104,acc:0.5386299951267056,recall:0.5029179232436197,f1:0.48554055483571545,pre:0.5288040990444023
MG epoch 138 | train loss:1.0350955724716187,test loss:1.6756072044372559,acc:0.4089668615984406,recall:0.38639979989102463,f1:0.33320581284690365,pre:0.4736963461542016
MG epoch 139 | train loss:1.026292324066162,test loss:1.2497241497039795,acc:0.516858552631579,recall:0.4509355732290047,f1:0.4357929821612992,pre:0.5080349714631718
MG epoch 140 | train loss:1.0447423458099365,test loss:1.2284612655639648,acc:0.5157894736842106,recall:0.45529712918174914,f1:0.43332811995765025,pre:0.49177723787719085
MG epoch 141 | train loss:1.0583034753799438,test loss:1.2803549766540527,acc:0.49733796296296295,recall:0.45677068417466693,f1:0.42513812058638156,pre:0.48746799433386034
MG epoch 142 | train loss:1.0332167148590088,test loss:1.1927450895309448,acc:0.5292580409356725,recall:0.49730981515538214,f1:0.4736839173856799,pre:0.49127063260597065
MG epoch 143 | train loss:1.0287528038024902,test loss:1.2696300745010376,acc:0.4994761208576998,recall:0.463466667628779,f1:0.44094325600952444,pre:0.5113458667957202
MG epoch 144 | train loss:1.0430727005004883,test loss:1.1594593524932861,acc:0.550615253411306,recall:0.5130862747191364,f1:0.502588081598248,pre:0.5276683683587634
MG epoch 145 | train loss:1.0380351543426514,test loss:1.1792620420455933,acc:0.5378776803118908,recall:0.4846490189069551,f1:0.47868231816949375,pre:0.5267674827493893
MG epoch 146 | train loss:1.0334656238555908,test loss:1.2387179136276245,acc:0.5149457846003899,recall:0.46620011898920327,f1:0.4412617605141016,pre:0.4915674627190909
MG epoch 147 | train loss:1.0421746969223022,test loss:1.3031855821609497,acc:0.5018792641325537,recall:0.44932623141031924,f1:0.42187933426275037,pre:0.5055558075624
MG epoch 148 | train loss:1.0415223836898804,test loss:1.2979813814163208,acc:0.49629934210526316,recall:0.4581101598707159,f1:0.4317069075020784,pre:0.4948009095631469
MG epoch 149 | train loss:1.0293992757797241,test loss:2.4965126514434814,acc:0.3554824561403509,recall:0.282113553451438,f1:0.21413676377430557,pre:0.20127084147515004
MG epoch 150 | train loss:1.031042218208313,test loss:2.0350537300109863,acc:0.3019980506822612,recall:0.2493295949917069,f1:0.19344713534368754,pre:0.2407023155820235
training has finished used time : 4010.316842317581
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (15873, 18)
trait shape (1, 15873)
df shape (20087, 42195)
(5000, 32032) (10873, 32032)
train dataset already completed!
5000
test dataset already completed!
10873
SQ epoch 1 | train loss:1.089414119720459,test loss:0.9770616888999939,acc:0.4405885391346621,recall:0.24686274509803907,f1:0.1509543661855029,pre:0.10902121566601847
epoch 1 : weight has update
SQ epoch 2 | train loss:0.975401759147644,test loss:0.9512511491775513,acc:0.4407108349538162,recall:0.25274509803921563,f1:0.15439434100589144,pre:0.11152727981688546
epoch 2 : weight has update
SQ epoch 3 | train loss:0.978104829788208,test loss:0.9807286262512207,acc:0.4406044907632475,recall:0.2498039215686273,f1:0.1526139804037098,pre:0.1102889903378707
SQ epoch 4 | train loss:0.9775060415267944,test loss:0.9525708556175232,acc:0.4905817027224113,recall:0.24843137254901945,f1:0.16340796470823002,pre:0.12211233744530871
epoch 4 : weight has update
SQ epoch 5 | train loss:0.9787997007369995,test loss:0.9765611886978149,acc:0.4905923371414681,recall:0.2476470588235293,f1:0.16306575160971945,pre:0.12188249473343053
SQ epoch 6 | train loss:0.9881382584571838,test loss:1.0773301124572754,acc:0.4406044907632475,recall:0.2505882352941175,f1:0.15303587449364653,pre:0.11041256481931616
SQ epoch 7 | train loss:0.9884520173072815,test loss:0.9496718645095825,acc:0.49060828877005347,recall:0.24803921568627438,f1:0.16268253589371925,pre:0.12133620209447417
SQ epoch 8 | train loss:0.9745747447013855,test loss:1.0755541324615479,acc:0.49059765435099656,recall:0.24647058823529402,f1:0.16193650183999359,pre:0.12092453613676873
SQ epoch 9 | train loss:0.9690119624137878,test loss:1.0479445457458496,acc:0.49057638551288285,recall:0.2445098039215685,f1:0.16078974980069932,pre:0.12003010553394915
SQ epoch 10 | train loss:0.9611167311668396,test loss:1.0116950273513794,acc:0.490602971560525,recall:0.24999999999999986,f1:0.1644454900157908,pre:0.12283566784151675
epoch 10 : weight has update
SQ epoch 11 | train loss:0.953116774559021,test loss:1.0173945426940918,acc:0.4406151251823043,recall:0.24725490196078423,f1:0.1512314018252627,pre:0.10921934502106627
SQ epoch 12 | train loss:0.9576676487922668,test loss:0.9483757019042969,acc:0.4905444822557122,recall:0.2474509803921567,f1:0.1629271127198607,pre:0.12177214997569276
SQ epoch 13 | train loss:0.9616166353225708,test loss:0.9524787664413452,acc:0.490565751093826,recall:0.2503921568627449,f1:0.1647117970038193,pre:0.12300438796386326
epoch 13 : weight has update
SQ epoch 14 | train loss:0.9566546082496643,test loss:0.9483920335769653,acc:0.44062575960136124,recall:0.2515686274509803,f1:0.15386169443730205,pre:0.11108015313563442
SQ epoch 15 | train loss:0.9568995237350464,test loss:0.9462332725524902,acc:0.4406789316966456,recall:0.24725490196078426,f1:0.15118908296750105,pre:0.10932108096337709
SQ epoch 16 | train loss:0.9555826783180237,test loss:0.9569721221923828,acc:0.490565751093826,recall:0.24725490196078417,f1:0.1628571775981808,pre:0.12177252977637337
SQ epoch 17 | train loss:0.9574360847473145,test loss:0.9449899196624756,acc:0.4905710683033544,recall:0.2501960784313724,f1:0.16470468377040634,pre:0.1230973631704748
SQ epoch 18 | train loss:0.9597010612487793,test loss:0.9495900273323059,acc:0.4405885391346621,recall:0.25117647058823517,f1:0.1533557566026083,pre:0.11063426713660672
SQ epoch 19 | train loss:0.9566887021064758,test loss:0.9563117623329163,acc:0.44062575960136124,recall:0.254313725490196,f1:0.15545266726755483,pre:0.11227660123966944
SQ epoch 20 | train loss:0.9533759951591492,test loss:0.9465224742889404,acc:0.44065766285853186,recall:0.250392156862745,f1:0.15292390992477284,pre:0.11041836310970668
SQ epoch 21 | train loss:0.9532609581947327,test loss:0.9432904720306396,acc:0.49050194457948465,recall:0.24784313725490184,f1:0.16288218444883604,pre:0.12157924921001459
SQ epoch 22 | train loss:0.9551435708999634,test loss:0.9519222378730774,acc:0.490565751093826,recall:0.2501960784313725,f1:0.1645603689768811,pre:0.1228849026697456
SQ epoch 23 | train loss:0.9564953446388245,test loss:0.9457444548606873,acc:0.49052853062712687,recall:0.24921568627450968,f1:0.1636917584243664,pre:0.12218138520904231
SQ epoch 24 | train loss:0.9544668793678284,test loss:0.9410944581031799,acc:0.49057638551288285,recall:0.24784313725490176,f1:0.16293810438431905,pre:0.12164379000567167
SQ epoch 25 | train loss:0.953102707862854,test loss:0.9392260313034058,acc:0.4906242403986388,recall:0.24843137254901948,f1:0.163596723929065,pre:0.12223632970750284
SQ epoch 26 | train loss:0.9527317881584167,test loss:0.9518793821334839,acc:0.44063639402041804,recall:0.24450980392156843,f1:0.14931955987024786,pre:0.10785517693647707
SQ epoch 27 | train loss:0.953679621219635,test loss:0.9459842443466187,acc:0.49056043388429754,recall:0.2476470588235293,f1:0.16284120525648835,pre:0.1215649054043105
SQ epoch 28 | train loss:0.952680766582489,test loss:0.9474141001701355,acc:0.4906136059795819,recall:0.24843137254901945,f1:0.16346780219382523,pre:0.12213256816156215
SQ epoch 29 | train loss:0.9536988735198975,test loss:0.9449208378791809,acc:0.4905551166747691,recall:0.2496078431372548,f1:0.16400072076944702,pre:0.12242585024712364
SQ epoch 30 | train loss:0.9541379809379578,test loss:0.9477313756942749,acc:0.49054979946524063,recall:0.248235294117647,f1:0.16345165122243888,pre:0.12210589349376114
SQ epoch 31 | train loss:0.9531177878379822,test loss:0.9418076872825623,acc:0.4905551166747691,recall:0.24529411764705872,f1:0.1611292270545379,pre:0.12035170809026093
SQ epoch 32 | train loss:0.9539744257926941,test loss:0.947827160358429,acc:0.4406523456490034,recall:0.24274509803921548,f1:0.1486031423613742,pre:0.1073030986671528
SQ epoch 33 | train loss:0.9553773403167725,test loss:0.943462610244751,acc:0.44064702843947495,recall:0.24745098039215677,f1:0.15122989123768624,pre:0.10915072769810405
SQ epoch 34 | train loss:0.9523187279701233,test loss:0.9555684924125671,acc:0.4406098079727758,recall:0.25333333333333324,f1:0.15457103009083553,pre:0.1115359899124939
SQ epoch 35 | train loss:0.9538793563842773,test loss:0.9495616555213928,acc:0.4406044907632475,recall:0.24999999999999992,f1:0.1528024962229668,pre:0.11040234818100794
SQ epoch 36 | train loss:0.9539320468902588,test loss:0.9442024827003479,acc:0.49056043388429754,recall:0.2513725490196077,f1:0.16495167334081234,pre:0.12312877268676066
epoch 36 : weight has update
SQ epoch 37 | train loss:0.9500678777694702,test loss:0.9487433433532715,acc:0.4905232134175984,recall:0.2460784313725489,f1:0.1617378902345854,pre:0.12072719170312755
SQ epoch 38 | train loss:0.9519327878952026,test loss:0.9535911083221436,acc:0.440599173553719,recall:0.24784313725490187,f1:0.15140426178544972,pre:0.10939128078917519
SQ epoch 39 | train loss:0.9542297124862671,test loss:0.9416443705558777,acc:0.490565751093826,recall:0.2439215686274509,f1:0.16033602082131973,pre:0.11976578958029492
SQ epoch 40 | train loss:0.9504241943359375,test loss:0.9486658573150635,acc:0.49058701993193976,recall:0.24901960784313718,f1:0.16348286057303135,pre:0.12211556575109381
SQ epoch 41 | train loss:0.9512161016464233,test loss:0.9434307217597961,acc:0.4406098079727758,recall:0.2480392156862744,f1:0.1514985725501143,pre:0.10937962090828067
SQ epoch 42 | train loss:0.9556822180747986,test loss:0.9435805678367615,acc:0.4905817027224113,recall:0.24784313725490187,f1:0.1631264004667426,pre:0.12185651636687733
SQ epoch 43 | train loss:0.9543699026107788,test loss:0.9443634152412415,acc:0.49059765435099656,recall:0.25392156862745086,f1:0.1671074405823607,pre:0.12477410721520012
epoch 43 : weight has update
SQ epoch 44 | train loss:0.9514646530151367,test loss:0.9481568336486816,acc:0.49057638551288285,recall:0.2462745098039215,f1:0.16183632760474362,pre:0.12084109392724032
SQ epoch 45 | train loss:0.9525145888328552,test loss:0.9440832138061523,acc:0.4406310768108897,recall:0.23980392156862737,f1:0.1464584745147142,pre:0.10571689910468321
SQ epoch 46 | train loss:0.953747570514679,test loss:0.9439237713813782,acc:0.49060828877005347,recall:0.24588235294117636,f1:0.16165689156934038,pre:0.12074810606060604
SQ epoch 47 | train loss:0.9526551961898804,test loss:0.9441226720809937,acc:0.490565751093826,recall:0.2507843137254901,f1:0.1650313446823606,pre:0.12332277487441262
SQ epoch 48 | train loss:0.9523494839668274,test loss:0.9509295225143433,acc:0.4906136059795819,recall:0.2421568627450979,f1:0.158988426817107,pre:0.11871402021552424
SQ epoch 49 | train loss:0.95176100730896,test loss:0.9430634379386902,acc:0.49052853062712687,recall:0.25078431372549004,f1:0.16502431066066778,pre:0.12327704687246802
SQ epoch 50 | train loss:0.9539282321929932,test loss:0.944299578666687,acc:0.4905551166747691,recall:0.248627450980392,f1:0.16379960493250115,pre:0.12247683215848322
SQ epoch 51 | train loss:0.9499349594116211,test loss:0.9430481791496277,acc:0.490602971560525,recall:0.2507843137254901,f1:0.16495527156802706,pre:0.12327267916464106
SQ epoch 52 | train loss:0.9502804279327393,test loss:0.9437146782875061,acc:0.4406310768108897,recall:0.24372549019607828,f1:0.1489934703469309,pre:0.10749130256441418
SQ epoch 53 | train loss:0.951758861541748,test loss:0.9406054615974426,acc:0.49057638551288285,recall:0.24980392156862738,f1:0.16466276381961317,pre:0.12316582857316483
SQ epoch 54 | train loss:0.9483793377876282,test loss:0.9410022497177124,acc:0.490602971560525,recall:0.24960784313725468,f1:0.16406069015805794,pre:0.12251704039053639
SQ epoch 55 | train loss:0.9500268697738647,test loss:0.9430055022239685,acc:0.4906189231891103,recall:0.2517647058823528,f1:0.16543292298127638,pre:0.12359406650056712
SQ epoch 56 | train loss:0.9521393775939941,test loss:0.9417254328727722,acc:0.4905817027224113,recall:0.2476470588235293,f1:0.16302506187405152,pre:0.12189174921001458
SQ epoch 57 | train loss:0.9536128044128418,test loss:0.9445934891700745,acc:0.44062575960136124,recall:0.250392156862745,f1:0.15310046173905,pre:0.11058076588073246
SQ epoch 58 | train loss:0.9504063129425049,test loss:0.9422687292098999,acc:0.4905125789985416,recall:0.24901960784313715,f1:0.1634675575177529,pre:0.12196638004375304
SQ epoch 59 | train loss:0.949974775314331,test loss:0.9474167823791504,acc:0.44064702843947495,recall:0.248627450980392,f1:0.15187356918820105,pre:0.10977266397261384
SQ epoch 60 | train loss:0.9507841467857361,test loss:0.9406961798667908,acc:0.49051789620806996,recall:0.24803921568627446,f1:0.16306019520400758,pre:0.12192404492788848
SQ epoch 61 | train loss:0.9490644931793213,test loss:0.9464365243911743,acc:0.44062575960136124,recall:0.24725490196078417,f1:0.15102678788325927,pre:0.10908869358693889
SQ epoch 62 | train loss:0.9508512616157532,test loss:0.9432265758514404,acc:0.49054979946524063,recall:0.24568627450980374,f1:0.1616611691151018,pre:0.12076467803030304
SQ epoch 63 | train loss:0.9483941793441772,test loss:0.9427802562713623,acc:0.4905817027224113,recall:0.24941176470588225,f1:0.16418359135687638,pre:0.12269390090747041
SQ epoch 64 | train loss:0.952710747718811,test loss:0.9456311464309692,acc:0.49050194457948465,recall:0.24529411764705872,f1:0.16122278540733412,pre:0.1204931585237401
SQ epoch 65 | train loss:0.95131516456604,test loss:0.9475882053375244,acc:0.44063639402041804,recall:0.2513725490196077,f1:0.1537292004510964,pre:0.11101081419137904
SQ epoch 66 | train loss:0.9498810768127441,test loss:0.940369725227356,acc:0.490565751093826,recall:0.2507843137254901,f1:0.16525072820829811,pre:0.12365859463620159
SQ epoch 67 | train loss:0.950954258441925,test loss:0.9420206546783447,acc:0.490565751093826,recall:0.24901960784313718,f1:0.16397576599356084,pre:0.12252031933641223
SQ epoch 68 | train loss:0.9495337009429932,test loss:0.9406434297561646,acc:0.4905551166747691,recall:0.24705882352941164,f1:0.1626763501543559,pre:0.12153933215848325
SQ epoch 69 | train loss:0.9505409002304077,test loss:0.9408561587333679,acc:0.490602971560525,recall:0.25117647058823517,f1:0.16526278170615516,pre:0.12346722573326853
SQ epoch 70 | train loss:0.9514407515525818,test loss:0.9412825703620911,acc:0.4405885391346621,recall:0.24686274509803915,f1:0.15063075522470834,pre:0.10870718380327336
SQ epoch 71 | train loss:0.9514646530151367,test loss:0.9405099749565125,acc:0.4906136059795819,recall:0.2470588235294117,f1:0.1624404369906616,pre:0.12134365884783663
SQ epoch 72 | train loss:0.9519507884979248,test loss:0.9423673748970032,acc:0.4406310768108897,recall:0.24333333333333318,f1:0.14871185022300026,pre:0.10737590645762436
SQ epoch 73 | train loss:0.9489588737487793,test loss:0.9412083625793457,acc:0.49060828877005347,recall:0.2513725490196077,f1:0.16538629106076544,pre:0.12352523395721926
SQ epoch 74 | train loss:0.9499839544296265,test loss:0.9442441463470459,acc:0.4406523456490034,recall:0.24823529411764694,f1:0.15183292645995486,pre:0.10969280454950579
SQ epoch 75 | train loss:0.9530238509178162,test loss:0.9544679522514343,acc:0.4905232134175984,recall:0.24607843137254895,f1:0.1618657624829882,pre:0.12097945531518389
SQ epoch 76 | train loss:0.9515576362609863,test loss:0.9415559768676758,acc:0.4406204423918328,recall:0.24960784313725476,f1:0.15284498663378718,pre:0.11043850520580134
SQ epoch 77 | train loss:0.9518843293190002,test loss:0.9406992197036743,acc:0.4905232134175984,recall:0.2515686274509803,f1:0.16542775498819834,pre:0.12370360101685304
SQ epoch 78 | train loss:0.9505885243415833,test loss:0.9445255994796753,acc:0.4406310768108897,recall:0.24980392156862732,f1:0.15277196430873988,pre:0.11037529371252636
SQ epoch 79 | train loss:0.9505367875099182,test loss:0.9401317834854126,acc:0.4905817027224113,recall:0.24882352941176455,f1:0.1635443734265613,pre:0.12210719747609788
SQ epoch 80 | train loss:0.9497219920158386,test loss:0.949095606803894,acc:0.49057638551288285,recall:0.24980392156862738,f1:0.1642985391501709,pre:0.12274366745665208
SQ epoch 81 | train loss:0.9488027691841125,test loss:0.9435946345329285,acc:0.490602971560525,recall:0.2507843137254901,f1:0.16502610163195405,pre:0.12329872083130775
SQ epoch 82 | train loss:0.9512882828712463,test loss:0.9508086442947388,acc:0.4905710683033544,recall:0.24901960784313715,f1:0.16346805217251797,pre:0.12192891903662288
SQ epoch 83 | train loss:0.9506539702415466,test loss:0.94411700963974,acc:0.44065766285853186,recall:0.2519607843137253,f1:0.15407616397075985,pre:0.11132546639523579
SQ epoch 84 | train loss:0.9485480785369873,test loss:0.9418267607688904,acc:0.49057638551288285,recall:0.24843137254901945,f1:0.16330751809440075,pre:0.1218848368376276
SQ epoch 85 | train loss:0.9489589929580688,test loss:0.9452567100524902,acc:0.4407002005347594,recall:0.2421568627450979,f1:0.1483332365979763,pre:0.10723540552584666
SQ epoch 86 | train loss:0.949374794960022,test loss:0.9402360320091248,acc:0.4905444822557122,recall:0.24529411764705872,f1:0.16127862151378666,pre:0.1204746622305947
SQ epoch 87 | train loss:0.9505245685577393,test loss:0.9411389827728271,acc:0.49057638551288285,recall:0.2505882352941175,f1:0.16481366108954051,pre:0.12302336533787069
SQ epoch 88 | train loss:0.9501317739486694,test loss:0.9406115412712097,acc:0.4905551166747691,recall:0.24843137254901948,f1:0.16338102947480634,pre:0.121993864953006
SQ epoch 89 | train loss:0.9514864683151245,test loss:0.9470635056495667,acc:0.49054979946524063,recall:0.24588235294117636,f1:0.16192827919244085,pre:0.12105044006238859
SQ epoch 90 | train loss:0.9485214352607727,test loss:0.9423351883888245,acc:0.49062955760816723,recall:0.2527450980392155,f1:0.166510170099095,pre:0.12461051440204185
SQ epoch 91 | train loss:0.9508415460586548,test loss:0.940161406993866,acc:0.49056043388429754,recall:0.24607843137254887,f1:0.16173916208638256,pre:0.12073293935342733
SQ epoch 92 | train loss:0.9503440856933594,test loss:0.9395304918289185,acc:0.49057638551288285,recall:0.25470588235294106,f1:0.1679920190122249,pre:0.1257078218684168
epoch 92 : weight has update
SQ epoch 93 | train loss:0.9509185552597046,test loss:0.9402751326560974,acc:0.4905923371414681,recall:0.24862745098039202,f1:0.16334108324349086,pre:0.12196334163830823
SQ epoch 94 | train loss:0.9497154355049133,test loss:0.9447711110115051,acc:0.49059765435099656,recall:0.24980392156862732,f1:0.1643310000835998,pre:0.12277962192108248
SQ epoch 95 | train loss:0.9508525133132935,test loss:0.9414941668510437,acc:0.4905817027224113,recall:0.25313725490196065,f1:0.1666708660922551,pre:0.12449195328958029
SQ epoch 96 | train loss:0.951401948928833,test loss:0.9434241056442261,acc:0.4905710683033544,recall:0.24921568627450963,f1:0.16394803267096814,pre:0.12244515678172092
SQ epoch 97 | train loss:0.9506757855415344,test loss:0.9404376149177551,acc:0.4906189231891103,recall:0.25058823529411756,f1:0.16430435204152052,pre:0.12260417932668932
SQ epoch 98 | train loss:0.9519058465957642,test loss:0.9419484734535217,acc:0.4905551166747691,recall:0.2533333333333332,f1:0.16671506177066955,pre:0.1245571017663264
SQ epoch 99 | train loss:0.9518798589706421,test loss:0.9417324662208557,acc:0.49056043388429754,recall:0.2496078431372547,f1:0.16430569634743775,pre:0.1227879142359423
SQ epoch 100 | train loss:0.9501779079437256,test loss:0.9436280131340027,acc:0.4406682972775887,recall:0.25294117647058817,f1:0.15438824435878165,pre:0.11151754425943931
SQ epoch 101 | train loss:0.9555320143699646,test loss:0.9423518776893616,acc:0.49060828877005347,recall:0.24764705882352933,f1:0.16258752353359,pre:0.12139747660427809
SQ epoch 102 | train loss:0.9548115134239197,test loss:0.9421143531799316,acc:0.44059385634419057,recall:0.24549019607843128,f1:0.14983034122540057,pre:0.1081294943080538
SQ epoch 103 | train loss:0.9498754739761353,test loss:0.9417393803596497,acc:0.49058701993193976,recall:0.24960784313725476,f1:0.16431657854145798,pre:0.1227647084143575
SQ epoch 104 | train loss:0.9501388669013977,test loss:0.9413381218910217,acc:0.4905817027224113,recall:0.24941176470588225,f1:0.16406902281932045,pre:0.12253666342570085
SQ epoch 105 | train loss:0.9496067762374878,test loss:0.9444945454597473,acc:0.49064019202722414,recall:0.24803921568627432,f1:0.16314067650944966,pre:0.12182518281072761
SQ epoch 106 | train loss:0.9495771527290344,test loss:0.9402915835380554,acc:0.49058701993193976,recall:0.25098039215686263,f1:0.16517994692261703,pre:0.12349847066925944
SQ epoch 107 | train loss:0.9506667852401733,test loss:0.9426568746566772,acc:0.4406523456490034,recall:0.2476470588235293,f1:0.15119314962135202,pre:0.10909690994166261
SQ epoch 108 | train loss:0.9546562433242798,test loss:0.943119466304779,acc:0.4905338478366553,recall:0.25529411764705867,f1:0.1680352465449949,pre:0.12550264088073243
epoch 108 : weight has update
SQ epoch 109 | train loss:0.9507363438606262,test loss:0.941343367099762,acc:0.49060828877005347,recall:0.25156862745098024,f1:0.16567244994903405,pre:0.12375960895721923
SQ epoch 110 | train loss:0.9511640667915344,test loss:0.943942666053772,acc:0.4406417112299465,recall:0.2480392156862743,f1:0.15151937280080013,pre:0.10944198418003566
SQ epoch 111 | train loss:0.9535070657730103,test loss:0.9405602216720581,acc:0.4905923371414681,recall:0.25156862745098024,f1:0.16558541089233247,pre:0.1237801308539945
SQ epoch 112 | train loss:0.9479387998580933,test loss:0.9428804516792297,acc:0.49058701993193976,recall:0.24745098039215677,f1:0.1628747341983329,pre:0.12173366350672502
SQ epoch 113 | train loss:0.9506781101226807,test loss:0.9459575414657593,acc:0.4905817027224113,recall:0.24882352941176464,f1:0.16349040664844067,pre:0.12202042568060281
SQ epoch 114 | train loss:0.9524694681167603,test loss:0.9459435343742371,acc:0.4406523456490034,recall:0.25294117647058817,f1:0.15439723440559772,pre:0.11148736276535406
SQ epoch 115 | train loss:0.9509041905403137,test loss:0.9425385594367981,acc:0.49057638551288285,recall:0.24901960784313715,f1:0.1638229042808332,pre:0.12234899124939232
SQ epoch 116 | train loss:0.948874831199646,test loss:0.9431719779968262,acc:0.49064019202722414,recall:0.2435294117647058,f1:0.1599715322081093,pre:0.1194132712485821
SQ epoch 117 | train loss:0.94947749376297,test loss:0.9405364990234375,acc:0.49057638551288285,recall:0.25137254901960765,f1:0.16533663248174618,pre:0.12351320693566686
SQ epoch 118 | train loss:0.9490526914596558,test loss:0.9415632486343384,acc:0.49060828877005347,recall:0.2549019607843136,f1:0.1679368630341814,pre:0.12556261140819963
SQ epoch 119 | train loss:0.9504256844520569,test loss:0.9415852427482605,acc:0.490565751093826,recall:0.24980392156862732,f1:0.16422259941142908,pre:0.12260150806190247
SQ epoch 120 | train loss:0.9511263966560364,test loss:0.9412011504173279,acc:0.49054979946524063,recall:0.24666666666666656,f1:0.16198680530209733,pre:0.12094474153297681
SQ epoch 121 | train loss:0.9502308368682861,test loss:0.9412199258804321,acc:0.49060828877005347,recall:0.246470588235294,f1:0.161939397113587,pre:0.12085060160427806
SQ epoch 122 | train loss:0.9491866827011108,test loss:0.9465299844741821,acc:0.490602971560525,recall:0.24941176470588225,f1:0.16397972906101724,pre:0.12253278945875873
SQ epoch 123 | train loss:0.9492257833480835,test loss:0.9429311752319336,acc:0.44063639402041804,recall:0.25254901960784293,f1:0.15419632490410254,pre:0.11129420879922215
SQ epoch 124 | train loss:0.9529354572296143,test loss:0.9428678154945374,acc:0.4406789316966456,recall:0.2449019607843135,f1:0.14984103322684375,pre:0.10820578360476421
SQ epoch 125 | train loss:0.951401948928833,test loss:0.941341757774353,acc:0.49058701993193976,recall:0.25254901960784293,f1:0.1661814706048211,pre:0.12404524438907796
SQ epoch 126 | train loss:0.9492756128311157,test loss:0.9427493214607239,acc:0.49059765435099656,recall:0.250392156862745,f1:0.16475895260089157,pre:0.1230875263328472
SQ epoch 127 | train loss:0.9492428302764893,test loss:0.9451471567153931,acc:0.44066298006806026,recall:0.2476470588235293,f1:0.15153767535932547,pre:0.10948369895478854
SQ epoch 128 | train loss:0.9513145089149475,test loss:0.941891610622406,acc:0.4905817027224113,recall:0.2435294117647058,f1:0.16012659012994032,pre:0.11949132028844596
SQ epoch 129 | train loss:0.9489489197731018,test loss:0.9410279393196106,acc:0.49054979946524063,recall:0.25156862745098024,f1:0.1656446546512341,pre:0.1238215797682709
SQ epoch 130 | train loss:0.9492537975311279,test loss:0.9406229257583618,acc:0.4905338478366553,recall:0.2492156862745097,f1:0.16397787755614301,pre:0.122590531822233
SQ epoch 131 | train loss:0.9481960535049438,test loss:0.9424698948860168,acc:0.4405566358774915,recall:0.24999999999999978,f1:0.15283652493926345,pre:0.11043787220466703
SQ epoch 132 | train loss:0.9485625624656677,test loss:0.9438709020614624,acc:0.4406417112299465,recall:0.24725490196078417,f1:0.15108313935106227,pre:0.1090198863636364
SQ epoch 133 | train loss:0.9512565732002258,test loss:0.940301239490509,acc:0.49056043388429754,recall:0.2468627450980391,f1:0.16246249661664655,pre:0.12138244915734889
SQ epoch 134 | train loss:0.9520519375801086,test loss:0.9413395524024963,acc:0.49056043388429754,recall:0.24862745098039202,f1:0.1634338271413296,pre:0.12209952550234975
SQ epoch 135 | train loss:0.9524964690208435,test loss:0.9405972957611084,acc:0.490602971560525,recall:0.2498039215686273,f1:0.16433062641004045,pre:0.12282200767703777
SQ epoch 136 | train loss:0.9509104490280151,test loss:0.9398308396339417,acc:0.49060828877005347,recall:0.2513725490196077,f1:0.16535238399444707,pre:0.12348094919786094
SQ epoch 137 | train loss:0.9519528150558472,test loss:0.941478431224823,acc:0.4905817027224113,recall:0.24901960784313715,f1:0.1639346208362932,pre:0.12246376701507052
SQ epoch 138 | train loss:0.9536291360855103,test loss:0.9411544799804688,acc:0.4905923371414681,recall:0.2456862745098038,f1:0.1614137997584167,pre:0.12052951810889645
SQ epoch 139 | train loss:0.9502314329147339,test loss:0.9404019713401794,acc:0.49049131016042785,recall:0.24764705882352922,f1:0.16274812318610554,pre:0.12153367312834225
SQ epoch 140 | train loss:0.9497835040092468,test loss:0.9442975521087646,acc:0.4406523456490034,recall:0.24784313725490187,f1:0.1518248139370109,pre:0.10977246141225083
SQ epoch 141 | train loss:0.9496425986289978,test loss:0.9397796988487244,acc:0.4905817027224113,recall:0.24901960784313718,f1:0.16375475888920438,pre:0.12224777436801168
SQ epoch 142 | train loss:0.9528959393501282,test loss:0.9439186453819275,acc:0.49058701993193976,recall:0.24647058823529408,f1:0.16210234606528184,pre:0.12112867900259276
SQ epoch 143 | train loss:0.9488232135772705,test loss:0.9452103972434998,acc:0.49054979946524063,recall:0.25058823529411756,f1:0.16476512321426137,pre:0.12304562165775401
SQ epoch 144 | train loss:0.9509773254394531,test loss:0.9468276500701904,acc:0.44064702843947495,recall:0.24960784313725476,f1:0.15250071815663516,pre:0.1101158012275158
SQ epoch 145 | train loss:0.9501045346260071,test loss:0.9432326555252075,acc:0.4905391650461838,recall:0.25117647058823517,f1:0.1649790036042867,pre:0.12313877410468323
SQ epoch 146 | train loss:0.9488204717636108,test loss:0.9424425363540649,acc:0.49058701993193976,recall:0.24607843137254895,f1:0.16166255069936894,pre:0.1206292917476908
SQ epoch 147 | train loss:0.9520471096038818,test loss:0.940735936164856,acc:0.49052853062712687,recall:0.24411764705882344,f1:0.16067703882109774,pre:0.12013366451952684
SQ epoch 148 | train loss:0.9499955773353577,test loss:0.9403423070907593,acc:0.4905923371414681,recall:0.24764705882352933,f1:0.16285026416053724,pre:0.12161254506968075
SQ epoch 149 | train loss:0.9518693089485168,test loss:0.9451460838317871,acc:0.44065766285853186,recall:0.2488235294117646,f1:0.15216151716123708,pre:0.10989011100307894
SQ epoch 150 | train loss:0.9517074227333069,test loss:0.9405964016914368,acc:0.490602971560525,recall:0.24647058823529402,f1:0.16225099582094563,pre:0.12128891690973906
training has finished used time : 3965.188246011734
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (17074, 18)
trait shape (1, 17074)
df shape (20087, 42195)
(5000, 32032) (12074, 32032)
train dataset already completed!
5000
test dataset already completed!
12074
ST epoch 1 | train loss:0.9490902423858643,test loss:1.812401294708252,acc:0.38180216165413533,recall:0.33333333333333287,f1:0.18375130982750848,pre:0.12726738721804515
epoch 1 : weight has update
ST epoch 2 | train loss:0.7248906493186951,test loss:1.1513736248016357,acc:0.38264411027568923,recall:0.33333333333333287,f1:0.1841028019781278,pre:0.1275480367585631
epoch 2 : weight has update
ST epoch 3 | train loss:0.6931812763214111,test loss:1.5848331451416016,acc:0.381296992481203,recall:0.33333333333333287,f1:0.18350834015654985,pre:0.12709899749373432
ST epoch 4 | train loss:0.6860821843147278,test loss:0.6930605173110962,acc:0.7351464598997494,recall:0.5310649203574074,f1:0.5059235578200392,pre:0.4861601155324566
epoch 4 : weight has update
ST epoch 5 | train loss:0.6785600781440735,test loss:0.7145546674728394,acc:0.7570332080200501,recall:0.5405382199942242,f1:0.5190721531208677,pre:0.5007446697130435
epoch 5 : weight has update
ST epoch 6 | train loss:0.6725705862045288,test loss:0.664786696434021,acc:0.7382792919799499,recall:0.5155604943087856,f1:0.4999944237303601,pre:0.5093109876260352
ST epoch 7 | train loss:0.6607106924057007,test loss:2.1026036739349365,acc:0.3924107142857143,recall:0.3396768576119666,f1:0.1983567524053389,pre:0.3821105647618945
ST epoch 8 | train loss:0.6450557112693787,test loss:0.6673435568809509,acc:0.7519423558897244,recall:0.5474329989533262,f1:0.5187767998768676,pre:0.5005636148922523
epoch 8 : weight has update
ST epoch 9 | train loss:0.6259905099868774,test loss:0.7343078255653381,acc:0.7029957706766916,recall:0.5217894403681148,f1:0.486301259618589,pre:0.48464203644838655
ST epoch 10 | train loss:0.6198493242263794,test loss:0.6205989718437195,acc:0.7747807017543861,recall:0.5550708276809649,f1:0.5322252507704038,pre:0.513030138762922
epoch 10 : weight has update
ST epoch 11 | train loss:0.613958477973938,test loss:0.6959800720214844,acc:0.7547344924812031,recall:0.5465381249245356,f1:0.5198455019120788,pre:0.49969638193753213
ST epoch 12 | train loss:0.6064784526824951,test loss:0.610319197177887,acc:0.774577067669173,recall:0.5552743555052552,f1:0.5344104169450022,pre:0.5175243575855693
epoch 12 : weight has update
ST epoch 13 | train loss:0.6095948219299316,test loss:0.5981330275535583,acc:0.7811286027568922,recall:0.5577329958963616,f1:0.5359969599577665,pre:0.5185045966977351
epoch 13 : weight has update
ST epoch 14 | train loss:0.6044152975082397,test loss:0.6112405061721802,acc:0.7776002506265665,recall:0.5512324733169874,f1:0.5324620143892085,pre:0.5200056548271129
ST epoch 15 | train loss:0.599513590335846,test loss:0.6134978532791138,acc:0.7790883458646617,recall:0.559650645967218,f1:0.5360405228193925,pre:0.5157858127175257
ST epoch 16 | train loss:0.5962245464324951,test loss:0.5941669940948486,acc:0.7803062343358396,recall:0.5577960171096992,f1:0.5357899753513463,pre:0.5176875733925416
ST epoch 17 | train loss:0.5983304977416992,test loss:0.612533450126648,acc:0.7798167293233084,recall:0.5540551038470805,f1:0.5339886358163856,pre:0.5202944391410862
ST epoch 18 | train loss:0.5964735150337219,test loss:0.6004071831703186,acc:0.7832001879699249,recall:0.5603792180391459,f1:0.5376475135150195,pre:0.5183311498655436
epoch 18 : weight has update
ST epoch 19 | train loss:0.5913682579994202,test loss:0.5969551205635071,acc:0.7817943295739348,recall:0.5539107629505675,f1:0.5350761834790486,pre:0.5238242074127415
ST epoch 20 | train loss:0.5906070470809937,test loss:0.6257721185684204,acc:0.7856594611528822,recall:0.5589580982692834,f1:0.538734186534509,pre:0.5241711975513458
epoch 20 : weight has update
ST epoch 21 | train loss:0.5886930227279663,test loss:0.6005685925483704,acc:0.7810541979949874,recall:0.5547787908360643,f1:0.5353229724202627,pre:0.5212907954006226
ST epoch 22 | train loss:0.5866441130638123,test loss:0.5963557958602905,acc:0.7817943295739348,recall:0.558247161489319,f1:0.5366161095566039,pre:0.5184900527014431
ST epoch 23 | train loss:0.5797064900398254,test loss:0.5990465879440308,acc:0.7786614974937343,recall:0.5523743905946465,f1:0.533102206312374,pre:0.5200400971140218
ST epoch 24 | train loss:0.5794329643249512,test loss:0.6058374643325806,acc:0.7818687343358396,recall:0.5553662998419808,f1:0.5364345376376916,pre:0.5232867041113445
ST epoch 25 | train loss:0.5753279328346252,test loss:0.5925060510635376,acc:0.7862390350877192,recall:0.5634254777297788,f1:0.5402044094461387,pre:0.5205097025996785
epoch 25 : weight has update
ST epoch 26 | train loss:0.5757944583892822,test loss:0.5864898562431335,acc:0.7884437656641604,recall:0.5610056299239072,f1:0.5409421749538851,pre:0.5262241408594238
epoch 26 : weight has update
ST epoch 27 | train loss:0.5675169229507446,test loss:0.5825498104095459,acc:0.7910087719298246,recall:0.5615464691154388,f1:0.5425318471382286,pre:0.5304700328332888
epoch 27 : weight has update
ST epoch 28 | train loss:0.5646214485168457,test loss:0.5745102763175964,acc:0.7906093358395989,recall:0.5660225850530927,f1:0.5436397452876142,pre:0.5248876928814307
ST epoch 29 | train loss:0.5593568682670593,test loss:0.6227432489395142,acc:0.7849937343358395,recall:0.5559463792910357,f1:0.5376152888227311,pre:0.526419924544708
ST epoch 30 | train loss:0.5701360106468201,test loss:0.5723552107810974,acc:0.7937930764411028,recall:0.5685889367907005,f1:0.5460536424278823,pre:0.5268036538010372
epoch 30 : weight has update
ST epoch 31 | train loss:0.5533685088157654,test loss:0.576229453086853,acc:0.7881187343358396,recall:0.5614413890453754,f1:0.5411578619857275,pre:0.5252348835502185
ST epoch 32 | train loss:0.5561596155166626,test loss:0.5801498293876648,acc:0.7892622180451128,recall:0.563610793260361,f1:0.5422626755556051,pre:0.5249686211476866
ST epoch 33 | train loss:0.5501277446746826,test loss:0.5737212896347046,acc:0.7949483082706768,recall:0.568422267330725,f1:0.5465550790790226,pre:0.5282564699649662
epoch 33 : weight has update
ST epoch 34 | train loss:0.5476348400115967,test loss:0.5669865012168884,acc:0.7923206453634085,recall:0.5646713546457629,f1:0.5441285572999498,pre:0.5286776563079156
ST epoch 35 | train loss:0.5393037796020508,test loss:0.57967609167099,acc:0.7839324874686717,recall:0.5606984299107418,f1:0.5386494928394754,pre:0.5204565179838788
ST epoch 36 | train loss:0.5415380001068115,test loss:0.5778864622116089,acc:0.7901824874686717,recall:0.5662467067027426,f1:0.5436125538437366,pre:0.5245828734621286
ST epoch 37 | train loss:0.5347912907600403,test loss:0.5667914748191833,acc:0.7926535087719297,recall:0.5651828615233611,f1:0.544245220719609,pre:0.5281908095959386
ST epoch 38 | train loss:0.5408666729927063,test loss:0.5700123906135559,acc:0.7927944862155388,recall:0.568598137604081,f1:0.5454395802038541,pre:0.5257609712558229
ST epoch 39 | train loss:0.5407926440238953,test loss:0.5756705403327942,acc:0.7922462406015038,recall:0.5617292822894197,f1:0.5432183840194219,pre:0.5312280740320798
ST epoch 40 | train loss:0.5371357202529907,test loss:0.5657138228416443,acc:0.7953594924812031,recall:0.569215646959726,f1:0.5468131821896853,pre:0.527846127022373
epoch 40 : weight has update
ST epoch 41 | train loss:0.5350168943405151,test loss:0.5666658878326416,acc:0.7927279135338346,recall:0.5634977508569579,f1:0.5438283116187641,pre:0.5303981334873453
ST epoch 42 | train loss:0.5264180302619934,test loss:0.5679728984832764,acc:0.7940515350877192,recall:0.575499126929622,f1:0.5577396226561852,pre:0.586062474071593
epoch 42 : weight has update
ST epoch 43 | train loss:0.5392829775810242,test loss:0.5641810894012451,acc:0.7921600877192982,recall:0.5672511305681721,f1:0.5487736600935377,pre:0.5499251117514377
ST epoch 44 | train loss:0.5228352546691895,test loss:0.5643822550773621,acc:0.7929824561403508,recall:0.5673790408729159,f1:0.5505339598611079,pre:0.5678867186049639
ST epoch 45 | train loss:0.5215632319450378,test loss:0.5591912865638733,acc:0.7962915100250626,recall:0.5699161930426182,f1:0.550125061211377,pre:0.5375838137905722
ST epoch 46 | train loss:0.528292179107666,test loss:0.5571813583374023,acc:0.7947877506265664,recall:0.5702237415963479,f1:0.5486839942288596,pre:0.5415537522429279
ST epoch 47 | train loss:0.5310841202735901,test loss:0.5678905844688416,acc:0.7926417606516291,recall:0.5680756481113141,f1:0.5506040698511968,pre:0.5619700497048211
ST epoch 48 | train loss:0.5130789279937744,test loss:0.5637802481651306,acc:0.7973214285714285,recall:0.57354683716235,f1:0.557881843555586,pre:0.5838893934145876
ST epoch 49 | train loss:0.5158250331878662,test loss:0.5653471350669861,acc:0.7911497493734336,recall:0.5681203780034456,f1:0.5443729598345967,pre:0.524370218488891
ST epoch 50 | train loss:0.5209195613861084,test loss:0.5646103620529175,acc:0.7973370927318296,recall:0.572060749951323,f1:0.5581289636424877,pre:0.5871189048620311
epoch 50 : weight has update
ST epoch 51 | train loss:0.5132535696029663,test loss:0.5846866369247437,acc:0.7881343984962407,recall:0.5732921651938335,f1:0.555546042074034,pre:0.5908928245688865
ST epoch 52 | train loss:0.5149636268615723,test loss:0.5764370560646057,acc:0.7922266604010025,recall:0.578080406645018,f1:0.5682797599317049,pre:0.6144993641850589
epoch 52 : weight has update
ST epoch 53 | train loss:0.5213556885719299,test loss:0.5670246481895447,acc:0.7871436403508771,recall:0.5743219243379257,f1:0.5539895479465742,pre:0.571344600835559
ST epoch 54 | train loss:0.5032103657722473,test loss:0.5618472099304199,acc:0.7931430137844612,recall:0.576614915690899,f1:0.5602396647432266,pre:0.6062101661801481
ST epoch 55 | train loss:0.5042288899421692,test loss:0.5585925579071045,acc:0.7951950187969925,recall:0.5692272834639618,f1:0.548795799432489,pre:0.5392946441402054
ST epoch 56 | train loss:0.5126994252204895,test loss:0.5729488134384155,acc:0.7955083020050125,recall:0.5746429443822204,f1:0.5662179314696967,pre:0.6300762162408867
epoch 56 : weight has update
ST epoch 57 | train loss:0.5173971652984619,test loss:0.5603588819503784,acc:0.7988212719298246,recall:0.5776464968895195,f1:0.5673424481978272,pre:0.6200941918729628
ST epoch 58 | train loss:0.5000988245010376,test loss:0.6041671633720398,acc:0.7925634398496241,recall:0.5642177107966674,f1:0.550122601816536,pre:0.5749089735908832
ST epoch 59 | train loss:0.4942013621330261,test loss:0.5842825174331665,acc:0.7897752192982456,recall:0.5669584211077158,f1:0.5559773355196306,pre:0.5993590949196229
ST epoch 60 | train loss:0.4967075288295746,test loss:0.5619034171104431,acc:0.7956845238095238,recall:0.586363212805684,f1:0.5783562689012405,pre:0.6527562569691575
epoch 60 : weight has update
ST epoch 61 | train loss:0.49347642064094543,test loss:0.5636772513389587,acc:0.7968593358395989,recall:0.5767747567047073,f1:0.567382058177514,pre:0.6233212007680262
ST epoch 62 | train loss:0.5025704503059387,test loss:0.5557847619056702,acc:0.8015115914786968,recall:0.5926034585317034,f1:0.5884428296498114,pre:0.6801475597435732
epoch 62 : weight has update
ST epoch 63 | train loss:0.4983575940132141,test loss:0.5530638098716736,acc:0.8010573308270676,recall:0.5869175332912004,f1:0.5803303378563006,pre:0.6393801259215692
ST epoch 64 | train loss:0.495878130197525,test loss:0.5725969076156616,acc:0.7978187656641604,recall:0.5686459184705848,f1:0.5534569775095639,pre:0.568224351705717
ST epoch 65 | train loss:0.4909767806529999,test loss:0.5582811832427979,acc:0.7970433897243108,recall:0.5815388170182223,f1:0.5732976105478459,pre:0.64022189010234
ST epoch 66 | train loss:0.4895462095737457,test loss:0.5588665008544922,acc:0.7900806704260651,recall:0.5674681689301565,f1:0.5493141423551587,pre:0.5601225336054179
ST epoch 67 | train loss:0.49791425466537476,test loss:0.5498858094215393,acc:0.8002858709273183,recall:0.5832449899307929,f1:0.5687359651631179,pre:0.6155366004468369
ST epoch 68 | train loss:0.4991174042224884,test loss:0.5607832670211792,acc:0.7998786027568922,recall:0.5847110191160592,f1:0.5757457147120281,pre:0.6438677296729561
ST epoch 69 | train loss:0.49365684390068054,test loss:0.5825243592262268,acc:0.7907581453634085,recall:0.5677635426253165,f1:0.5507071960830263,pre:0.5621625464729438
ST epoch 70 | train loss:0.4852670729160309,test loss:0.565203070640564,acc:0.7950462092731829,recall:0.5714927809099737,f1:0.5568939389654908,pre:0.5798163220507669
ST epoch 71 | train loss:0.495227187871933,test loss:0.5582351684570312,acc:0.7942042606516291,recall:0.5772304500170027,f1:0.5601742723377326,pre:0.5860885953874668
ST epoch 72 | train loss:0.48415303230285645,test loss:0.5667704939842224,acc:0.7940437030075188,recall:0.571924254387255,f1:0.5552837095527398,pre:0.5773682939769168
ST epoch 73 | train loss:0.48218122124671936,test loss:0.5540136694908142,acc:0.8018522869674185,recall:0.5893034024610321,f1:0.5826550438597187,pre:0.6696078863403944
ST epoch 74 | train loss:0.4873703718185425,test loss:0.5914823412895203,acc:0.7947994987468672,recall:0.5867483043289382,f1:0.5852917194136917,pre:0.6289670727893216
ST epoch 75 | train loss:0.4891510605812073,test loss:0.562950849533081,acc:0.8007832080200501,recall:0.5785706424134819,f1:0.5698941364607792,pre:0.6170933494049067
ST epoch 76 | train loss:0.4995689392089844,test loss:0.5652742981910706,acc:0.7961035401002506,recall:0.5735648012329041,f1:0.562557263152828,pre:0.6094983467596927
ST epoch 77 | train loss:0.48517853021621704,test loss:0.5549116134643555,acc:0.7997297932330828,recall:0.5989802698789073,f1:0.5997912894004502,pre:0.6773029042528245
epoch 77 : weight has update
ST epoch 78 | train loss:0.4850253760814667,test loss:0.5641178488731384,acc:0.7970864661654136,recall:0.5788792696987083,f1:0.5704000951289292,pre:0.6435784648306097
ST epoch 79 | train loss:0.49030110239982605,test loss:0.5577374696731567,acc:0.7961779448621553,recall:0.5854722753799884,f1:0.5713852886765207,pre:0.6176121223939344
ST epoch 80 | train loss:0.4806751310825348,test loss:0.5676112174987793,acc:0.798656798245614,recall:0.5839770959688076,f1:0.5737213879731895,pre:0.6377740727821208
ST epoch 81 | train loss:0.4808124303817749,test loss:0.5799949169158936,acc:0.7983983395989974,recall:0.5914621513363588,f1:0.5873244302209814,pre:0.6647089348878437
ST epoch 82 | train loss:0.4825468361377716,test loss:0.5619294047355652,acc:0.7990562343358396,recall:0.5851882517281539,f1:0.5744386018076916,pre:0.6403875001366742
ST epoch 83 | train loss:0.4870927333831787,test loss:0.5677147507667542,acc:0.7956962719298245,recall:0.5739250190905558,f1:0.558002849040524,pre:0.5813541833265139
ST epoch 84 | train loss:0.48509499430656433,test loss:0.5799413323402405,acc:0.794701597744361,recall:0.5841942075359119,f1:0.5819694040623256,pre:0.6603221168246307
ST epoch 85 | train loss:0.4855482280254364,test loss:0.5550501346588135,acc:0.7987351190476191,recall:0.5911158662480769,f1:0.5859641548353162,pre:0.6704841375881615
ST epoch 86 | train loss:0.47836995124816895,test loss:0.5779352188110352,acc:0.7850798872180452,recall:0.5962312416364478,f1:0.5949306261296322,pre:0.6585221160186324
ST epoch 87 | train loss:0.47893089056015015,test loss:0.5502787232398987,acc:0.8004699248120302,recall:0.6014738667944163,f1:0.6021031862794695,pre:0.6738918545319628
epoch 87 : weight has update
ST epoch 88 | train loss:0.4758937954902649,test loss:0.5545641779899597,acc:0.7968397556390978,recall:0.5832690869849286,f1:0.5726100058279892,pre:0.6255115199326141
ST epoch 89 | train loss:0.47750142216682434,test loss:0.5592854022979736,acc:0.7956884398496241,recall:0.5898641202685183,f1:0.5871776595752505,pre:0.6576037995329146
ST epoch 90 | train loss:0.4705645442008972,test loss:0.5508974194526672,acc:0.7983161027568922,recall:0.5864586738744076,f1:0.5760437643681878,pre:0.6404274749089204
ST epoch 91 | train loss:0.4746835231781006,test loss:0.5552236437797546,acc:0.7999569235588972,recall:0.5961472387591749,f1:0.5935191461659202,pre:0.6679490095738015
ST epoch 92 | train loss:0.4831894636154175,test loss:0.5729181170463562,acc:0.7930451127819548,recall:0.5764552871296276,f1:0.5656135629028884,pre:0.6195127901876133
ST epoch 93 | train loss:0.48012006282806396,test loss:0.5506340265274048,acc:0.802764724310777,recall:0.5885664683625104,f1:0.5781274931921803,pre:0.6522214348415292
ST epoch 94 | train loss:0.4660217761993408,test loss:0.5953678488731384,acc:0.7948543233082707,recall:0.5789783212815295,f1:0.5733057826290224,pre:0.6235499134681584
ST epoch 95 | train loss:0.4706622362136841,test loss:0.564248263835907,acc:0.7967301065162907,recall:0.5881908136359965,f1:0.5904178863394389,pre:0.6760471272309414
ST epoch 96 | train loss:0.46891066431999207,test loss:0.5677861571311951,acc:0.8018679511278196,recall:0.6065048480327332,f1:0.6083159893917552,pre:0.6722351166033179
epoch 96 : weight has update
ST epoch 97 | train loss:0.4649790823459625,test loss:0.569567084312439,acc:0.7961113721804511,recall:0.6003694409480297,f1:0.6010395519181878,pre:0.6638003541173298
ST epoch 98 | train loss:0.4714813828468323,test loss:0.5772046446800232,acc:0.8026119987468672,recall:0.5923797097216233,f1:0.5871796421800366,pre:0.6692030061224995
ST epoch 99 | train loss:0.4630420506000519,test loss:0.5841214060783386,acc:0.7993930137844611,recall:0.5939371592362442,f1:0.5949596064865864,pre:0.6763200235529324
ST epoch 100 | train loss:0.4712328016757965,test loss:0.5527541041374207,acc:0.7975211466165414,recall:0.6096839347489512,f1:0.6100990322573799,pre:0.6490418857268344
ST epoch 101 | train loss:0.46354880928993225,test loss:0.563933253288269,acc:0.7991580513784461,recall:0.60190801640542,f1:0.6055811056466266,pre:0.6681206960891396
ST epoch 102 | train loss:0.4640020728111267,test loss:0.5550830960273743,acc:0.7991306390977443,recall:0.59841938757881,f1:0.5980658757030657,pre:0.6831615724510749
ST epoch 103 | train loss:0.46818798780441284,test loss:0.5784217715263367,acc:0.7966713659147869,recall:0.5822919128348794,f1:0.5757079136992722,pre:0.6476574122744447
ST epoch 104 | train loss:0.46319714188575745,test loss:0.5717533230781555,acc:0.7946389411027568,recall:0.5933831141815921,f1:0.5861055088161209,pre:0.6551956484278766
ST epoch 105 | train loss:0.4519946873188019,test loss:0.581476628780365,acc:0.7904252819548873,recall:0.5977087337620588,f1:0.5962580431625528,pre:0.6574841137660323
ST epoch 106 | train loss:0.46704673767089844,test loss:0.5588275194168091,acc:0.7981672932330828,recall:0.5848917797996566,f1:0.5808930449247249,pre:0.6568737889761593
ST epoch 107 | train loss:0.4560638964176178,test loss:0.5549532175064087,acc:0.7949483082706768,recall:0.5903896788430697,f1:0.5911194333466404,pre:0.6770875623212244
ST epoch 108 | train loss:0.46589577198028564,test loss:0.5773302912712097,acc:0.7966008771929824,recall:0.5897423124469043,f1:0.5801945829282453,pre:0.6542766108877931
ST epoch 109 | train loss:0.46189945936203003,test loss:0.5658801198005676,acc:0.8021812343358395,recall:0.5935220536391129,f1:0.5913724954728127,pre:0.6659850641677229
ST epoch 110 | train loss:0.46154746413230896,test loss:0.5633879899978638,acc:0.7882244674185463,recall:0.6114991429519695,f1:0.6053902599617645,pre:0.6461961053949825
ST epoch 111 | train loss:0.45165562629699707,test loss:0.5804844498634338,acc:0.7902451441102757,recall:0.5978623666189805,f1:0.5981225390313566,pre:0.6541274966263986
ST epoch 112 | train loss:0.4568416476249695,test loss:0.5681943893432617,acc:0.796577380952381,recall:0.5907137106515133,f1:0.5896296080102705,pre:0.6588312184442818
ST epoch 113 | train loss:0.45504605770111084,test loss:0.5913847088813782,acc:0.7983278508771929,recall:0.6049032452105451,f1:0.6072731962031623,pre:0.6758551834447983
ST epoch 114 | train loss:0.4660642147064209,test loss:0.5609594583511353,acc:0.7984805764411027,recall:0.5799414458812956,f1:0.5715126582998845,pre:0.6284188038418473
ST epoch 115 | train loss:0.45030638575553894,test loss:0.5532599091529846,acc:0.7984923245614035,recall:0.5994273981236681,f1:0.5986453626984978,pre:0.6653220118211646
ST epoch 116 | train loss:0.4572935402393341,test loss:0.5869030356407166,acc:0.7964285714285715,recall:0.59420520047666,f1:0.5926074527171251,pre:0.6588670217027385
ST epoch 117 | train loss:0.45686566829681396,test loss:0.5542532205581665,acc:0.8027686403508771,recall:0.5991583222420405,f1:0.5991086846067092,pre:0.6666778582634021
ST epoch 118 | train loss:0.45069390535354614,test loss:0.5535586476325989,acc:0.7979949874686717,recall:0.6051008910527872,f1:0.6102310608614087,pre:0.6651675577286491
ST epoch 119 | train loss:0.4529760479927063,test loss:0.580894410610199,acc:0.8021068295739349,recall:0.5963397830111635,f1:0.5936588084534432,pre:0.6745848690765571
ST epoch 120 | train loss:0.448416531085968,test loss:0.5779634714126587,acc:0.7972587719298245,recall:0.5838430561035614,f1:0.5769212357096201,pre:0.6409118763461528
ST epoch 121 | train loss:0.46206846833229065,test loss:0.5504870414733887,acc:0.7998981829573935,recall:0.6039097277867682,f1:0.6058755983041157,pre:0.6646876422264862
ST epoch 122 | train loss:0.4587479531764984,test loss:0.5548447966575623,acc:0.7992011278195489,recall:0.5941562510382581,f1:0.5918046477419895,pre:0.6736718188463331
ST epoch 123 | train loss:0.45891591906547546,test loss:0.5900018811225891,acc:0.8017896303258145,recall:0.6079379822788363,f1:0.609530880981631,pre:0.6683238875509906
ST epoch 124 | train loss:0.4559374749660492,test loss:0.5621201395988464,acc:0.7969298245614035,recall:0.5958091419391323,f1:0.5947659864693318,pre:0.6936298562788572
ST epoch 125 | train loss:0.4407641291618347,test loss:0.5670284032821655,acc:0.8006892230576441,recall:0.6025396895089229,f1:0.6061746244644246,pre:0.6784652693810921
ST epoch 126 | train loss:0.46393775939941406,test loss:0.5511908531188965,acc:0.7992951127819549,recall:0.585789708643362,f1:0.5788439639401579,pre:0.6509435998801332
ST epoch 127 | train loss:0.44991981983184814,test loss:0.5522111654281616,acc:0.798656798245614,recall:0.5927530165819185,f1:0.5881125332781919,pre:0.6591534528786486
ST epoch 128 | train loss:0.4546007513999939,test loss:0.5567615032196045,acc:0.8019423558897243,recall:0.5991529019920618,f1:0.5992711961366528,pre:0.6881111002492768
ST epoch 129 | train loss:0.4556765854358673,test loss:0.5622630715370178,acc:0.7942003446115289,recall:0.5945740598345691,f1:0.5888939282507832,pre:0.658146733342586
ST epoch 130 | train loss:0.4466641843318939,test loss:0.5717518329620361,acc:0.7961857769423559,recall:0.5869954645547026,f1:0.5763935564386057,pre:0.6402299177317236
ST epoch 131 | train loss:0.45223966240882874,test loss:0.5661103129386902,acc:0.7949639724310776,recall:0.5759533858499966,f1:0.5562653060149505,pre:0.5793171868803121
ST epoch 132 | train loss:0.4577169716358185,test loss:0.5525481104850769,acc:0.7998942669172933,recall:0.5931284766538854,f1:0.5891928994693001,pre:0.6446095351946994
ST epoch 133 | train loss:0.4611605107784271,test loss:0.5957489609718323,acc:0.7980615601503759,recall:0.6015131069806661,f1:0.6031730566148035,pre:0.6784050236820798
ST epoch 134 | train loss:0.45267584919929504,test loss:0.5541499257087708,acc:0.7992285401002507,recall:0.6039357530903411,f1:0.6042947847898118,pre:0.6714447507321677
ST epoch 135 | train loss:0.44740980863571167,test loss:0.5661536455154419,acc:0.7961975250626566,recall:0.5973949728263142,f1:0.5922592378161389,pre:0.6543291929386831
ST epoch 136 | train loss:0.4379376173019409,test loss:0.57892245054245,acc:0.795296835839599,recall:0.596268171988316,f1:0.6001433439769193,pre:0.6711974234197334
ST epoch 137 | train loss:0.45184728503227234,test loss:0.6079462170600891,acc:0.7986528822055138,recall:0.5802065723387165,f1:0.5709052559017777,pre:0.6274799554991791
ST epoch 138 | train loss:0.44749191403388977,test loss:0.5837697982788086,acc:0.7960839598997493,recall:0.5879714552199923,f1:0.5845054188723644,pre:0.6735842072687034
ST epoch 139 | train loss:0.44287124276161194,test loss:0.5774977207183838,acc:0.7957550125313283,recall:0.5950297904662449,f1:0.5953700559957237,pre:0.6563339333731791
ST epoch 140 | train loss:0.44908905029296875,test loss:0.5539786219596863,acc:0.7976621240601505,recall:0.5875145322452381,f1:0.5802895994496601,pre:0.6348064152595574
ST epoch 141 | train loss:0.44003453850746155,test loss:0.585242748260498,acc:0.790343045112782,recall:0.5994089416180394,f1:0.6002901907246493,pre:0.6412963371947852
ST epoch 142 | train loss:0.45547279715538025,test loss:0.5572302937507629,acc:0.7992128759398496,recall:0.5980969238536678,f1:0.5953904558119792,pre:0.6550780196895044
ST epoch 143 | train loss:0.44055914878845215,test loss:0.5581241846084595,acc:0.8005404135338346,recall:0.5890724444899592,f1:0.5858450992966339,pre:0.6683628284943786
ST epoch 144 | train loss:0.4410838782787323,test loss:0.5667273998260498,acc:0.7991423872180452,recall:0.6007374638344238,f1:0.6057760311687077,pre:0.6777234694369572
ST epoch 145 | train loss:0.4518122971057892,test loss:0.5584867596626282,acc:0.7988251879699249,recall:0.591215265214828,f1:0.5852668591570114,pre:0.6602665185409539
ST epoch 146 | train loss:0.4417204260826111,test loss:0.5763987898826599,acc:0.7964403195488722,recall:0.5927331909937839,f1:0.5943044140709023,pre:0.6662553564332774
ST epoch 147 | train loss:0.45408615469932556,test loss:0.5601194500923157,acc:0.7963619987468672,recall:0.603774559741571,f1:0.6058678406942198,pre:0.6769222679657256
ST epoch 148 | train loss:0.4481763541698456,test loss:0.5705963373184204,acc:0.8024436090225564,recall:0.595326854426208,f1:0.5904565420267989,pre:0.6505148877574091
ST epoch 149 | train loss:0.4456777274608612,test loss:0.5664897561073303,acc:0.7977404448621553,recall:0.6046731278940837,f1:0.6071571799480134,pre:0.6626395922597256
ST epoch 150 | train loss:0.44392746686935425,test loss:0.5628457069396973,acc:0.7984923245614035,recall:0.5984972461920876,f1:0.5963825091692585,pre:0.6778002753765836
training has finished used time : 3760.68017411232
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (15848, 18)
trait shape (1, 15848)
df shape (20087, 42195)
(5000, 32032) (10848, 32032)
train dataset already completed!
5000
test dataset already completed!
10848
Ldg epoch 1 | train loss:1.5003371238708496,test loss:1.8351069688796997,acc:0.25949754901960786,recall:0.19999999999999968,f1:0.08207478350559938,pre:0.05190457580670063
epoch 1 : weight has update
Ldg epoch 2 | train loss:1.3582996129989624,test loss:2.0998735427856445,acc:0.259375,recall:0.19999999999999968,f1:0.08210216130988007,pre:0.051875
Ldg epoch 3 | train loss:1.325430989265442,test loss:1.8478291034698486,acc:0.26207107843137256,recall:0.20129055355836564,f1:0.08835687631662671,pre:0.07776763513109498
epoch 3 : weight has update
Ldg epoch 4 | train loss:1.3214070796966553,test loss:1.9270288944244385,acc:0.2592830882352941,recall:0.19999999999999968,f1:0.08205632575813239,pre:0.05187181565539601
Ldg epoch 5 | train loss:1.3040213584899902,test loss:1.5754531621932983,acc:0.2788296568627451,recall:0.21536657376018836,f1:0.11287890323284963,pre:0.1694940646299436
epoch 5 : weight has update
Ldg epoch 6 | train loss:1.3050799369812012,test loss:1.4181859493255615,acc:0.3567708333333333,recall:0.21145293292773717,f1:0.13479244658324724,pre:0.23482292644175748
epoch 6 : weight has update
Ldg epoch 7 | train loss:1.3084102869033813,test loss:1.757340431213379,acc:0.29466911764705883,recall:0.22602033860382675,f1:0.13103939148344296,pre:0.17942536678260146
Ldg epoch 8 | train loss:1.300988793373108,test loss:2.3176610469818115,acc:0.2649816176470588,recall:0.20377288276106323,f1:0.094568236064923,pre:0.12369025928824862
Ldg epoch 9 | train loss:1.2783353328704834,test loss:2.2882890701293945,acc:0.13655024509803923,recall:0.23092926899397226,f1:0.09377021642593782,pre:0.10510306421911464
Ldg epoch 10 | train loss:1.2655858993530273,test loss:1.4398326873779297,acc:0.3122549019607843,recall:0.22805728770823214,f1:0.1447812005222253,pre:0.16826120311120016
Ldg epoch 11 | train loss:1.259529948234558,test loss:1.2722333669662476,acc:0.4423713235294118,recall:0.3123290931300845,f1:0.2980871550686325,pre:0.3501067338598988
epoch 11 : weight has update
Ldg epoch 12 | train loss:1.2498717308044434,test loss:1.4594496488571167,acc:0.30168504901960785,recall:0.22752876555958165,f1:0.14471892658032964,pre:0.2224131650114189
Ldg epoch 13 | train loss:1.244361162185669,test loss:1.8617796897888184,acc:0.26173406862745097,recall:0.2019924068301594,f1:0.08601909625186355,pre:0.09322641029388783
Ldg epoch 14 | train loss:1.246975302696228,test loss:1.3137500286102295,acc:0.40897671568627453,recall:0.28790510481236464,f1:0.2534922136440984,pre:0.2742723498419826
Ldg epoch 15 | train loss:1.2448140382766724,test loss:1.3392013311386108,acc:0.40726102941176473,recall:0.2780169656304637,f1:0.24415664970135403,pre:0.27447701762380805
Ldg epoch 16 | train loss:1.2478575706481934,test loss:1.2605724334716797,acc:0.4446691176470588,recall:0.3194715257914898,f1:0.30895273462497186,pre:0.3660370338031149
epoch 16 : weight has update
Ldg epoch 17 | train loss:1.2476447820663452,test loss:2.103473663330078,acc:0.2933823529411765,recall:0.2636814753673558,f1:0.18231723184075158,pre:0.26727424101328534
Ldg epoch 18 | train loss:1.236315369606018,test loss:1.3407833576202393,acc:0.39926470588235297,recall:0.29633250915965054,f1:0.265970229797633,pre:0.35371274092535626
Ldg epoch 19 | train loss:1.2367688417434692,test loss:1.2951689958572388,acc:0.4347120098039216,recall:0.29517839797553663,f1:0.27230568468991007,pre:0.29915310587085553
Ldg epoch 20 | train loss:1.2323004007339478,test loss:1.673226237297058,acc:0.27273284313725493,recall:0.2073397923620582,f1:0.10173521384525368,pre:0.09540446823392922
Ldg epoch 21 | train loss:1.228742003440857,test loss:1.2381278276443481,acc:0.4506740196078431,recall:0.32304209506262205,f1:0.3088918891880562,pre:0.35589131625726556
Ldg epoch 22 | train loss:1.2338238954544067,test loss:1.2432063817977905,acc:0.4440563725490196,recall:0.3285307821618316,f1:0.3273022421452224,pre:0.3868550917269297
epoch 22 : weight has update
Ldg epoch 23 | train loss:1.2286295890808105,test loss:1.6473203897476196,acc:0.36066176470588235,recall:0.31042048387861715,f1:0.2566150539328394,pre:0.3034090602046906
Ldg epoch 24 | train loss:1.2338557243347168,test loss:1.51983642578125,acc:0.3097732843137255,recall:0.24326711534592993,f1:0.16797054643270884,pre:0.2969336976947219
Ldg epoch 25 | train loss:1.2199251651763916,test loss:1.5867408514022827,acc:0.32527573529411763,recall:0.2344832360259321,f1:0.1550170795790135,pre:0.17325586481417116
Ldg epoch 26 | train loss:1.216135025024414,test loss:1.4582931995391846,acc:0.33900122549019607,recall:0.24093094654088865,f1:0.16917045831797092,pre:0.20152697776982326
Ldg epoch 27 | train loss:1.2111886739730835,test loss:1.3688437938690186,acc:0.39892769607843137,recall:0.27521361362096886,f1:0.2258585327021518,pre:0.3209851514429911
Ldg epoch 28 | train loss:1.2120189666748047,test loss:1.2401262521743774,acc:0.4514399509803922,recall:0.35173476128092684,f1:0.34136085369525165,pre:0.38703300422418063
epoch 28 : weight has update
Ldg epoch 29 | train loss:1.2060778141021729,test loss:1.5822908878326416,acc:0.2952205882352941,recall:0.22127298896986064,f1:0.13112554870035148,pre:0.19807158895915825
Ldg epoch 30 | train loss:1.220029354095459,test loss:1.4930691719055176,acc:0.3177083333333333,recall:0.23666601929627062,f1:0.1603899009858346,pre:0.23277354173092435
Ldg epoch 31 | train loss:1.2046736478805542,test loss:1.3689022064208984,acc:0.38933823529411765,recall:0.2920012484245797,f1:0.25735561927192807,pre:0.3558887311317621
Ldg epoch 32 | train loss:1.2076259851455688,test loss:1.2418545484542847,acc:0.4483149509803922,recall:0.31330960974922045,f1:0.3027085003830346,pre:0.34645402183260315
Ldg epoch 33 | train loss:1.2036125659942627,test loss:1.8547922372817993,acc:0.2631127450980392,recall:0.202370204135674,f1:0.08867843460013547,pre:0.08181810350862032
Ldg epoch 34 | train loss:1.1982983350753784,test loss:1.2681037187576294,acc:0.4362438725490196,recall:0.322941465729675,f1:0.29323201996994963,pre:0.35563419211947045
Ldg epoch 35 | train loss:1.1918790340423584,test loss:1.4812846183776855,acc:0.3761642156862745,recall:0.2615193321257436,f1:0.20227757220823434,pre:0.24449656813369863
Ldg epoch 36 | train loss:1.1883583068847656,test loss:1.2383341789245605,acc:0.4512254901960784,recall:0.33122030971844546,f1:0.3105510639753585,pre:0.3687860586215638
Ldg epoch 37 | train loss:1.2033923864364624,test loss:1.474046230316162,acc:0.34479166666666666,recall:0.25890458664552757,f1:0.19871793552950948,pre:0.30313956392614205
Ldg epoch 38 | train loss:1.1849141120910645,test loss:1.224071979522705,acc:0.46173406862745103,recall:0.32900538692539355,f1:0.3253486202688452,pre:0.3899733053817132
Ldg epoch 39 | train loss:1.19070303440094,test loss:1.5368822813034058,acc:0.3292892156862745,recall:0.2388425909139451,f1:0.16313050919204364,pre:0.196989095464278
Ldg epoch 40 | train loss:1.1895060539245605,test loss:1.7361633777618408,acc:0.28161764705882353,recall:0.21282361089710047,f1:0.11225343176397712,pre:0.1679728275031659
Ldg epoch 41 | train loss:1.1867105960845947,test loss:1.8837569952011108,acc:0.26697303921568627,recall:0.20508837091072193,f1:0.09499177883556792,pre:0.0950450175811794
Ldg epoch 42 | train loss:1.1871570348739624,test loss:1.3203099966049194,acc:0.41731004901960783,recall:0.31835818355349804,f1:0.294595619605929,pre:0.40122316479410475
Ldg epoch 43 | train loss:1.1767958402633667,test loss:1.317929983139038,acc:0.4131740196078431,recall:0.3019271939764036,f1:0.276093942997639,pre:0.3714744908287568
Ldg epoch 44 | train loss:1.1789551973342896,test loss:1.50248384475708,acc:0.3481924019607843,recall:0.2523231135810891,f1:0.18988746980262206,pre:0.24973210223039724
Ldg epoch 45 | train loss:1.1629093885421753,test loss:1.2671619653701782,acc:0.450765931372549,recall:0.3114459591159171,f1:0.3036002446953072,pre:0.3741945462629252
Ldg epoch 46 | train loss:1.1787437200546265,test loss:1.2121690511703491,acc:0.46590073529411763,recall:0.3525214688085248,f1:0.34508479995618535,pre:0.3925238061769638
epoch 46 : weight has update
Ldg epoch 47 | train loss:1.1601201295852661,test loss:1.2420008182525635,acc:0.44512867647058824,recall:0.3185897406877816,f1:0.3045932743599653,pre:0.36972196332968293
Ldg epoch 48 | train loss:1.163122534751892,test loss:1.3738391399383545,acc:0.4302389705882353,recall:0.34819800807188656,f1:0.3292794686196384,pre:0.3419877294203396
Ldg epoch 49 | train loss:1.1536622047424316,test loss:1.2450933456420898,acc:0.4501225490196078,recall:0.3382032490986281,f1:0.32565083724752647,pre:0.4257528777998476
Ldg epoch 50 | train loss:1.1641947031021118,test loss:1.2824963331222534,acc:0.44555759803921574,recall:0.34499809608563875,f1:0.3303041874114585,pre:0.3735997152452926
Ldg epoch 51 | train loss:1.1674115657806396,test loss:1.2242183685302734,acc:0.4635110294117647,recall:0.3545808973686997,f1:0.3443520259747418,pre:0.4245583210378485
epoch 51 : weight has update
Ldg epoch 52 | train loss:1.1647777557373047,test loss:1.7382023334503174,acc:0.27876838235294116,recall:0.21119239548152607,f1:0.10987882401154973,pre:0.12144223403478967
Ldg epoch 53 | train loss:1.1525522470474243,test loss:1.3342591524124146,acc:0.43097426470588235,recall:0.35608563418281736,f1:0.3377479748145173,pre:0.38588905569437143
Ldg epoch 54 | train loss:1.151974081993103,test loss:1.5877646207809448,acc:0.3130821078431373,recall:0.2371639702617029,f1:0.16082149502543447,pre:0.26320841671065914
Ldg epoch 55 | train loss:1.1447458267211914,test loss:1.7680195569992065,acc:0.29699754901960784,recall:0.22062858126490675,f1:0.12724634047956,pre:0.12350949046544547
Ldg epoch 56 | train loss:1.1528955698013306,test loss:1.7618651390075684,acc:0.2680453431372549,recall:0.20505516583657427,f1:0.09665428249383157,pre:0.12707177421157004
Ldg epoch 57 | train loss:1.1423320770263672,test loss:1.323493242263794,acc:0.42092524509803925,recall:0.30665355101457964,f1:0.2807233318122746,pre:0.3624892813036869
Ldg epoch 58 | train loss:1.1457425355911255,test loss:1.200744867324829,acc:0.47549019607843135,recall:0.3545910467808992,f1:0.3590352398047877,pre:0.44640428907588364
epoch 58 : weight has update
Ldg epoch 59 | train loss:1.1521447896957397,test loss:1.256317377090454,acc:0.45484068627450985,recall:0.33865635029640007,f1:0.33236101910929533,pre:0.4523197087800061
Ldg epoch 60 | train loss:1.1382935047149658,test loss:1.3500579595565796,acc:0.4065870098039216,recall:0.3129662728657435,f1:0.2868579256808232,pre:0.4364610096366734
Ldg epoch 61 | train loss:1.136971354484558,test loss:1.2718504667282104,acc:0.44543504901960784,recall:0.3343288304095903,f1:0.31802156693611944,pre:0.3952633823776428
Ldg epoch 62 | train loss:1.1404798030853271,test loss:1.4568016529083252,acc:0.3565563725490196,recall:0.2619145111586915,f1:0.20433075551696195,pre:0.32444132687090316
Ldg epoch 63 | train loss:1.1382570266723633,test loss:1.254359483718872,acc:0.4467524509803922,recall:0.3611356356900412,f1:0.35845301453487755,pre:0.44037543955512104
Ldg epoch 64 | train loss:1.121991753578186,test loss:1.237331509590149,acc:0.46703431372549015,recall:0.35486187704706335,f1:0.3502712543938987,pre:0.4694330918001722
epoch 64 : weight has update
Ldg epoch 65 | train loss:1.1410133838653564,test loss:1.532450795173645,acc:0.3324142156862745,recall:0.24386544065015398,f1:0.1716174316287404,pre:0.2280335055870327
Ldg epoch 66 | train loss:1.1311452388763428,test loss:1.4458001852035522,acc:0.3587622549019608,recall:0.2633568597590259,f1:0.2068907288786928,pre:0.3242368020607892
Ldg epoch 67 | train loss:1.122622013092041,test loss:1.7581573724746704,acc:0.28137254901960784,recall:0.21331815025334663,f1:0.11477431933905097,pre:0.16762509677544604
Ldg epoch 68 | train loss:1.1174414157867432,test loss:1.2125961780548096,acc:0.47261029411764705,recall:0.34620534578179707,f1:0.3496929377034063,pre:0.44843847749607274
Ldg epoch 69 | train loss:1.1351318359375,test loss:1.4112886190414429,acc:0.39304534313725487,recall:0.2880553713951209,f1:0.24950191003795233,pre:0.33862719413811015
Ldg epoch 70 | train loss:1.1104918718338013,test loss:1.9736930131912231,acc:0.27322303921568625,recall:0.2081416652741635,f1:0.10293632999425946,pre:0.1435549489412246
Ldg epoch 71 | train loss:1.1184968948364258,test loss:1.2506622076034546,acc:0.4546875,recall:0.37075098717607274,f1:0.3708637804468828,pre:0.46588123790637376
epoch 71 : weight has update
Ldg epoch 72 | train loss:1.120413064956665,test loss:1.426133394241333,acc:0.37634803921568627,recall:0.2774859995884859,f1:0.2305081693738066,pre:0.3316955802154989
Ldg epoch 73 | train loss:1.1226515769958496,test loss:1.4803051948547363,acc:0.4029105392156863,recall:0.3354770857956978,f1:0.3014723350823848,pre:0.3716586951001938
Ldg epoch 74 | train loss:1.1165558099746704,test loss:1.3154557943344116,acc:0.4311274509803922,recall:0.3243480449458608,f1:0.3014927898611866,pre:0.4020714821556501
Ldg epoch 75 | train loss:1.1161350011825562,test loss:1.2930281162261963,acc:0.4436274509803922,recall:0.3314433803815569,f1:0.31821014395387254,pre:0.42698183800393563
Ldg epoch 76 | train loss:1.1213937997817993,test loss:1.2144945859909058,acc:0.47178308823529413,recall:0.3620925724832374,f1:0.3643248374325168,pre:0.4861387517338491
epoch 76 : weight has update
Ldg epoch 77 | train loss:1.115071415901184,test loss:1.210361361503601,acc:0.47359068627450984,recall:0.36665291161735114,f1:0.3769361472786591,pre:0.5053004623076587
epoch 77 : weight has update
Ldg epoch 78 | train loss:1.110182523727417,test loss:1.5855073928833008,acc:0.3744791666666667,recall:0.34098243461904376,f1:0.2925034152562158,pre:0.384405261818731
Ldg epoch 79 | train loss:1.1045160293579102,test loss:1.222655177116394,acc:0.4707107843137255,recall:0.34299643023749865,f1:0.3405417537776816,pre:0.45173632343698555
Ldg epoch 80 | train loss:1.110516905784607,test loss:1.486807942390442,acc:0.36299019607843136,recall:0.2746747617275608,f1:0.2252590017076607,pre:0.351616223453573
Ldg epoch 81 | train loss:1.1112511157989502,test loss:1.2222825288772583,acc:0.47135416666666663,recall:0.3424406093857294,f1:0.33815858800351867,pre:0.4314927742629108
Ldg epoch 82 | train loss:1.1019824743270874,test loss:1.2617707252502441,acc:0.45036764705882354,recall:0.35379141519776586,f1:0.3388305725418455,pre:0.4648317781890083
Ldg epoch 83 | train loss:1.110026240348816,test loss:2.052438497543335,acc:0.2592830882352941,recall:0.19985002678448358,f1:0.08330182633816736,pre:0.06638252338419656
Ldg epoch 84 | train loss:1.095663070678711,test loss:1.3300328254699707,acc:0.3966605392156863,recall:0.29094755992998844,f1:0.25296705912133055,pre:0.34971552602595957
Ldg epoch 85 | train loss:1.1074544191360474,test loss:1.3507097959518433,acc:0.41712622549019607,recall:0.3259902477915042,f1:0.3051892466515809,pre:0.4335472888175234
Ldg epoch 86 | train loss:1.1121541261672974,test loss:1.5294760465621948,acc:0.3304227941176471,recall:0.24628535736514448,f1:0.17734027083412024,pre:0.2877136371501672
Ldg epoch 87 | train loss:1.1090764999389648,test loss:1.2261935472488403,acc:0.4572610294117647,recall:0.3133687949607651,f1:0.3053972655142471,pre:0.3852307531910667
Ldg epoch 88 | train loss:1.0934213399887085,test loss:1.2048113346099854,acc:0.47359068627450984,recall:0.34381166696674514,f1:0.33997552668722275,pre:0.42982804812733905
Ldg epoch 89 | train loss:1.0901867151260376,test loss:1.4603452682495117,acc:0.3647671568627451,recall:0.2768457404505367,f1:0.23012984561828476,pre:0.3687876108476701
Ldg epoch 90 | train loss:1.1017649173736572,test loss:1.3702861070632935,acc:0.43354779411764705,recall:0.36721444115928514,f1:0.34686047008047116,pre:0.38819716352131933
Ldg epoch 91 | train loss:1.0963757038116455,test loss:1.314815878868103,acc:0.4231924019607843,recall:0.31240794451117476,f1:0.2860626908984976,pre:0.3888648566836922
Ldg epoch 92 | train loss:1.0854549407958984,test loss:1.2191734313964844,acc:0.4581495098039216,recall:0.3514690628076052,f1:0.343690879187705,pre:0.4263337052536909
Ldg epoch 93 | train loss:1.087697148323059,test loss:1.7197527885437012,acc:0.2864583333333333,recall:0.21966923295897833,f1:0.12528519373028701,pre:0.17231126881186454
Ldg epoch 94 | train loss:1.092606782913208,test loss:1.2977272272109985,acc:0.4348651960784313,recall:0.3281712366538755,f1:0.3128085328698058,pre:0.4362364215393261
Ldg epoch 95 | train loss:1.0887868404388428,test loss:1.2163515090942383,acc:0.46314338235294117,recall:0.34154213899316493,f1:0.33986960372800123,pre:0.45715232119790833
Ldg epoch 96 | train loss:1.089900255203247,test loss:1.2534430027008057,acc:0.4449754901960784,recall:0.3272307849527306,f1:0.30774805365461305,pre:0.4027032863240134
Ldg epoch 97 | train loss:1.080908179283142,test loss:1.2011539936065674,acc:0.4775428921568628,recall:0.3917205442889896,f1:0.3998685868367858,pre:0.46533743466497396
epoch 97 : weight has update
Ldg epoch 98 | train loss:1.0812757015228271,test loss:1.2587952613830566,acc:0.4597120098039216,recall:0.35415096204027097,f1:0.3576323612269552,pre:0.4954594894045643
Ldg epoch 99 | train loss:1.077854037284851,test loss:1.2502325773239136,acc:0.46660539215686275,recall:0.3553550974456147,f1:0.35815273963756705,pre:0.49850045338418447
Ldg epoch 100 | train loss:1.0859774351119995,test loss:1.238521695137024,acc:0.46568627450980393,recall:0.3346173876746538,f1:0.3332347329232682,pre:0.4464227470093123
Ldg epoch 101 | train loss:1.0761607885360718,test loss:1.2567493915557861,acc:0.46014093137254897,recall:0.34730806545503634,f1:0.34485340954328114,pre:0.46206448872854794
Ldg epoch 102 | train loss:1.0709493160247803,test loss:1.3278721570968628,acc:0.4223039215686275,recall:0.3284836472407825,f1:0.307339984422975,pre:0.4415778571780945
Ldg epoch 103 | train loss:1.0832325220108032,test loss:1.682897925376892,acc:0.2840686274509804,recall:0.22767532650825165,f1:0.13984420187447158,pre:0.2627828343409489
Ldg epoch 104 | train loss:1.0792014598846436,test loss:1.247434139251709,acc:0.46715686274509804,recall:0.37400036317776464,f1:0.38239030084232983,pre:0.4735751604167155
Ldg epoch 105 | train loss:1.0716478824615479,test loss:1.310446858406067,acc:0.4542279411764706,recall:0.3655698793868164,f1:0.35839393192723673,pre:0.4656452466329731
Ldg epoch 106 | train loss:1.070420742034912,test loss:1.2103747129440308,acc:0.46308210784313725,recall:0.3630088214696747,f1:0.36169348596156004,pre:0.4403486408668245
Ldg epoch 107 | train loss:1.0809004306793213,test loss:1.23228919506073,acc:0.4595281862745098,recall:0.3355279750051715,f1:0.33058785343468133,pre:0.4507408414618668
Ldg epoch 108 | train loss:1.0654246807098389,test loss:1.5831512212753296,acc:0.335906862745098,recall:0.2817190342309037,f1:0.22699433234443656,pre:0.3723839339642159
Ldg epoch 109 | train loss:1.0825483798980713,test loss:1.2701700925827026,acc:0.45784313725490194,recall:0.37600200089089714,f1:0.3701006077760275,pre:0.42338651850165876
Ldg epoch 110 | train loss:1.0739092826843262,test loss:1.4127289056777954,acc:0.3888786764705882,recall:0.2964233214870989,f1:0.26347078547289954,pre:0.41076409026189337
Ldg epoch 111 | train loss:1.064330816268921,test loss:1.2200382947921753,acc:0.4632352941176471,recall:0.3592897320108209,f1:0.36078961399196996,pre:0.4485318990812317
Ldg epoch 112 | train loss:1.076743721961975,test loss:2.1930370330810547,acc:0.2595588235294118,recall:0.20016552075375574,f1:0.08252186785538466,pre:0.05782423449219973
Ldg epoch 113 | train loss:1.0649827718734741,test loss:1.2143913507461548,acc:0.47882965686274515,recall:0.3551581097957785,f1:0.35931492236839785,pre:0.4607693814195578
Ldg epoch 114 | train loss:1.0719014406204224,test loss:2.00119948387146,acc:0.2733762254901961,recall:0.21123291341638367,f1:0.10734979300141428,pre:0.2068721958586523
Ldg epoch 115 | train loss:1.0739548206329346,test loss:1.5044654607772827,acc:0.36887254901960786,recall:0.2808372707107566,f1:0.23565198149778707,pre:0.37326354106138715
Ldg epoch 116 | train loss:1.07025146484375,test loss:1.9502439498901367,acc:0.2931985294117647,recall:0.22360922289706275,f1:0.13190080092361806,pre:0.17330518406118928
Ldg epoch 117 | train loss:1.076228380203247,test loss:1.4068201780319214,acc:0.3998774509803922,recall:0.3130864762482019,f1:0.2880811432754578,pre:0.42708086399950757
Ldg epoch 118 | train loss:1.0648194551467896,test loss:1.3041809797286987,acc:0.4265625,recall:0.3261255873537457,f1:0.30953218352511996,pre:0.43732991461039805
Ldg epoch 119 | train loss:1.0633447170257568,test loss:1.3096023797988892,acc:0.442984068627451,recall:0.3574244606876675,f1:0.32727872161327,pre:0.4680018692316935
Ldg epoch 120 | train loss:1.0647624731063843,test loss:1.2618930339813232,acc:0.44938725490196074,recall:0.34388215900177577,f1:0.330211966929817,pre:0.4350102098682404
Ldg epoch 121 | train loss:1.0684033632278442,test loss:1.2190555334091187,acc:0.46090686274509807,recall:0.32114840935015543,f1:0.31844911289454997,pre:0.41748960647769423
Ldg epoch 122 | train loss:1.0631155967712402,test loss:1.2909345626831055,acc:0.4449754901960784,recall:0.3503415937019851,f1:0.34329625001128417,pre:0.47271411194088797
Ldg epoch 123 | train loss:1.0640555620193481,test loss:1.2962186336517334,acc:0.45597426470588237,recall:0.3664242628747297,f1:0.35969151930207904,pre:0.4563996564796055
Ldg epoch 124 | train loss:1.0610147714614868,test loss:1.4762895107269287,acc:0.3941176470588235,recall:0.33560622457268086,f1:0.28872856026410815,pre:0.37388599438066294
Ldg epoch 125 | train loss:1.055938482284546,test loss:1.207576870918274,acc:0.4759191176470588,recall:0.3877072215060906,f1:0.40325776163828614,pre:0.494507442878781
epoch 125 : weight has update
Ldg epoch 126 | train loss:1.0579885244369507,test loss:1.696158766746521,acc:0.3102022058823529,recall:0.2417836735703386,f1:0.16830440544441547,pre:0.31941559321576046
Ldg epoch 127 | train loss:1.0481038093566895,test loss:1.4735771417617798,acc:0.4096813725490196,recall:0.32320834815453037,f1:0.30370019620575434,pre:0.4503992750736081
Ldg epoch 128 | train loss:1.049991488456726,test loss:1.2173455953598022,acc:0.47549019607843135,recall:0.3594780498503477,f1:0.3561481609849141,pre:0.46608651408953977
Ldg epoch 129 | train loss:1.059380054473877,test loss:1.253395915031433,acc:0.45649509803921573,recall:0.3507088804098403,f1:0.3444869107928496,pre:0.46230478067213404
Ldg epoch 130 | train loss:1.0504825115203857,test loss:1.3668369054794312,acc:0.407015931372549,recall:0.3242103711737328,f1:0.30463065980729037,pre:0.4562649380950031
Ldg epoch 131 | train loss:1.0623859167099,test loss:1.457985281944275,acc:0.3490502450980392,recall:0.27145044937737534,f1:0.21925678971752258,pre:0.3878924718248155
Ldg epoch 132 | train loss:1.0454388856887817,test loss:1.2735413312911987,acc:0.4528492647058823,recall:0.36640866135349703,f1:0.3706102912284719,pre:0.47213739540285454
Ldg epoch 133 | train loss:1.0500305891036987,test loss:1.5955508947372437,acc:0.3694852941176471,recall:0.32459567065963574,f1:0.2567918845642928,pre:0.324295144940251
Ldg epoch 134 | train loss:1.0553916692733765,test loss:1.2688692808151245,acc:0.4506127450980392,recall:0.3417960513582305,f1:0.34078018158828727,pre:0.508017996329014
Ldg epoch 135 | train loss:1.0521787405014038,test loss:1.3334920406341553,acc:0.42873774509803925,recall:0.32695551027472336,f1:0.3153155499358655,pre:0.4557102267957118
Ldg epoch 136 | train loss:1.0572600364685059,test loss:1.298431158065796,acc:0.4388480392156863,recall:0.33686081181554917,f1:0.3261213508281829,pre:0.4632937274352285
Ldg epoch 137 | train loss:1.0524834394454956,test loss:1.2354180812835693,acc:0.46277573529411764,recall:0.35242204324495224,f1:0.3571992355895804,pre:0.48422140012395737
Ldg epoch 138 | train loss:1.061568260192871,test loss:1.3226357698440552,acc:0.4076899509803922,recall:0.3171777058034434,f1:0.2911014348224553,pre:0.4327666604071089
Ldg epoch 139 | train loss:1.0529961585998535,test loss:1.211254596710205,acc:0.4822916666666666,recall:0.3835874084151981,f1:0.39391664662609044,pre:0.4872662414482695
Ldg epoch 140 | train loss:1.048715591430664,test loss:1.224245309829712,acc:0.46920955882352944,recall:0.34634475557111793,f1:0.355208046483273,pre:0.47363819890799863
Ldg epoch 141 | train loss:1.0518893003463745,test loss:1.2082633972167969,acc:0.4622549019607843,recall:0.33077051465578095,f1:0.32804247385077934,pre:0.4203865297864065
Ldg epoch 142 | train loss:1.0426132678985596,test loss:1.5106065273284912,acc:0.34816176470588234,recall:0.26647315115489545,f1:0.21129715481529526,pre:0.3561385647599926
Ldg epoch 143 | train loss:1.0452849864959717,test loss:1.309254765510559,acc:0.4278186274509804,recall:0.31772959976004866,f1:0.30091495243307054,pre:0.4344713837272736
Ldg epoch 144 | train loss:1.0335309505462646,test loss:1.3050463199615479,acc:0.4362745098039216,recall:0.32980619609915635,f1:0.3206963934176534,pre:0.4718614543462547
Ldg epoch 145 | train loss:1.041880488395691,test loss:1.2126375436782837,acc:0.4786764705882353,recall:0.3592649456078746,f1:0.3626316755677566,pre:0.4537006625765222
Ldg epoch 146 | train loss:1.046873688697815,test loss:1.6163471937179565,acc:0.3308517156862745,recall:0.2539778386126339,f1:0.18789341978693017,pre:0.3215278314088542
Ldg epoch 147 | train loss:1.0457919836044312,test loss:1.189142107963562,acc:0.4857843137254902,recall:0.386839767016499,f1:0.4007416841711037,pre:0.4998111859010558
epoch 147 : weight has update
Ldg epoch 148 | train loss:1.0330755710601807,test loss:1.904866337776184,acc:0.2957720588235294,recall:0.22679727778820127,f1:0.13774312084808243,pre:0.2719755456184687
Ldg epoch 149 | train loss:1.0293163061141968,test loss:1.22704017162323,acc:0.4713848039215687,recall:0.3762317539779089,f1:0.38437568339573047,pre:0.4742753103719482
Ldg epoch 150 | train loss:1.0427879095077515,test loss:1.2340692281723022,acc:0.46522671568627455,recall:0.34856779759134476,f1:0.33587958201094725,pre:0.38987501221944754
training has finished used time : 3815.84139251709
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (16927, 18)
trait shape (1, 16927)
df shape (20087, 42195)
(5000, 32032) (11927, 32032)
train dataset already completed!
5000
test dataset already completed!
11927
FC epoch 1 | train loss:0.7136697173118591,test loss:0.6260519623756409,acc:0.675987222479186,recall:0.5,f1:0.4030384413061591,pre:0.337993611239593
epoch 1 : weight has update
FC epoch 2 | train loss:0.6476799249649048,test loss:0.867098331451416,acc:0.6778843374190564,recall:0.5,f1:0.40354234646129145,pre:0.3389421687095282
epoch 2 : weight has update
FC epoch 3 | train loss:0.6444834470748901,test loss:0.6802066564559937,acc:0.6664293767345051,recall:0.5072179298711884,f1:0.44583729508871406,pre:0.5376419636781088
epoch 3 : weight has update
FC epoch 4 | train loss:0.6575892567634583,test loss:0.6367514133453369,acc:0.6695623265494912,recall:0.5043203610275665,f1:0.4329571339693214,pre:0.5362426729216789
FC epoch 5 | train loss:0.6172725558280945,test loss:0.5017499327659607,acc:0.760746704440333,recall:0.7709681553837434,f1:0.7443349411901142,pre:0.7418777997643327
epoch 5 : weight has update
FC epoch 6 | train loss:0.4506832957267761,test loss:0.4042653441429138,acc:0.8287682123034227,recall:0.8370383414506894,f1:0.8137404556339473,pre:0.8060476302830429
epoch 6 : weight has update
FC epoch 7 | train loss:0.3439524173736572,test loss:0.3288658857345581,acc:0.8500086725254393,recall:0.7787660736273415,f1:0.8040614317636798,pre:0.8816665192722769
epoch 7 : weight has update
FC epoch 8 | train loss:0.293423593044281,test loss:0.27118638157844543,acc:0.9143009944495838,recall:0.896470970321243,f1:0.9002492947805749,pre:0.9070136595804783
epoch 8 : weight has update
FC epoch 9 | train loss:0.2541261911392212,test loss:0.2546895444393158,acc:0.899839558279371,recall:0.910531547778036,f1:0.8895696800013199,pre:0.8795418863132313
FC epoch 10 | train loss:0.24574370682239532,test loss:0.37962576746940613,acc:0.8247427150786308,recall:0.7310142785802857,f1:0.756178823278539,pre:0.8881519485682488
FC epoch 11 | train loss:0.23599813878536224,test loss:0.19966542720794678,acc:0.9254488031914894,recall:0.9205483613607405,f1:0.9151292891485651,pre:0.9113928532161912
epoch 11 : weight has update
FC epoch 12 | train loss:0.22158679366111755,test loss:0.20000238716602325,acc:0.929058741905643,recall:0.92026203003704,f1:0.9181759522101189,pre:0.9178628945497141
epoch 12 : weight has update
FC epoch 13 | train loss:0.22305794060230255,test loss:0.2802670896053314,acc:0.8897360661424606,recall:0.8364015768823183,f1:0.8610788470432964,pre:0.9165402984807326
FC epoch 14 | train loss:0.21921679377555847,test loss:0.21179847419261932,acc:0.9164149225254393,recall:0.9114288817258176,f1:0.9048636253350195,pre:0.9012678369802403
FC epoch 15 | train loss:0.2241390496492386,test loss:0.2117701768875122,acc:0.9227783880666051,recall:0.8973412632046325,f1:0.9083958297361112,pre:0.9247971801868363
FC epoch 16 | train loss:0.2252626270055771,test loss:0.22325940430164337,acc:0.9267316142460685,recall:0.9275023432692854,f1:0.9171787129426255,pre:0.9103806636227165
FC epoch 17 | train loss:0.2273377925157547,test loss:0.20813366770744324,acc:0.9179940448658649,recall:0.9200986505832616,f1:0.9080491914117793,pre:0.9004941548793695
FC epoch 18 | train loss:0.22348029911518097,test loss:0.38546013832092285,acc:0.8313446750693801,recall:0.8681904421172968,f1:0.8230625844902698,pre:0.8237109874445767
FC epoch 19 | train loss:0.2059255838394165,test loss:0.2105696201324463,acc:0.9297706117021277,recall:0.9157992087476383,f1:0.9183344727040647,pre:0.9227560709369769
epoch 19 : weight has update
FC epoch 20 | train loss:0.20647059381008148,test loss:0.1965765357017517,acc:0.9261389916743755,recall:0.910813074060931,f1:0.9141023010852988,pre:0.919403416796112
FC epoch 21 | train loss:0.22124630212783813,test loss:0.18291790783405304,acc:0.9381901884828862,recall:0.9282801081112699,f1:0.9280003493213929,pre:0.9289517983284123
epoch 21 : weight has update
FC epoch 22 | train loss:0.2089335322380066,test loss:0.21744397282600403,acc:0.9171737685013877,recall:0.922291457256875,f1:0.9073660806224361,pre:0.8979264631670071
FC epoch 23 | train loss:0.2040286809206009,test loss:0.19166043400764465,acc:0.9366472016651248,recall:0.9233447881693888,f1:0.9262330910804354,pre:0.931463359696183
FC epoch 24 | train loss:0.2091236561536789,test loss:0.21906805038452148,acc:0.9188251618871415,recall:0.9260305079474562,f1:0.9094338681749569,pre:0.8997700721418874
FC epoch 25 | train loss:0.20905451476573944,test loss:0.19268295168876648,acc:0.9359461725254393,recall:0.9289636758301332,f1:0.9266741286566538,pre:0.9255320570456234
FC epoch 26 | train loss:0.20905418694019318,test loss:0.2602591812610626,acc:0.9040312789084181,recall:0.9096605369270161,f1:0.8932251476554841,pre:0.8841949938117168
FC epoch 27 | train loss:0.20131626725196838,test loss:0.18772289156913757,acc:0.9356715425531915,recall:0.9324825031808041,f1:0.9267032778455683,pre:0.9227413871753347
FC epoch 28 | train loss:0.1953803300857544,test loss:0.20291045308113098,acc:0.9278590425531915,recall:0.927941207905942,f1:0.9186941688957988,pre:0.9127544615661746
FC epoch 29 | train loss:0.19280821084976196,test loss:0.23168498277664185,acc:0.9241551514801111,recall:0.8912353007327353,f1:0.9080056406770735,pre:0.9355436837707111
FC epoch 30 | train loss:0.19965451955795288,test loss:0.18082115054130554,acc:0.9421903908418131,recall:0.9286104731931568,f1:0.9324593487601723,pre:0.9381156611859035
epoch 30 : weight has update
FC epoch 31 | train loss:0.2038111537694931,test loss:0.19849324226379395,acc:0.9285239361702128,recall:0.9291262735590498,f1:0.9193041196287031,pre:0.9125904063275553
FC epoch 32 | train loss:0.2003713697195053,test loss:0.20880398154258728,acc:0.9234071461609621,recall:0.9240303701638185,f1:0.9136577326981561,pre:0.906679239497278
FC epoch 33 | train loss:0.19569411873817444,test loss:0.1822182983160019,acc:0.935031943802035,recall:0.9273893616482971,f1:0.9255430795429029,pre:0.9250995741915549
FC epoch 34 | train loss:0.21790355443954468,test loss:0.18520183861255646,acc:0.9401957099907493,recall:0.9308343055785486,f1:0.9309806820387063,pre:0.9324414927374121
FC epoch 35 | train loss:0.20701643824577332,test loss:0.2759956419467926,acc:0.8899384250693801,recall:0.8351634176694386,f1:0.8608206973528947,pre:0.9192077257000252
FC epoch 36 | train loss:0.20105336606502533,test loss:0.21752196550369263,acc:0.9203320131822387,recall:0.9279834113431141,f1:0.9116321815099913,pre:0.9023342341960041
FC epoch 37 | train loss:0.20514072477817535,test loss:0.19966699182987213,acc:0.9207114361702128,recall:0.923736329997233,f1:0.9111501195822941,pre:0.9031168944934719
FC epoch 38 | train loss:0.2001415193080902,test loss:0.18039380013942719,acc:0.9367881302035153,recall:0.9232741883862617,f1:0.9260888122280222,pre:0.9310059240466683
FC epoch 39 | train loss:0.21375355124473572,test loss:0.22542786598205566,acc:0.915500693802035,recall:0.9233472830188265,f1:0.9058864544698196,pre:0.8955893028898948
FC epoch 40 | train loss:0.19162437319755554,test loss:0.1827903687953949,acc:0.9391983695652174,recall:0.9303892702075812,f1:0.929742342420471,pre:0.9305412161804838
FC epoch 41 | train loss:0.19873133301734924,test loss:0.18904025852680206,acc:0.9378685823311749,recall:0.9358895860093789,f1:0.9292650689578981,pre:0.9246156648491075
FC epoch 42 | train loss:0.20182321965694427,test loss:0.17840498685836792,acc:0.9415616327474561,recall:0.9357442802367661,f1:0.9332424594424438,pre:0.9320057220453168
epoch 42 : weight has update
FC epoch 43 | train loss:0.20691093802452087,test loss:0.18841615319252014,acc:0.9382733001850138,recall:0.9211116129021378,f1:0.9274628877004961,pre:0.9368526802537298
FC epoch 44 | train loss:0.1919790506362915,test loss:0.2169014811515808,acc:0.9155476699814986,recall:0.9225597477962179,f1:0.9058051940160594,pre:0.8957683650518825
FC epoch 45 | train loss:0.19076305627822876,test loss:0.1816404163837433,acc:0.9404450450971323,recall:0.9283467794235412,f1:0.9308472865072638,pre:0.9346353593608601
FC epoch 46 | train loss:0.19588951766490936,test loss:0.20436228811740875,acc:0.9315051167900094,recall:0.9322535781126182,f1:0.9225439902264293,pre:0.9159487789883659
FC epoch 47 | train loss:0.19402959942817688,test loss:0.19547851383686066,acc:0.9317436112395929,recall:0.9280355769397272,f1:0.921477813303124,pre:0.9181934294355742
FC epoch 48 | train loss:0.19277861714363098,test loss:0.19803261756896973,acc:0.9310534227567068,recall:0.9075910747118121,f1:0.9176115773125927,pre:0.932201998576607
FC epoch 49 | train loss:0.19536425173282623,test loss:0.2021597921848297,acc:0.9334528214616096,recall:0.9311495016930347,f1:0.9245214280028297,pre:0.9198634033140156
FC epoch 50 | train loss:0.19454097747802734,test loss:0.18122589588165283,acc:0.9388659227567068,recall:0.932260257453901,f1:0.9300644010607235,pre:0.9292818361985649
FC epoch 51 | train loss:0.20692680776119232,test loss:0.22025582194328308,acc:0.9233963055041627,recall:0.9271669669084307,f1:0.913777348646796,pre:0.9053809873962936
FC epoch 52 | train loss:0.19879820942878723,test loss:0.1913110613822937,acc:0.9364195478723404,recall:0.9150535242673874,f1:0.9248061733760752,pre:0.9388914007258012
FC epoch 53 | train loss:0.1953781545162201,test loss:0.23355978727340698,acc:0.9104778561517114,recall:0.9220250581780002,f1:0.9011525701009487,pre:0.8901204892745825
FC epoch 54 | train loss:0.18539072573184967,test loss:0.24028293788433075,acc:0.9101923855226642,recall:0.9202890914313274,f1:0.9008972906438597,pre:0.8911038394557438
FC epoch 55 | train loss:0.18970239162445068,test loss:0.19842243194580078,acc:0.9295935476410732,recall:0.9282171801601939,f1:0.9200739128282847,pre:0.9146149285045945
FC epoch 56 | train loss:0.2090526968240738,test loss:0.1858675628900528,acc:0.9379047178538391,recall:0.9262801621226562,f1:0.9282117199309535,pre:0.9317577783734589
FC epoch 57 | train loss:0.19668801128864288,test loss:0.19057796895503998,acc:0.9385804521276596,recall:0.9228248475574717,f1:0.9279945480761781,pre:0.9356158014732354
FC epoch 58 | train loss:0.20018301904201508,test loss:0.17496268451213837,acc:0.9434840425531915,recall:0.9299088209372061,f1:0.9343716118954613,pre:0.9403188722976401
epoch 58 : weight has update
FC epoch 59 | train loss:0.18958532810211182,test loss:0.2290075272321701,acc:0.9138745952821461,recall:0.9221236125159606,f1:0.9042609190893897,pre:0.8944350876675566
FC epoch 60 | train loss:0.1920643448829651,test loss:0.22470374405384064,acc:0.9181132920906567,recall:0.9239497505979043,f1:0.9086093624614884,pre:0.8996314398156859
FC epoch 61 | train loss:0.2021753191947937,test loss:0.19244693219661713,acc:0.9270640610545792,recall:0.9264284575411987,f1:0.9174599036719036,pre:0.9113969707891089
FC epoch 62 | train loss:0.1944752186536789,test loss:0.2389615923166275,acc:0.9160102046716004,recall:0.9217248949982672,f1:0.9063240747560604,pre:0.8969101435306478
FC epoch 63 | train loss:0.18888475000858307,test loss:0.18274201452732086,acc:0.9375722710453285,recall:0.928033563646299,f1:0.9280676074301931,pre:0.9298089470647743
FC epoch 64 | train loss:0.19641512632369995,test loss:0.22503168880939484,acc:0.9142901537927844,recall:0.8793092165171572,f1:0.8962578448552634,pre:0.9238088610572828
FC epoch 65 | train loss:0.18687182664871216,test loss:0.18230412900447845,acc:0.9369904891304348,recall:0.9269793024733263,f1:0.9272438401873146,pre:0.92883950513588
FC epoch 66 | train loss:0.19411295652389526,test loss:0.18027445673942566,acc:0.9355414546716004,recall:0.9332756221861458,f1:0.9270035928668362,pre:0.922680846071212
FC epoch 67 | train loss:0.183980330824852,test loss:0.18925073742866516,acc:0.9356607018963923,recall:0.9329415266135767,f1:0.9266501567501496,pre:0.9224499154312457
FC epoch 68 | train loss:0.19258876144886017,test loss:0.18618732690811157,acc:0.9362424838112859,recall:0.9170906230518471,f1:0.9250114286382708,pre:0.9362107577568841
FC epoch 69 | train loss:0.20170515775680542,test loss:0.19450441002845764,acc:0.9275265957446809,recall:0.9174172623869594,f1:0.9163970909822413,pre:0.9167422555466801
FC epoch 70 | train loss:0.1865653097629547,test loss:0.1986006647348404,acc:0.927219443802035,recall:0.9253857071344075,f1:0.9168003639184455,pre:0.9111928164023186
FC epoch 71 | train loss:0.1905824989080429,test loss:0.17864550650119781,acc:0.940278821692877,recall:0.9295747705604729,f1:0.9308889552393429,pre:0.9337754334034541
FC epoch 72 | train loss:0.18763156235218048,test loss:0.1709713637828827,acc:0.9445536540240519,recall:0.9370122108898079,f1:0.9362156124796933,pre:0.9368551485925997
epoch 72 : weight has update
FC epoch 73 | train loss:0.1934366375207901,test loss:0.20544077455997467,acc:0.9300560823311749,recall:0.9308553272545503,f1:0.9208636121866463,pre:0.9141981140960612
FC epoch 74 | train loss:0.2054281234741211,test loss:0.17531675100326538,acc:0.9396609042553191,recall:0.9346602053896086,f1:0.9310397281788153,pre:0.928761660914093
FC epoch 75 | train loss:0.19334669411182404,test loss:0.20775915682315826,acc:0.9318845397779834,recall:0.9309299089876024,f1:0.9225515088939106,pre:0.9172104992004037
FC epoch 76 | train loss:0.19849389791488647,test loss:0.1712864190340042,acc:0.9460135291396855,recall:0.9358954687442257,f1:0.9375930221236648,pre:0.940665623343146
epoch 76 : weight has update
FC epoch 77 | train loss:0.19377440214157104,test loss:0.17948074638843536,acc:0.9347934493524515,recall:0.9254679002007226,f1:0.925288513318274,pre:0.9268972708933543
FC epoch 78 | train loss:0.20063644647598267,test loss:0.21896998584270477,acc:0.9238118640148011,recall:0.9268919403484068,f1:0.9146689650659547,pre:0.9068363660302327
FC epoch 79 | train loss:0.19444258511066437,test loss:0.18308387696743011,acc:0.9389851699814986,recall:0.9220767812295964,f1:0.9282758152151395,pre:0.9370942992478976
FC epoch 80 | train loss:0.19273510575294495,test loss:0.2096952348947525,acc:0.9304716408418131,recall:0.9292566196762956,f1:0.9216388271031761,pre:0.916353434840747
FC epoch 81 | train loss:0.19490012526512146,test loss:0.18220874667167664,acc:0.9394838401942647,recall:0.9309196392276792,f1:0.929568914732944,pre:0.9296550529100078
FC epoch 82 | train loss:0.21033969521522522,test loss:0.18877333402633667,acc:0.9370844414893617,recall:0.9228327365103335,f1:0.9267853928260054,pre:0.9328150424388858
FC epoch 83 | train loss:0.18792706727981567,test loss:0.20846432447433472,acc:0.9249501329787234,recall:0.9302323907838176,f1:0.9159561249700294,pre:0.9070732493446969
FC epoch 84 | train loss:0.18219143152236938,test loss:0.19779346883296967,acc:0.9326686806197966,recall:0.9313096636737083,f1:0.9237259898734733,pre:0.9183148642398818
FC epoch 85 | train loss:0.1902947872877121,test loss:0.18474647402763367,acc:0.9327987685013877,recall:0.9091408560676706,f1:0.9202786532418823,pre:0.9364573709424688
FC epoch 86 | train loss:0.18872028589248657,test loss:0.20018033683300018,acc:0.9272555793246993,recall:0.9273602386585261,f1:0.917586647288002,pre:0.9110554457811096
FC epoch 87 | train loss:0.19498006999492645,test loss:0.1719767302274704,acc:0.9443151595744681,recall:0.9386292588591048,f1:0.936307988656169,pre:0.9352423839584553
FC epoch 88 | train loss:0.1771193891763687,test loss:0.1947953999042511,acc:0.9299151537927844,recall:0.9326741008190261,f1:0.921139434179947,pre:0.9136269447521335
FC epoch 89 | train loss:0.18549303710460663,test loss:0.17358456552028656,acc:0.9448499653098983,recall:0.9356320546888849,f1:0.9360121047010483,pre:0.9376914248137265
FC epoch 90 | train loss:0.18672621250152588,test loss:0.18810530006885529,acc:0.937001329787234,recall:0.9292854747612117,f1:0.9277041830566964,pre:0.9277213751992236
FC epoch 91 | train loss:0.19427035748958588,test loss:0.22897401452064514,acc:0.9246791165587419,recall:0.9252764969941171,f1:0.9149868508937636,pre:0.9081349830370159
FC epoch 92 | train loss:0.18970967829227448,test loss:0.16732460260391235,acc:0.9445175185013877,recall:0.9284785548003018,f1:0.9350465574049981,pre:0.9437657045435547
FC epoch 93 | train loss:0.1847187876701355,test loss:0.19085150957107544,acc:0.9349235372340425,recall:0.9140943508607206,f1:0.9232890847212138,pre:0.9362546527658578
FC epoch 94 | train loss:0.18826644122600555,test loss:0.1731625497341156,acc:0.9396030874190564,recall:0.9265341290240904,f1:0.9294774506397783,pre:0.9345219802719227
FC epoch 95 | train loss:0.18730026483535767,test loss:0.3218960165977478,acc:0.8850926514801111,recall:0.9051616981723263,f1:0.8757698388611057,pre:0.8656430370556297
FC epoch 96 | train loss:0.1943732053041458,test loss:0.195671945810318,acc:0.9290117657261795,recall:0.9293499042868714,f1:0.9198142608812012,pre:0.9132898749994921
FC epoch 97 | train loss:0.1975727081298828,test loss:0.18382036685943604,acc:0.9389128989361702,recall:0.9328476278539736,f1:0.9300895546637334,pre:0.9286664687796977
FC epoch 98 | train loss:0.19241704046726227,test loss:0.22510603070259094,acc:0.9180771565679925,recall:0.9227913673818553,f1:0.9087330801751471,pre:0.8998185969149792
FC epoch 99 | train loss:0.2007802128791809,test loss:0.21373924612998962,acc:0.9248670212765957,recall:0.9299196811843132,f1:0.9160135960911253,pre:0.9078860332020283
FC epoch 100 | train loss:0.19532382488250732,test loss:0.18670842051506042,acc:0.9333335742368178,recall:0.9095902711325519,f1:0.9206783567903208,pre:0.93695729228595
FC epoch 101 | train loss:0.18216049671173096,test loss:0.19106867909431458,acc:0.9347573138297872,recall:0.9252466173040137,f1:0.925185250573054,pre:0.9264197260622818
FC epoch 102 | train loss:0.18420137465000153,test loss:0.2272176295518875,acc:0.9120208429694727,recall:0.9200145470621859,f1:0.9024149097450702,pre:0.8927202678071359
FC epoch 103 | train loss:0.19928660988807678,test loss:0.19932052493095398,acc:0.9333335742368178,recall:0.9293858447745917,f1:0.9241891692510493,pre:0.9204952140777558
FC epoch 104 | train loss:0.18758998811244965,test loss:0.20455192029476166,acc:0.9291779891304348,recall:0.9250764551437192,f1:0.9198060542431493,pre:0.9163996497657899
FC epoch 105 | train loss:0.18478117883205414,test loss:0.1901634782552719,acc:0.9384395235892691,recall:0.934008135358427,f1:0.9296744558395242,pre:0.9268068693045391
FC epoch 106 | train loss:0.18296721577644348,test loss:0.19402572512626648,acc:0.9307932469935244,recall:0.9311414773274376,f1:0.921766032116412,pre:0.9156170888593398
FC epoch 107 | train loss:0.18224108219146729,test loss:0.22194981575012207,acc:0.9160102046716004,recall:0.9236191001995112,f1:0.9066580356363407,pre:0.8967102006977149
FC epoch 108 | train loss:0.18920978903770447,test loss:0.183304563164711,acc:0.9376192472247918,recall:0.9304334493193062,f1:0.9285342247615684,pre:0.9275988074318721
FC epoch 109 | train loss:0.1912035346031189,test loss:0.18711838126182556,acc:0.9365387950971323,recall:0.932078550673425,f1:0.927813627489206,pre:0.9249967818448777
FC epoch 110 | train loss:0.18043309450149536,test loss:0.1806318163871765,acc:0.9369904891304348,recall:0.9309692154115844,f1:0.9278436688046963,pre:0.9260984804810732
FC epoch 111 | train loss:0.1870250552892685,test loss:0.20043659210205078,acc:0.9324916165587419,recall:0.9267787159921069,f1:0.9228017423322606,pre:0.9202813617946382
FC epoch 112 | train loss:0.1785908192396164,test loss:0.18223926424980164,acc:0.9312557816836263,recall:0.91599690234639,f1:0.9198263453165312,pre:0.9255890704071916
FC epoch 113 | train loss:0.19180260598659515,test loss:0.18583334982395172,acc:0.9356498612395929,recall:0.9331645266346824,f1:0.9270326980532017,pre:0.9234554873673404
FC epoch 114 | train loss:0.19293631613254547,test loss:0.23237739503383636,acc:0.9191684493524515,recall:0.8825019877435988,f1:0.9012548120902362,pre:0.9332608372538462
FC epoch 115 | train loss:0.18856513500213623,test loss:0.16826096177101135,acc:0.9419302150786308,recall:0.927418272075675,f1:0.9315904343102464,pre:0.9377586812071219
FC epoch 116 | train loss:0.18422295153141022,test loss:0.18878719210624695,acc:0.9348295848751157,recall:0.9339302539102906,f1:0.9261303193335689,pre:0.920681880288179
FC epoch 117 | train loss:0.18586395680904388,test loss:0.19412750005722046,acc:0.9338792206290472,recall:0.9305809543919452,f1:0.925034015403582,pre:0.9213905006619808
FC epoch 118 | train loss:0.18125797808170319,test loss:0.2178473025560379,acc:0.9254379625346901,recall:0.9278169789685813,f1:0.9161134888571059,pre:0.9087178971121442
FC epoch 119 | train loss:0.18914589285850525,test loss:0.1878783404827118,acc:0.9373699121184089,recall:0.928685267184811,f1:0.9281185174039467,pre:0.9289800308929352
FC epoch 120 | train loss:0.18887317180633545,test loss:0.18935367465019226,acc:0.9410629625346901,recall:0.9270137855422597,f1:0.9304261605420454,pre:0.9362554143158106
FC epoch 121 | train loss:0.1842833012342453,test loss:0.20080965757369995,acc:0.9350066489361702,recall:0.9329522450197697,f1:0.9263631439381225,pre:0.9218527324592292
FC epoch 122 | train loss:0.17968030273914337,test loss:0.20610733330249786,acc:0.9284769599907493,recall:0.8988614667770145,f1:0.9142379778027196,pre:0.9387588304447894
FC epoch 123 | train loss:0.18012364208698273,test loss:0.18298666179180145,acc:0.9383202763644773,recall:0.9206796833677988,f1:0.927628942971619,pre:0.9374298121646255
FC epoch 124 | train loss:0.1976381093263626,test loss:0.2428600937128067,acc:0.9125556487049029,recall:0.9166887864097564,f1:0.9024848209376355,pre:0.8938943521689169
FC epoch 125 | train loss:0.18345558643341064,test loss:0.24607440829277039,acc:0.9024991327474561,recall:0.9125248783936047,f1:0.8925756958294785,pre:0.8822433587029151
FC epoch 126 | train loss:0.1743113100528717,test loss:0.1956334114074707,acc:0.9318014280758558,recall:0.9301539001002473,f1:0.9225971427981224,pre:0.917380850431412
FC epoch 127 | train loss:0.1795535385608673,test loss:0.18631404638290405,acc:0.9356498612395929,recall:0.9261635702167385,f1:0.9259181360259648,pre:0.9268937301329334
FC epoch 128 | train loss:0.19670411944389343,test loss:0.20251736044883728,acc:0.9274687789084181,recall:0.9278720821309391,f1:0.9180669242166877,pre:0.9120726186567614
FC epoch 129 | train loss:0.1812162548303604,test loss:0.20142020285129547,acc:0.9270170848751157,recall:0.9283498669329223,f1:0.9177469021174047,pre:0.9106648110536318
FC epoch 130 | train loss:0.1861402839422226,test loss:0.18513613939285278,acc:0.9379047178538391,recall:0.9241801443424188,f1:0.9271082503572041,pre:0.9316506207831204
FC epoch 131 | train loss:0.18830452859401703,test loss:0.1835457980632782,acc:0.9352921195652174,recall:0.9200719392275796,f1:0.9245769852414089,pre:0.9309920715489994
FC epoch 132 | train loss:0.1823415607213974,test loss:0.17728973925113678,acc:0.9377384944495838,recall:0.9240856229501487,f1:0.9276958958948198,pre:0.9331633881359932
FC epoch 133 | train loss:0.186188206076622,test loss:0.18296469748020172,acc:0.9351150555041627,recall:0.9238578350186775,f1:0.9246713373841519,pre:0.9270820170720723
FC epoch 134 | train loss:0.18576432764530182,test loss:0.19244633615016937,acc:0.9297127948658649,recall:0.9271730651167445,f1:0.9201360042089025,pre:0.9153596414451177
FC epoch 135 | train loss:0.1713794618844986,test loss:0.18979240953922272,acc:0.9338792206290472,recall:0.9306321232991491,f1:0.924972178215136,pre:0.9216367167169481
FC epoch 136 | train loss:0.18092049658298492,test loss:0.1827009618282318,acc:0.9346272259481961,recall:0.9301408726033233,f1:0.925389625442397,pre:0.9222440208377697
FC epoch 137 | train loss:0.1910126954317093,test loss:0.2746724486351013,acc:0.9161547467622572,recall:0.919819631868707,f1:0.9057462219117992,pre:0.8971991765186541
FC epoch 138 | train loss:0.18502356112003326,test loss:0.1824483573436737,acc:0.936029284227567,recall:0.925891877232004,f1:0.9261924580245838,pre:0.9279045771585565
FC epoch 139 | train loss:0.1944476068019867,test loss:0.17988869547843933,acc:0.9412653214616096,recall:0.9287173216899943,f1:0.9312745249401443,pre:0.9362264842571384
FC epoch 140 | train loss:0.1834528148174286,test loss:0.18439267575740814,acc:0.9349126965772433,recall:0.9335472964402194,f1:0.9260237348643723,pre:0.9208316926162948
FC epoch 141 | train loss:0.19006720185279846,test loss:0.18622945249080658,acc:0.9330264222941721,recall:0.9134634294511319,f1:0.9213064018715641,pre:0.9331008746204996
FC epoch 142 | train loss:0.18392670154571533,test loss:0.23370036482810974,acc:0.9274434840425532,recall:0.8960338253918667,f1:0.912311827378948,pre:0.939176927224496
FC epoch 143 | train loss:0.18709853291511536,test loss:0.19342893362045288,acc:0.9318267229417205,recall:0.931408633476189,f1:0.922798893309308,pre:0.9168104075724963
FC epoch 144 | train loss:0.18940119445323944,test loss:0.17982721328735352,acc:0.9394115691489362,recall:0.9349033553941586,f1:0.9308679183955724,pre:0.928838502381639
FC epoch 145 | train loss:0.18020223081111908,test loss:0.19497676193714142,acc:0.9313027578630898,recall:0.9302041057887689,f1:0.9221650361089377,pre:0.916502190556509
FC epoch 146 | train loss:0.18666252493858337,test loss:0.18607333302497864,acc:0.9367881302035153,recall:0.933022987039404,f1:0.9282102475904467,pre:0.9251699338819481
FC epoch 147 | train loss:0.19490456581115723,test loss:0.1698419600725174,acc:0.9431877312673451,recall:0.9374922052002043,f1:0.9346886358884201,pre:0.9329615747719497
FC epoch 148 | train loss:0.18239407241344452,test loss:0.17047010362148285,acc:0.9434840425531915,recall:0.9317191836500945,f1:0.9344139082929732,pre:0.9387938320285952
FC epoch 149 | train loss:0.18233710527420044,test loss:0.1898583471775055,acc:0.9362424838112859,recall:0.9184791166064528,f1:0.9250313516327909,pre:0.9342234912143914
FC epoch 150 | train loss:0.18258120119571686,test loss:0.1844303458929062,acc:0.9421072791396855,recall:0.9250061572570268,f1:0.9318451442246543,pre:0.9420289383856295
training has finished used time : 4197.145660638809
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (16298, 18)
trait shape (1, 16298)
df shape (20087, 42195)
(5000, 32032) (11298, 32032)
train dataset already completed!
5000
test dataset already completed!
11298
P_CLR epoch 1 | train loss:0.7809842824935913,test loss:0.8148062229156494,acc:0.5482846579643094,recall:0.5,f1:0.3535776543322411,pre:0.2741423289821547
epoch 1 : weight has update
P_CLR epoch 2 | train loss:0.6911920309066772,test loss:2.0907773971557617,acc:0.5482846579643094,recall:0.5,f1:0.3535002309382299,pre:0.2741423289821547
P_CLR epoch 3 | train loss:0.6807100772857666,test loss:1.023806095123291,acc:0.5338834269662921,recall:0.48833298133030284,f1:0.3550250501496167,pre:0.3437339067075842
epoch 3 : weight has update
P_CLR epoch 4 | train loss:0.6467909216880798,test loss:0.9010196924209595,acc:0.5393051883674819,recall:0.49270700303391984,f1:0.35658485424341463,pre:0.3718084316486751
epoch 4 : weight has update
P_CLR epoch 5 | train loss:0.623641312122345,test loss:0.6120155453681946,acc:0.6160515118968936,recall:0.576992882975793,f1:0.5109605876213844,pre:0.7349337826365585
epoch 5 : weight has update
P_CLR epoch 6 | train loss:0.5629285573959351,test loss:0.9275661706924438,acc:0.547313904494382,recall:0.5000323001229127,f1:0.35359421906698735,pre:0.2849008559674423
P_CLR epoch 7 | train loss:0.5379451513290405,test loss:0.6662738919258118,acc:0.5815278007270324,recall:0.5376128234144615,f1:0.43133271043589777,pre:0.7625496215957803
P_CLR epoch 8 | train loss:0.48091766238212585,test loss:0.49538782238960266,acc:0.7714288664904164,recall:0.7491795273062651,f1:0.7455154975292466,pre:0.8427953243906078
epoch 8 : weight has update
P_CLR epoch 9 | train loss:0.348243772983551,test loss:0.3171275854110718,acc:0.8715094183740912,recall:0.8590717301796159,f1:0.8645481827964006,pre:0.8980794661087699
epoch 9 : weight has update
P_CLR epoch 10 | train loss:0.29385247826576233,test loss:0.330522358417511,acc:0.8859467944481163,recall:0.8753334479996321,f1:0.8807011194593107,pre:0.90699050019068
epoch 10 : weight has update
P_CLR epoch 11 | train loss:0.277539998292923,test loss:0.2954084575176239,acc:0.890180931923331,recall:0.8820789093269709,f1:0.8859679153399226,pre:0.9037238076330906
epoch 11 : weight has update
P_CLR epoch 12 | train loss:0.271566241979599,test loss:0.24332177639007568,acc:0.9082018341044282,recall:0.9018456104637248,f1:0.9050132218650684,pre:0.9152389575668279
epoch 12 : weight has update
P_CLR epoch 13 | train loss:0.26309552788734436,test loss:0.2442050725221634,acc:0.9075822042300067,recall:0.9007545495058404,f1:0.904600359153558,pre:0.9185325087744637
epoch 13 : weight has update
P_CLR epoch 14 | train loss:0.2675468325614929,test loss:0.24704766273498535,acc:0.9167114177131528,recall:0.9140561964625001,f1:0.9149942441540387,pre:0.9178407113262453
epoch 14 : weight has update
P_CLR epoch 15 | train loss:0.2581649124622345,test loss:0.2380133718252182,acc:0.9152243060145406,recall:0.9095547785155658,f1:0.9125464123194509,pre:0.9217082633330074
P_CLR epoch 16 | train loss:0.24395625293254852,test loss:0.21846438944339752,acc:0.921875,recall:0.9163795567490819,f1:0.9195551843556605,pre:0.9285257145100005
epoch 16 : weight has update
P_CLR epoch 17 | train loss:0.2548583447933197,test loss:0.24739938974380493,acc:0.9146718027098479,recall:0.9094701614927889,f1:0.91241259100606,pre:0.9215041014607793
P_CLR epoch 18 | train loss:0.2530486285686493,test loss:0.2507788836956024,acc:0.9172845753469927,recall:0.918316970805066,f1:0.91625679673241,pre:0.9159925484252706
P_CLR epoch 19 | train loss:0.2504499554634094,test loss:0.2319944202899933,acc:0.9108559153998678,recall:0.9042310705661728,f1:0.9080268618011642,pre:0.9205859597998545
P_CLR epoch 20 | train loss:0.24597874283790588,test loss:0.22022388875484467,acc:0.9236719266358229,recall:0.9201268825241066,f1:0.9219399911086208,pre:0.9266196899427337
epoch 20 : weight has update
P_CLR epoch 21 | train loss:0.24155555665493011,test loss:0.24611006677150726,acc:0.9202019993390614,recall:0.9149367810821802,f1:0.9177630896331663,pre:0.9262204562805701
P_CLR epoch 22 | train loss:0.24632598459720612,test loss:0.24227365851402283,acc:0.9221125247851949,recall:0.9209440427582869,f1:0.9206855461897495,pre:0.9217584710133867
P_CLR epoch 23 | train loss:0.25925832986831665,test loss:0.2319633662700653,acc:0.916055642762723,recall:0.9094706569465121,f1:0.9132627392180148,pre:0.9259431651139822
P_CLR epoch 24 | train loss:0.2412174940109253,test loss:0.21481436491012573,acc:0.9268320389953734,recall:0.9259299948297057,f1:0.9255263649554932,pre:0.9263560589977233
epoch 24 : weight has update
P_CLR epoch 25 | train loss:0.2341911643743515,test loss:0.22856418788433075,acc:0.9265893506278915,recall:0.9214891027842415,f1:0.924573098758666,pre:0.9321946106108738
epoch 25 : weight has update
P_CLR epoch 26 | train loss:0.24413585662841797,test loss:0.2090948522090912,acc:0.9207080304031724,recall:0.9208827760471038,f1:0.9195123754779811,pre:0.9194112388138412
P_CLR epoch 27 | train loss:0.24652980268001556,test loss:0.2013714611530304,acc:0.9341591622604097,recall:0.9310822865415204,f1:0.9325723284617335,pre:0.9361788439616608
epoch 27 : weight has update
P_CLR epoch 28 | train loss:0.23116150498390198,test loss:0.2515449523925781,acc:0.8998161764705882,recall:0.8909382179981308,f1:0.8956652489456657,pre:0.9151004818211746
P_CLR epoch 29 | train loss:0.2377610057592392,test loss:0.21859167516231537,acc:0.9244826090548578,recall:0.9242607203519301,f1:0.9234445054953648,pre:0.9239410478717643
P_CLR epoch 30 | train loss:0.23427200317382812,test loss:0.21096570789813995,acc:0.9267236037673496,recall:0.9257556287884662,f1:0.9253962621683992,pre:0.9261298368738609
P_CLR epoch 31 | train loss:0.23338682949543,test loss:0.2038537561893463,acc:0.9316599884335757,recall:0.9273846651727472,f1:0.9298699514743859,pre:0.9357682046651697
P_CLR epoch 32 | train loss:0.22537127137184143,test loss:0.2087445855140686,acc:0.9250764210178453,recall:0.9199835477729245,f1:0.9230078716068307,pre:0.9310557919969628
P_CLR epoch 33 | train loss:0.22301509976387024,test loss:0.21007220447063446,acc:0.9271366903502973,recall:0.9239277335907157,f1:0.9254133027632288,pre:0.9298500880151037
P_CLR epoch 34 | train loss:0.23358826339244843,test loss:0.20359180867671967,acc:0.9315463896232651,recall:0.9293312062118333,f1:0.9299809186479073,pre:0.9328308224820103
P_CLR epoch 35 | train loss:0.22740428149700165,test loss:0.20735202729701996,acc:0.9318562045604758,recall:0.9281635325679263,f1:0.930265647423812,pre:0.9354435522863204
P_CLR epoch 36 | train loss:0.2458769530057907,test loss:0.22325308620929718,acc:0.926677131526768,recall:0.9254362055381037,f1:0.9253186307478625,pre:0.9266623068320643
P_CLR epoch 37 | train loss:0.2318519502878189,test loss:0.20461101830005646,acc:0.9303639292795769,recall:0.9270928746049594,f1:0.9287406977167237,pre:0.932848039127786
P_CLR epoch 38 | train loss:0.234420046210289,test loss:0.23266689479351044,acc:0.9193913169200264,recall:0.9131084504958292,f1:0.9168616707289682,pre:0.9284327254069149
P_CLR epoch 39 | train loss:0.24021562933921814,test loss:0.21434803307056427,acc:0.9245290812954395,recall:0.9196303153170184,f1:0.9223847719172503,pre:0.9313838811094228
P_CLR epoch 40 | train loss:0.22469709813594818,test loss:0.218890979886055,acc:0.9248802048909451,recall:0.9193264384450267,f1:0.9226677623362652,pre:0.9324647776387904
P_CLR epoch 41 | train loss:0.21855278313159943,test loss:0.2116663008928299,acc:0.9255101619299405,recall:0.9250929904438973,f1:0.9244663349501653,pre:0.9247877345519486
P_CLR epoch 42 | train loss:0.23119719326496124,test loss:0.21040651202201843,acc:0.9332193902842035,recall:0.9284854795595641,f1:0.9312309858837056,pre:0.9376308955161774
P_CLR epoch 43 | train loss:0.2190673053264618,test loss:0.21025095880031586,acc:0.9257993225380039,recall:0.9208882952835331,f1:0.9239184373620826,pre:0.9323268237245678
P_CLR epoch 44 | train loss:0.2202756106853485,test loss:0.20599649846553802,acc:0.9297288086582948,recall:0.9277999687039733,f1:0.9283173630228678,pre:0.9304864881130595
P_CLR epoch 45 | train loss:0.23067188262939453,test loss:0.21339815855026245,acc:0.9270489094514209,recall:0.9273438119257218,f1:0.9257932012835512,pre:0.9254252291996662
P_CLR epoch 46 | train loss:0.22755645215511322,test loss:0.21513468027114868,acc:0.9317477693324521,recall:0.928750641520924,f1:0.9302015822334289,pre:0.933839269248141
P_CLR epoch 47 | train loss:0.22921545803546906,test loss:0.20087698101997375,acc:0.9310868307997355,recall:0.9296656799384213,f1:0.9298548526849344,pre:0.931360106439083
P_CLR epoch 48 | train loss:0.21628844738006592,test loss:0.21523283421993256,acc:0.9295325925313945,recall:0.9288746399813566,f1:0.928439268610148,pre:0.928863051792113
P_CLR epoch 49 | train loss:0.21407558023929596,test loss:0.21542921662330627,acc:0.926914656311963,recall:0.921833001089425,f1:0.9248680290313682,pre:0.9338525691488822
P_CLR epoch 50 | train loss:0.22000129520893097,test loss:0.20688113570213318,acc:0.9324964887640449,recall:0.929396277130325,f1:0.9311660554213493,pre:0.9352125887692642
P_CLR epoch 51 | train loss:0.21062418818473816,test loss:0.24113672971725464,acc:0.9130504378717779,recall:0.9058591539008547,f1:0.9100714188723042,pre:0.9248593424207122
P_CLR epoch 52 | train loss:0.220330148935318,test loss:0.21532869338989258,acc:0.9322744547257105,recall:0.9314685421014784,f1:0.9311598252348475,pre:0.9318479602749933
P_CLR epoch 53 | train loss:0.22279514372348785,test loss:0.2107052505016327,acc:0.9318975132187707,recall:0.9279340800117597,f1:0.92998828445219,pre:0.9354284185578424
P_CLR epoch 54 | train loss:0.2311917096376419,test loss:0.2016923725605011,acc:0.9300541143423662,recall:0.9256155876919827,f1:0.9281905434677081,pre:0.9354644322221406
P_CLR epoch 55 | train loss:0.21793125569820404,test loss:0.2004939466714859,acc:0.9328217944481163,recall:0.930927861118633,f1:0.9314238809911807,pre:0.9335692802979725
P_CLR epoch 56 | train loss:0.21442259848117828,test loss:0.19305019080638885,acc:0.935806345009914,recall:0.9344584301669222,f1:0.9347278837671454,pre:0.9367782907198156
epoch 56 : weight has update
P_CLR epoch 57 | train loss:0.2268824726343155,test loss:0.19471842050552368,acc:0.9345361037673496,recall:0.9302991540756632,f1:0.9329400334109689,pre:0.9396585434395555
P_CLR epoch 58 | train loss:0.21313437819480896,test loss:0.21043366193771362,acc:0.9251642019167217,recall:0.9190391954259435,f1:0.9228339722609281,pre:0.9332247625489899
P_CLR epoch 59 | train loss:0.20275601744651794,test loss:0.2014775425195694,acc:0.933240044613351,recall:0.9293497102655819,f1:0.931492462772908,pre:0.9365163349244763
P_CLR epoch 60 | train loss:0.221352681517601,test loss:0.1935834139585495,acc:0.934117853602115,recall:0.9324625566966749,f1:0.9329689962834115,pre:0.9344994678556692
P_CLR epoch 61 | train loss:0.2152833193540573,test loss:0.20165780186653137,acc:0.9339216374752148,recall:0.9320568236537664,f1:0.9327319423693555,pre:0.9347782223782688
P_CLR epoch 62 | train loss:0.22314880788326263,test loss:0.19324786961078644,acc:0.9308906146728354,recall:0.9297031125605839,f1:0.9295775313345679,pre:0.9304897551126688
P_CLR epoch 63 | train loss:0.20262914896011353,test loss:0.20943573117256165,acc:0.9259025941837409,recall:0.9211196677261579,f1:0.9238818288265579,pre:0.931959484536712
P_CLR epoch 64 | train loss:0.2166585922241211,test loss:0.20590338110923767,acc:0.9347529742233972,recall:0.9319812860282515,f1:0.9333810536102498,pre:0.9370938594386218
P_CLR epoch 65 | train loss:0.21530452370643616,test loss:0.2064320296049118,acc:0.9281280981493721,recall:0.9238624793483956,f1:0.9261869838913486,pre:0.9328696846260381
P_CLR epoch 66 | train loss:0.2164314240217209,test loss:0.20167216658592224,acc:0.9287167465300726,recall:0.9239347986883557,f1:0.9268410302653411,pre:0.9348145039691274
P_CLR epoch 67 | train loss:0.2170756757259369,test loss:0.19947996735572815,acc:0.9329095753469927,recall:0.931321281284947,f1:0.9316378635328397,pre:0.9330547589826999
P_CLR epoch 68 | train loss:0.22195212543010712,test loss:0.21429388225078583,acc:0.925866449107733,recall:0.9196764430380692,f1:0.9234302531132822,pre:0.9339821939497235
P_CLR epoch 69 | train loss:0.20621001720428467,test loss:0.26694419980049133,acc:0.9014581956378057,recall:0.905118661379349,f1:0.9003800103194959,pre:0.9020747563200228
P_CLR epoch 70 | train loss:0.21954360604286194,test loss:0.2237330973148346,acc:0.9213431510244546,recall:0.9223345345421818,f1:0.9202442815702151,pre:0.9199409251087929
P_CLR epoch 71 | train loss:0.21226543188095093,test loss:0.21321596205234528,acc:0.9261297918043622,recall:0.920912981693273,f1:0.9240540295701849,pre:0.9327755956528151
P_CLR epoch 72 | train loss:0.2139536291360855,test loss:0.2001774162054062,acc:0.9306066176470588,recall:0.9257284894859706,f1:0.9287042269868067,pre:0.936709743943117
P_CLR epoch 73 | train loss:0.2135353833436966,test loss:0.20143435895442963,acc:0.9311333030403172,recall:0.9262780733654898,f1:0.9292944175807006,pre:0.9368834364755338
P_CLR epoch 74 | train loss:0.22530497610569,test loss:0.19589941203594208,acc:0.9342934153998678,recall:0.9300657994086017,f1:0.932617911838349,pre:0.9389329973802715
P_CLR epoch 75 | train loss:0.22630950808525085,test loss:0.2551742196083069,acc:0.9046854345670853,recall:0.8973767368273955,f1:0.9011795289720441,pre:0.9161802068671072
P_CLR epoch 76 | train loss:0.21253234148025513,test loss:0.1928018480539322,acc:0.934117853602115,recall:0.9320643573443309,f1:0.9328310000103751,pre:0.9352468656364862
P_CLR epoch 77 | train loss:0.21516898274421692,test loss:0.1971179097890854,acc:0.933678949107733,recall:0.9298727266536172,f1:0.9319141509795503,pre:0.9372185904278216
P_CLR epoch 78 | train loss:0.2071085423231125,test loss:0.24025700986385345,acc:0.919370662590879,recall:0.9125151710145426,f1:0.9166409412711531,pre:0.929146439775177
P_CLR epoch 79 | train loss:0.20888040959835052,test loss:0.3075796365737915,acc:0.8776747356245869,recall:0.8850918056552013,f1:0.8766588307236961,pre:0.8849805742698571
P_CLR epoch 80 | train loss:0.21562759578227997,test loss:0.2281530648469925,acc:0.9100658873099802,recall:0.914542135334923,f1:0.9093652185271529,pre:0.9103556157066623
P_CLR epoch 81 | train loss:0.20824478566646576,test loss:0.24908797442913055,acc:0.9174188284864507,recall:0.9101507068373561,f1:0.9146095308997196,pre:0.9285364890036171
P_CLR epoch 82 | train loss:0.2086697816848755,test loss:0.18781711161136627,acc:0.9359405981493721,recall:0.9336473989551632,f1:0.9347383836785135,pre:0.9372583109529553
P_CLR epoch 83 | train loss:0.20945239067077637,test loss:0.19890134036540985,acc:0.9343811962987442,recall:0.9318370461050024,f1:0.932905347555634,pre:0.9360390852089561
P_CLR epoch 84 | train loss:0.22117942571640015,test loss:0.20305462181568146,acc:0.9315050809649702,recall:0.9264584794282245,f1:0.9295269032947341,pre:0.9373881701106931
P_CLR epoch 85 | train loss:0.2078654170036316,test loss:0.2366418093442917,acc:0.9195255700594844,recall:0.9131441789605096,f1:0.9170163451962562,pre:0.9286061740354843
P_CLR epoch 86 | train loss:0.22042915225028992,test loss:0.20005258917808533,acc:0.9302554940515532,recall:0.9294066934360105,f1:0.9290068542593949,pre:0.9295079204081071
P_CLR epoch 87 | train loss:0.21682223677635193,test loss:0.1894724816083908,acc:0.9376084352280237,recall:0.9339120003215238,f1:0.9360537115276159,pre:0.9412559774706948
epoch 87 : weight has update
P_CLR epoch 88 | train loss:0.2275800257921219,test loss:0.19952857494354248,acc:0.9339629461335095,recall:0.931073580865973,f1:0.9326467750988212,pre:0.9361679508645021
P_CLR epoch 89 | train loss:0.22347193956375122,test loss:0.1915314793586731,acc:0.9365085922009253,recall:0.9345690068857805,f1:0.935193095534179,pre:0.9373048460398986
P_CLR epoch 90 | train loss:0.21482731401920319,test loss:0.19571278989315033,acc:0.9335033873099802,recall:0.9322458348384207,f1:0.9324963411657289,pre:0.9337102863561233
P_CLR epoch 91 | train loss:0.20273016393184662,test loss:0.1916140466928482,acc:0.9347116655651024,recall:0.9319449381321248,f1:0.9333180610733065,pre:0.9366319026178165
P_CLR epoch 92 | train loss:0.19880715012550354,test loss:0.18703551590442657,acc:0.9365963730998017,recall:0.9340699982820335,f1:0.9352370176813999,pre:0.9381665007755136
P_CLR epoch 93 | train loss:0.20684587955474854,test loss:0.19773639738559723,acc:0.9315050809649702,recall:0.9309596244552086,f1:0.9304747388076585,pre:0.9311230419942338
P_CLR epoch 94 | train loss:0.21746891736984253,test loss:0.19589637219905853,acc:0.9356979097818903,recall:0.9316630733879452,f1:0.9341196443810386,pre:0.9399831287065363
P_CLR epoch 95 | train loss:0.21652865409851074,test loss:0.2052062600851059,acc:0.934184980171844,recall:0.9342018278302646,f1:0.9331762228029858,pre:0.9333393000400371
P_CLR epoch 96 | train loss:0.21881286799907684,test loss:0.2062615007162094,acc:0.9318355502313285,recall:0.9271123011520905,f1:0.9300090185516409,pre:0.9375362764605669
P_CLR epoch 97 | train loss:0.20703944563865662,test loss:0.19846723973751068,acc:0.9338751652346331,recall:0.9313439496279774,f1:0.9323641295251719,pre:0.9356620537535706
P_CLR epoch 98 | train loss:0.2048155963420868,test loss:0.20660056173801422,acc:0.9326668869795108,recall:0.9328709042435857,f1:0.9316404733477938,pre:0.9313546217579614
P_CLR epoch 99 | train loss:0.20004421472549438,test loss:0.2290143221616745,acc:0.9160349884335757,recall:0.9172473539780073,f1:0.9148398163447728,pre:0.9150409033689347
P_CLR epoch 100 | train loss:0.20472726225852966,test loss:0.22595401108264923,acc:0.9238887970918703,recall:0.9180658732088655,f1:0.9214922450026328,pre:0.9320138495665694
P_CLR epoch 101 | train loss:0.20594310760498047,test loss:0.2090344876050949,acc:0.9273742151354925,recall:0.9221785475406633,f1:0.9254135175039948,pre:0.9344960360502087
P_CLR epoch 102 | train loss:0.21143969893455505,test loss:0.22143878042697906,acc:0.9239146150033046,recall:0.9175750653232286,f1:0.9214782523381401,pre:0.9331273409468599
P_CLR epoch 103 | train loss:0.2082366943359375,test loss:0.2655639350414276,acc:0.9188233228684732,recall:0.9122270870110638,f1:0.9161997163302104,pre:0.9293466876387853
P_CLR epoch 104 | train loss:0.21276988089084625,test loss:0.20274806022644043,acc:0.9329973562458691,recall:0.9286058771837451,f1:0.9312550347180341,pre:0.9380610217597954
P_CLR epoch 105 | train loss:0.2175433337688446,test loss:0.21267680823802948,acc:0.9299043704560476,recall:0.9255931156554424,f1:0.9281762436834085,pre:0.9345122952313137
P_CLR epoch 106 | train loss:0.21663744747638702,test loss:0.21513792872428894,acc:0.9276427214144084,recall:0.92768461669735,f1:0.9265463824616934,pre:0.9263218229839918
P_CLR epoch 107 | train loss:0.20397967100143433,test loss:0.23919688165187836,acc:0.9065959600132187,recall:0.9106044125451724,f1:0.9055922009172529,pre:0.9065756602412288
P_CLR epoch 108 | train loss:0.21036449074745178,test loss:0.20581549406051636,acc:0.9320782385988103,recall:0.9280969156217058,f1:0.9303700600763123,pre:0.9360353445688372
P_CLR epoch 109 | train loss:0.21568992733955383,test loss:0.22174052894115448,acc:0.9292692498347653,recall:0.9244123719297762,f1:0.9271943895413094,pre:0.9358661900232119
P_CLR epoch 110 | train loss:0.2022925764322281,test loss:0.21957054734230042,acc:0.9302968027098479,recall:0.9253293758237566,f1:0.9284390637563313,pre:0.936105499024092
P_CLR epoch 111 | train loss:0.20958323776721954,test loss:0.1944999247789383,acc:0.9367306262392597,recall:0.9332118257617037,f1:0.935193302602033,pre:0.9399082891800922
P_CLR epoch 112 | train loss:0.21155737340450287,test loss:0.2002018243074417,acc:0.9343605419695968,recall:0.9299616017640152,f1:0.9326968726950785,pre:0.9397687980836676
P_CLR epoch 113 | train loss:0.2135399878025055,test loss:0.31767910718917847,acc:0.8707348810310641,recall:0.8794249691110918,f1:0.8699388264100848,pre:0.8798606349852062
P_CLR epoch 114 | train loss:0.2017592489719391,test loss:0.2136307656764984,acc:0.9361368142762723,recall:0.9348177472019384,f1:0.9349720723472886,pre:0.935950307406106
P_CLR epoch 115 | train loss:0.1992429792881012,test loss:0.19073672592639923,acc:0.9337254213483146,recall:0.9321824436139913,f1:0.9324974294711821,pre:0.9337001823958112
P_CLR epoch 116 | train loss:0.21361388266086578,test loss:0.21250475943088531,acc:0.9324500165234633,recall:0.9279756971092642,f1:0.930898351616998,pre:0.9377610988529891
P_CLR epoch 117 | train loss:0.20680288970470428,test loss:0.19870910048484802,acc:0.9303432749504296,recall:0.9254554233299946,f1:0.9283531409370432,pre:0.9360816816655776
P_CLR epoch 118 | train loss:0.2018098384141922,test loss:0.271613210439682,acc:0.912100338730998,recall:0.9049544428283557,f1:0.9089007533585839,pre:0.923151366951646
P_CLR epoch 119 | train loss:0.20187032222747803,test loss:0.19416946172714233,acc:0.9362245951751487,recall:0.932128036776565,f1:0.9346216598387745,pre:0.9401291621634777
P_CLR epoch 120 | train loss:0.21233397722244263,test loss:0.20136968791484833,acc:0.9345774124256444,recall:0.931051732795017,f1:0.9329548573061025,pre:0.9375218890563071
P_CLR epoch 121 | train loss:0.21703551709651947,test loss:0.1854509711265564,acc:0.938310682419035,recall:0.935619127671079,f1:0.9369534669781349,pre:0.940342026645682
epoch 121 : weight has update
P_CLR epoch 122 | train loss:0.20788806676864624,test loss:0.2013697326183319,acc:0.9290059071381361,recall:0.9235411206730151,f1:0.9268937815376073,pre:0.9354514560393312
P_CLR epoch 123 | train loss:0.21334563195705414,test loss:0.19591647386550903,acc:0.9347116655651024,recall:0.931161364561477,f1:0.9330535888882219,pre:0.9373899176126933
P_CLR epoch 124 | train loss:0.21466605365276337,test loss:0.19695408642292023,acc:0.9344638136153338,recall:0.9307387097712233,f1:0.9329381501441536,pre:0.9384804704985636
P_CLR epoch 125 | train loss:0.2183426171541214,test loss:0.1931406706571579,acc:0.9353932584269663,recall:0.9340197347356411,f1:0.9343637114819013,pre:0.935903645069176
P_CLR epoch 126 | train loss:0.21092887222766876,test loss:0.20138315856456757,acc:0.9322744547257105,recall:0.9272574691760364,f1:0.9302544867479962,pre:0.9383713570344515
P_CLR epoch 127 | train loss:0.20534437894821167,test loss:0.20004859566688538,acc:0.9356307832121612,recall:0.9331102382630277,f1:0.9342757704803055,pre:0.9369399974024734
P_CLR epoch 128 | train loss:0.20124877989292145,test loss:0.22182762622833252,acc:0.9234550561797753,recall:0.9171413335337422,f1:0.9208864049067529,pre:0.9324867550390139
P_CLR epoch 129 | train loss:0.21460650861263275,test loss:0.1918579488992691,acc:0.9322538003965631,recall:0.9302120516542333,f1:0.931040336774024,pre:0.9336058670820565
P_CLR epoch 130 | train loss:0.20782218873500824,test loss:0.1921757310628891,acc:0.9395809236615994,recall:0.9363965881933007,f1:0.9380712369868125,pre:0.942557865634074
epoch 130 : weight has update
P_CLR epoch 131 | train loss:0.20386824011802673,test loss:0.24756371974945068,acc:0.9230781146728354,recall:0.9164587552861899,f1:0.920613381731258,pre:0.9324670135142084
P_CLR epoch 132 | train loss:0.21195174753665924,test loss:0.2138824313879013,acc:0.9247252974223397,recall:0.9252722545298192,f1:0.9235937536691458,pre:0.9239436743322482
P_CLR epoch 133 | train loss:0.20992068946361542,test loss:0.20407435297966003,acc:0.9336324768671512,recall:0.9324487766185001,f1:0.932372447861668,pre:0.9333661391873829
P_CLR epoch 134 | train loss:0.21458794176578522,test loss:0.2768246829509735,acc:0.9014633592200925,recall:0.9060174971342916,f1:0.9005511227056702,pre:0.9021130335274494
P_CLR epoch 135 | train loss:0.2050771564245224,test loss:0.20295700430870056,acc:0.9348614094514209,recall:0.9314825808126223,f1:0.9333896477696818,pre:0.9383353056336561
P_CLR epoch 136 | train loss:0.20181217789649963,test loss:0.20486602187156677,acc:0.9295325925313945,recall:0.9292630277828321,f1:0.9284438842294818,pre:0.9286042868131849
P_CLR epoch 137 | train loss:0.20113636553287506,test loss:0.2071610391139984,acc:0.9365344101123596,recall:0.9349647574096746,f1:0.9355020522510928,pre:0.9374193164930824
P_CLR epoch 138 | train loss:0.21136051416397095,test loss:0.21255938708782196,acc:0.9266977858559153,recall:0.9213641337394588,f1:0.9245865139697892,pre:0.9338442860424199
P_CLR epoch 139 | train loss:0.22051231563091278,test loss:0.2244434356689453,acc:0.9242863929279577,recall:0.9184810165975885,f1:0.921903523260286,pre:0.9317949158259167
P_CLR epoch 140 | train loss:0.20648173987865448,test loss:0.1953364461660385,acc:0.9364672835426305,recall:0.9330625835593231,f1:0.9349364980965519,pre:0.9401550909640591
P_CLR epoch 141 | train loss:0.20558685064315796,test loss:0.21507471799850464,acc:0.931375991407799,recall:0.9261964808964904,f1:0.9294186231990912,pre:0.9371615901622328
P_CLR epoch 142 | train loss:0.20755697786808014,test loss:0.2746035158634186,acc:0.8976887805684071,recall:0.9027186613039687,f1:0.8968564053516236,pre:0.8999519799510783
P_CLR epoch 143 | train loss:0.20944972336292267,test loss:0.23449140787124634,acc:0.9319439854593522,recall:0.9273275820663383,f1:0.9301468991129033,pre:0.9374141780997662
P_CLR epoch 144 | train loss:0.2023734599351883,test loss:0.19271831214427948,acc:0.9388580221414408,recall:0.9367217561712782,f1:0.9375867799320886,pre:0.9400139091834803
P_CLR epoch 145 | train loss:0.20831966400146484,test loss:0.2057376205921173,acc:0.9296616820885657,recall:0.9251569637413029,f1:0.9278643780321578,pre:0.934803301239265
P_CLR epoch 146 | train loss:0.20985496044158936,test loss:0.2126598209142685,acc:0.9281952247191011,recall:0.922750968922383,f1:0.926038444770026,pre:0.9350915952495382
P_CLR epoch 147 | train loss:0.21232479810714722,test loss:0.26419222354888916,acc:0.9166029824851288,recall:0.9098374953566979,f1:0.9137867373299163,pre:0.926919665952917
P_CLR epoch 148 | train loss:0.2017391175031662,test loss:0.19157706201076508,acc:0.934184980171844,recall:0.9330139009391105,f1:0.9330620269257632,pre:0.9337467345700832
P_CLR epoch 149 | train loss:0.2117103934288025,test loss:0.20245586335659027,acc:0.933849347323199,recall:0.9302438399820855,f1:0.9322871673529072,pre:0.937150112983724
P_CLR epoch 150 | train loss:0.20806533098220825,test loss:0.20277081429958344,acc:0.9257115416391275,recall:0.9257910307729982,f1:0.9244585353971085,pre:0.9244876084750221
training has finished used time : 3810.6335146427155
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (12866, 18)
trait shape (1, 12866)
df shape (20087, 42195)
(5000, 32032) (7866, 32032)
train dataset already completed!
5000
test dataset already completed!
7866
Mot epoch 1 | train loss:1.4957774877548218,test loss:1.5945322513580322,acc:0.07916348025583983,recall:0.19671875600544836,f1:0.02924921949114002,pre:0.040900975224184635
epoch 1 : weight has update
Mot epoch 2 | train loss:1.3972504138946533,test loss:1.5571378469467163,acc:0.4071537819799777,recall:0.1967741935483869,f1:0.11366293623699442,pre:0.08021615452354469
epoch 2 : weight has update
Mot epoch 3 | train loss:1.3689268827438354,test loss:1.605562448501587,acc:0.23556990406006675,recall:0.19782999235044144,f1:0.07882244831131079,pre:0.1309090140773038
Mot epoch 4 | train loss:1.3550820350646973,test loss:1.631847858428955,acc:0.2533631117908787,recall:0.2174205088057371,f1:0.11710349856364816,pre:0.20011854228843207
Mot epoch 5 | train loss:1.3581689596176147,test loss:1.5417150259017944,acc:0.2560136262513904,recall:0.20393776300741445,f1:0.10401389070994525,pre:0.14171438668401232
Mot epoch 6 | train loss:1.3536869287490845,test loss:1.5048754215240479,acc:0.270830436596218,recall:0.21569788977700458,f1:0.1267553976034507,pre:0.2404505487548123
epoch 6 : weight has update
Mot epoch 7 | train loss:1.3577604293823242,test loss:1.509155511856079,acc:0.33915722330367076,recall:0.2352533013542424,f1:0.17978853401933192,pre:0.26842102288431824
epoch 7 : weight has update
Mot epoch 8 | train loss:1.3448731899261475,test loss:1.3610340356826782,acc:0.3633768423248054,recall:0.2546338440250505,f1:0.23908174542503854,pre:0.2474976606801163
epoch 8 : weight has update
Mot epoch 9 | train loss:1.3206429481506348,test loss:1.3054232597351074,acc:0.4262765920467186,recall:0.22489477802808897,f1:0.18554629802370928,pre:0.27962160609977205
epoch 9 : weight has update
Mot epoch 10 | train loss:1.3023148775100708,test loss:1.324426293373108,acc:0.4336676167964405,recall:0.23661082874039838,f1:0.19325437336422643,pre:0.17801244839273506
Mot epoch 11 | train loss:1.3065663576126099,test loss:1.580925464630127,acc:0.23310188403781978,recall:0.19802916154759054,f1:0.07643537030427053,pre:0.08988696280453239
Mot epoch 12 | train loss:1.2908132076263428,test loss:1.262660026550293,acc:0.45150862068965514,recall:0.260022010093986,f1:0.24460520261554006,pre:0.284631610138996
epoch 12 : weight has update
Mot epoch 13 | train loss:1.284991979598999,test loss:1.7896695137023926,acc:0.23227196885428256,recall:0.19676513968958775,f1:0.07462693286469296,pre:0.06781892090691051
Mot epoch 14 | train loss:1.292892336845398,test loss:2.1867380142211914,acc:0.2337840656284761,recall:0.19567713515693672,f1:0.07641664296248103,pre:0.07771998620467713
Mot epoch 15 | train loss:1.282413363456726,test loss:1.4772223234176636,acc:0.4413019674638487,recall:0.23158716670543641,f1:0.18523538298861988,pre:0.1972143881295939
Mot epoch 16 | train loss:1.2730962038040161,test loss:1.2810341119766235,acc:0.4420319452169077,recall:0.2449052316761228,f1:0.21572182916834548,pre:0.2623708368425029
Mot epoch 17 | train loss:1.2828795909881592,test loss:1.8692561388015747,acc:0.23501807563959956,recall:0.19805753995646544,f1:0.07892598097463396,pre:0.12694402512007147
Mot epoch 18 | train loss:1.2680646181106567,test loss:1.5766751766204834,acc:0.37597764877641826,recall:0.24679555861647773,f1:0.17588559841691093,pre:0.1536851209207961
Mot epoch 19 | train loss:1.267333745956421,test loss:1.526870608329773,acc:0.28199735817575083,recall:0.23021584467570394,f1:0.14166073115462943,pre:0.2708457168743846
Mot epoch 20 | train loss:1.2608416080474854,test loss:1.2570936679840088,acc:0.4520865197441602,recall:0.25366138226200274,f1:0.23372681654927074,pre:0.28887559816661496
Mot epoch 21 | train loss:1.2587801218032837,test loss:1.7017358541488647,acc:0.24126633759733035,recall:0.20524962541541011,f1:0.08953300442555304,pre:0.2057715119343298
Mot epoch 22 | train loss:1.255258560180664,test loss:1.3822860717773438,acc:0.445890399054505,recall:0.2432667628194761,f1:0.1998739651254029,pre:0.1941431892287176
Mot epoch 23 | train loss:1.2497791051864624,test loss:1.5495352745056152,acc:0.2968923804226919,recall:0.23264071953209012,f1:0.151902332525449,pre:0.2874043410015085
Mot epoch 24 | train loss:1.2459912300109863,test loss:2.0269556045532227,acc:0.2351962249721913,recall:0.1981833676967341,f1:0.07820154567334152,pre:0.13004310903398855
Mot epoch 25 | train loss:1.2497156858444214,test loss:1.3070842027664185,acc:0.4194287055061179,recall:0.2855983850031462,f1:0.2599627389721847,pre:0.2691072001391723
Mot epoch 26 | train loss:1.2380650043487549,test loss:1.2494823932647705,acc:0.44755022942157957,recall:0.2416262358533989,f1:0.21024989188666676,pre:0.30872354858621687
Mot epoch 27 | train loss:1.241911768913269,test loss:1.2336405515670776,acc:0.4681199596774194,recall:0.274986972082024,f1:0.25259561886675813,pre:0.2745814440358675
epoch 27 : weight has update
Mot epoch 28 | train loss:1.2349752187728882,test loss:1.3149901628494263,acc:0.44668989849833146,recall:0.24141854682501737,f1:0.19443772136555737,pre:0.21422156114824226
Mot epoch 29 | train loss:1.2295457124710083,test loss:1.3381500244140625,acc:0.4497662333147942,recall:0.2471044903072662,f1:0.20293905771058934,pre:0.20579126342067325
Mot epoch 30 | train loss:1.2300069332122803,test loss:1.7307531833648682,acc:0.2622836137374861,recall:0.21700003697743137,f1:0.1172191867138759,pre:0.26620501775225763
Mot epoch 31 | train loss:1.2220618724822998,test loss:1.5085790157318115,acc:0.31729699666295885,recall:0.25948355582942945,f1:0.17750331923374812,pre:0.2728707997400632
Mot epoch 32 | train loss:1.2158849239349365,test loss:1.2223702669143677,acc:0.46948432285873193,recall:0.2848802501687007,f1:0.2684510767324976,pre:0.2705870512207284
epoch 32 : weight has update
Mot epoch 33 | train loss:1.2120996713638306,test loss:1.4360672235488892,acc:0.45357254588431595,recall:0.25838027756624576,f1:0.21175934661988716,pre:0.18988771484371003
Mot epoch 34 | train loss:1.2159433364868164,test loss:1.2402596473693848,acc:0.4546848929365962,recall:0.2953421183414385,f1:0.27687699381975056,pre:0.28566682571536084
epoch 34 : weight has update
Mot epoch 35 | train loss:1.2133216857910156,test loss:1.550972580909729,acc:0.30291904199110126,recall:0.23234956338444115,f1:0.15365764101215795,pre:0.2941604560931543
Mot epoch 36 | train loss:1.2091423273086548,test loss:1.4570163488388062,acc:0.42499478587319245,recall:0.2602432998506459,f1:0.2028893241296931,pre:0.20258753811297403
Mot epoch 37 | train loss:1.210707187652588,test loss:1.5534331798553467,acc:0.2894796301446051,recall:0.23303232040503,f1:0.14854779528026602,pre:0.2814706694244187
Mot epoch 38 | train loss:1.2043793201446533,test loss:1.3956503868103027,acc:0.43540565906562845,recall:0.2649517048189061,f1:0.20620052838669856,pre:0.17107122899702315
Mot epoch 39 | train loss:1.196873664855957,test loss:1.5175281763076782,acc:0.45786551028921024,recall:0.2638546668653955,f1:0.2161260333072363,pre:0.19045119293921428
Mot epoch 40 | train loss:1.1872429847717285,test loss:1.2872792482376099,acc:0.448058606785317,recall:0.2715807649024956,f1:0.22585395676976733,pre:0.26071288874321413
Mot epoch 41 | train loss:1.1850788593292236,test loss:1.3896819353103638,acc:0.38913028364849833,recall:0.28606678440564054,f1:0.24696119297924624,pre:0.31597871779250253
Mot epoch 42 | train loss:1.193924069404602,test loss:1.2168289422988892,acc:0.4767406493325918,recall:0.28831650439250306,f1:0.2690995085700308,pre:0.27675982339758126
Mot epoch 43 | train loss:1.1784924268722534,test loss:1.2580235004425049,acc:0.4450822093993326,recall:0.3090018164421511,f1:0.278206956653193,pre:0.2822984752078632
epoch 43 : weight has update
Mot epoch 44 | train loss:1.1782021522521973,test loss:1.700358510017395,acc:0.2890538097886541,recall:0.23037071017989988,f1:0.14690645163388436,pre:0.29196885474838835
Mot epoch 45 | train loss:1.1799471378326416,test loss:1.24186110496521,acc:0.46499582869855394,recall:0.27134723664100596,f1:0.23976864863772573,pre:0.27244545592157415
Mot epoch 46 | train loss:1.176934838294983,test loss:1.21062171459198,acc:0.4794389599555061,recall:0.29679372495546097,f1:0.2868561784060429,pre:0.3112306157741673
epoch 46 : weight has update
Mot epoch 47 | train loss:1.1671050786972046,test loss:1.5793590545654297,acc:0.30116796440489435,recall:0.23476963615192636,f1:0.15541770061486457,pre:0.28694103650614605
Mot epoch 48 | train loss:1.1695797443389893,test loss:1.262924313545227,acc:0.46322737068965514,recall:0.2600365927439676,f1:0.21604883552269627,pre:0.23324302537628208
Mot epoch 49 | train loss:1.1724797487258911,test loss:1.2069467306137085,acc:0.47771829810901,recall:0.2856892389819775,f1:0.2704417321159767,pre:0.28305470697681223
Mot epoch 50 | train loss:1.1666008234024048,test loss:1.3046633005142212,acc:0.432581340378198,recall:0.2897228546043529,f1:0.26399305576789894,pre:0.2908192620842917
Mot epoch 51 | train loss:1.1651257276535034,test loss:1.3317643404006958,acc:0.42322632786429365,recall:0.2922027008643026,f1:0.26500584533560634,pre:0.3319200680243625
Mot epoch 52 | train loss:1.1742397546768188,test loss:1.3704302310943604,acc:0.45443287680756395,recall:0.2471317492332667,f1:0.2011138532595487,pre:0.20313011699001485
Mot epoch 53 | train loss:1.1529983282089233,test loss:1.6158562898635864,acc:0.4082878545606229,recall:0.25659908637468953,f1:0.19063798348006725,pre:0.15979146612795175
Mot epoch 54 | train loss:1.159608244895935,test loss:1.3078902959823608,acc:0.4733645022246941,recall:0.27831932597903086,f1:0.24266441748462456,pre:0.2842232581898095
Mot epoch 55 | train loss:1.1532227993011475,test loss:1.2305827140808105,acc:0.4786090447719688,recall:0.31052626072122774,f1:0.299668258875745,pre:0.3348006895193427
epoch 55 : weight has update
Mot epoch 56 | train loss:1.1513323783874512,test loss:1.4061027765274048,acc:0.3835294424360401,recall:0.2892642515219876,f1:0.24766145337676035,pre:0.3260649451156429
Mot epoch 57 | train loss:1.1449023485183716,test loss:1.22458016872406,acc:0.48573501807563957,recall:0.2939990407487025,f1:0.2780824850141875,pre:0.30837044991833357
Mot epoch 58 | train loss:1.1615464687347412,test loss:1.550506591796875,acc:0.30818096496106784,recall:0.24171318400883285,f1:0.16702978164004226,pre:0.2848445428706492
Mot epoch 59 | train loss:1.1477490663528442,test loss:1.3050328493118286,acc:0.45617526418242493,recall:0.2809015230978701,f1:0.2368580205602803,pre:0.2655404649107328
Mot epoch 60 | train loss:1.140176773071289,test loss:1.2724040746688843,acc:0.4726301793659622,recall:0.27682804483291007,f1:0.24724067588884538,pre:0.26973190520354473
Mot epoch 61 | train loss:1.1378329992294312,test loss:1.8277069330215454,acc:0.2584034343715239,recall:0.21836200174492382,f1:0.11493666083252702,pre:0.29962408509252314
Mot epoch 62 | train loss:1.1408833265304565,test loss:1.435110330581665,acc:0.3766294146273637,recall:0.28996521958954136,f1:0.24947355497606943,pre:0.33620519341952027
Mot epoch 63 | train loss:1.1256498098373413,test loss:1.7099696397781372,acc:0.2934119507786429,recall:0.2432018497866876,f1:0.165689606198445,pre:0.3091462792218655
Mot epoch 64 | train loss:1.1291577816009521,test loss:1.4455589056015015,acc:0.4623018631813126,recall:0.2730039074801127,f1:0.22698806221706022,pre:0.25215839448729643
Mot epoch 65 | train loss:1.1300787925720215,test loss:1.3415236473083496,acc:0.4117161429365962,recall:0.29299782006090264,f1:0.2562484883943376,pre:0.310555679665068
Mot epoch 66 | train loss:1.1306235790252686,test loss:1.2576435804367065,acc:0.47144831062291437,recall:0.2902556044392542,f1:0.26036249897982755,pre:0.2867672027065615
Mot epoch 67 | train loss:1.1233932971954346,test loss:1.7808802127838135,acc:0.2914479630144605,recall:0.23746169964735667,f1:0.1523452446774609,pre:0.2931691507268361
Mot epoch 68 | train loss:1.130612850189209,test loss:1.202157974243164,acc:0.4867170119577308,recall:0.28509135667142016,f1:0.27403715667533574,pre:0.3314022360964543
Mot epoch 69 | train loss:1.1241403818130493,test loss:1.298929214477539,acc:0.4331331687986652,recall:0.3051078313740798,f1:0.2767950429863452,pre:0.3220379194216192
Mot epoch 70 | train loss:1.1171540021896362,test loss:1.4438472986221313,acc:0.46415722330367076,recall:0.26543762874919846,f1:0.22003209602424126,pre:0.22221917896966828
Mot epoch 71 | train loss:1.1201579570770264,test loss:1.2076640129089355,acc:0.47915652808676307,recall:0.2810815151732192,f1:0.26385184536248313,pre:0.2885416887760795
Mot epoch 72 | train loss:1.1220412254333496,test loss:1.195189356803894,acc:0.487855429644049,recall:0.30250125112203236,f1:0.29762159528543014,pre:0.3422373699821123
epoch 72 : weight has update
Mot epoch 73 | train loss:1.126164197921753,test loss:1.2834888696670532,acc:0.4796909760845384,recall:0.28398968192379964,f1:0.2516767066894777,pre:0.2840604522620282
Mot epoch 74 | train loss:1.124394416809082,test loss:1.5961512327194214,acc:0.4642137096774194,recall:0.26655061946517344,f1:0.2155349663131803,pre:0.18556856074278402
Mot epoch 75 | train loss:1.1295292377471924,test loss:1.5304673910140991,acc:0.31898724276974416,recall:0.26642832179829573,f1:0.1980696143421883,pre:0.32373265575062116
Mot epoch 76 | train loss:1.1083409786224365,test loss:1.2110135555267334,acc:0.47515034065628475,recall:0.3176527549905007,f1:0.30634850204974157,pre:0.33177790984091293
epoch 76 : weight has update
Mot epoch 77 | train loss:1.124409556388855,test loss:1.2133516073226929,acc:0.46348807703003336,recall:0.316988002238028,f1:0.2886444366453203,pre:0.27877163047895054
Mot epoch 78 | train loss:1.1152278184890747,test loss:1.2162624597549438,acc:0.47560223164627363,recall:0.2814320280691658,f1:0.2624132946122134,pre:0.3118794212566604
Mot epoch 79 | train loss:1.0997508764266968,test loss:1.566365122795105,acc:0.466581792269188,recall:0.254355562718978,f1:0.21090195397965783,pre:0.2561564944577472
Mot epoch 80 | train loss:1.1111458539962769,test loss:1.303352952003479,acc:0.46879779616240264,recall:0.2635820798456165,f1:0.22748896766653276,pre:0.2744259886260728
Mot epoch 81 | train loss:1.0927438735961914,test loss:1.8171236515045166,acc:0.4597512861512792,recall:0.2536042874835459,f1:0.20867018863438744,pre:0.19847581419097646
Mot epoch 82 | train loss:1.1111621856689453,test loss:1.4149069786071777,acc:0.468167755839822,recall:0.2684827261087878,f1:0.22745786494234999,pre:0.26769096206583065
Mot epoch 83 | train loss:1.112902045249939,test loss:1.2220627069473267,acc:0.47285612486095663,recall:0.31606490123979686,f1:0.29907168924583705,pre:0.3138452662597257
Mot epoch 84 | train loss:1.0992404222488403,test loss:1.2095998525619507,acc:0.49017571607341487,recall:0.29937085224386684,f1:0.28233201727188517,pre:0.3451908948447179
Mot epoch 85 | train loss:1.1077808141708374,test loss:1.6427326202392578,acc:0.33913115266963295,recall:0.27819159329370485,f1:0.2132753161351017,pre:0.31656028447657003
Mot epoch 86 | train loss:1.0913220643997192,test loss:1.2280913591384888,acc:0.4771925403225806,recall:0.31514126962475214,f1:0.30703032430752647,pre:0.36227721395286266
epoch 86 : weight has update
Mot epoch 87 | train loss:1.103922963142395,test loss:1.2750321626663208,acc:0.4448301932703003,recall:0.30833040392950484,f1:0.28567066826804144,pre:0.3184947864184257
Mot epoch 88 | train loss:1.103238821029663,test loss:1.294212818145752,acc:0.43503197997775306,recall:0.29573436937112446,f1:0.26796876386469,pre:0.3096932348273477
Mot epoch 89 | train loss:1.0948011875152588,test loss:1.2729378938674927,acc:0.47240423387096775,recall:0.2623822326459943,f1:0.23200793264027403,pre:0.32819913815309115
Mot epoch 90 | train loss:1.098942518234253,test loss:1.307988166809082,acc:0.4225006952169077,recall:0.3050433780601378,f1:0.2772745235053091,pre:0.3315088800464869
Mot epoch 91 | train loss:1.0993852615356445,test loss:1.4227561950683594,acc:0.3884046510011123,recall:0.30599125073013334,f1:0.2742187429967503,pre:0.373487687304164
Mot epoch 92 | train loss:1.0901525020599365,test loss:1.1912035942077637,acc:0.48288897385984425,recall:0.29545576254073,f1:0.28373989556185253,pre:0.29867532817138903
Mot epoch 93 | train loss:1.0887223482131958,test loss:1.2348603010177612,acc:0.4742161429365962,recall:0.3252287731272802,f1:0.3151593914316941,pre:0.36235862947804387
epoch 93 : weight has update
Mot epoch 94 | train loss:1.0971404314041138,test loss:1.1984422206878662,acc:0.4831192644605117,recall:0.32765935137393026,f1:0.3217480150002658,pre:0.3506651172274737
epoch 94 : weight has update
Mot epoch 95 | train loss:1.0967130661010742,test loss:1.2129491567611694,acc:0.48407084260289207,recall:0.3014698332990109,f1:0.2968077197746472,pre:0.3530080241453806
Mot epoch 96 | train loss:1.093291163444519,test loss:1.6323082447052002,acc:0.4707921996662959,recall:0.2596105114971684,f1:0.21445157394794484,pre:0.2037780161857789
Mot epoch 97 | train loss:1.0906577110290527,test loss:1.2237437963485718,acc:0.4798082939377086,recall:0.2831188151230638,f1:0.26365755631809,pre:0.3543939396683171
Mot epoch 98 | train loss:1.084187626838684,test loss:1.1950150728225708,acc:0.4855568687430478,recall:0.28754895025607513,f1:0.27854985819366324,pre:0.33483992031359605
Mot epoch 99 | train loss:1.0895582437515259,test loss:1.3103394508361816,acc:0.4776922274749722,recall:0.27804543337867,f1:0.25247166386575126,pre:0.345587412569113
Mot epoch 100 | train loss:1.0850130319595337,test loss:1.549793004989624,acc:0.3445755700778643,recall:0.2956374476516488,f1:0.24529257468415236,pre:0.3733700016319485
Mot epoch 101 | train loss:1.0901035070419312,test loss:1.2010289430618286,acc:0.47993864710789763,recall:0.29079372935862613,f1:0.26923247196273414,pre:0.2873276351606671
Mot epoch 102 | train loss:1.0933297872543335,test loss:1.1861752271652222,acc:0.4915313890433815,recall:0.2962258860066325,f1:0.2863970532974991,pre:0.3378371262841379
Mot epoch 103 | train loss:1.079970121383667,test loss:1.2020312547683716,acc:0.49117943548387094,recall:0.3048412820957667,f1:0.288958196183787,pre:0.3007904834644352
Mot epoch 104 | train loss:1.083840250968933,test loss:1.2250083684921265,acc:0.4653955784204672,recall:0.26278626188174065,f1:0.23962804935382667,pre:0.35196955591869483
Mot epoch 105 | train loss:1.0822769403457642,test loss:1.2708029747009277,acc:0.455588674916574,recall:0.3148932901778259,f1:0.2972809265860159,pre:0.354397830101628
Mot epoch 106 | train loss:1.0902425050735474,test loss:1.3947157859802246,acc:0.4614154616240267,recall:0.24518458974726431,f1:0.19949187981932254,pre:0.22106039048126963
Mot epoch 107 | train loss:1.0835245847702026,test loss:1.2084661722183228,acc:0.48470522803114574,recall:0.31267379799815964,f1:0.3019074851072605,pre:0.3389232803081112
Mot epoch 108 | train loss:1.0829797983169556,test loss:1.2199476957321167,acc:0.47801811040044495,recall:0.34565914882693755,f1:0.3418548616408524,pre:0.392169667922028
epoch 108 : weight has update
Mot epoch 109 | train loss:1.0847153663635254,test loss:1.188188910484314,acc:0.4949162263626251,recall:0.3137457095620879,f1:0.31209767500492874,pre:0.371275225092575
Mot epoch 110 | train loss:1.0816655158996582,test loss:1.365166425704956,acc:0.4123157675194661,recall:0.33587224145402833,f1:0.2832062077280848,pre:0.3119377781551715
Mot epoch 111 | train loss:1.0828948020935059,test loss:1.4616196155548096,acc:0.466586137374861,recall:0.25042392344889125,f1:0.20857936879090416,pre:0.25268446728957733
Mot epoch 112 | train loss:1.0896509885787964,test loss:1.2014254331588745,acc:0.4879032258064516,recall:0.32776929007816735,f1:0.3262690038634914,pre:0.36369951040544146
Mot epoch 113 | train loss:1.0730481147766113,test loss:1.215074062347412,acc:0.48460094549499444,recall:0.3078002824448685,f1:0.2967183859101558,pre:0.3326255509063578
Mot epoch 114 | train loss:1.0835390090942383,test loss:1.1953589916229248,acc:0.48863754866518355,recall:0.28980100405098336,f1:0.2740732750949014,pre:0.2917712472654119
Mot epoch 115 | train loss:1.0746556520462036,test loss:1.2122821807861328,acc:0.490019292269188,recall:0.30354142990655913,f1:0.2973882517246156,pre:0.34348286652035964
Mot epoch 116 | train loss:1.0791351795196533,test loss:1.2180975675582886,acc:0.4859870342046719,recall:0.28311247656680627,f1:0.26586659461999995,pre:0.288124386012955
Mot epoch 117 | train loss:1.073047399520874,test loss:1.2077001333236694,acc:0.4814681243047831,recall:0.2878796515434406,f1:0.28076760111713045,pre:0.3659152734876138
Mot epoch 118 | train loss:1.066406011581421,test loss:1.2335140705108643,acc:0.48016024749721914,recall:0.28877650402599087,f1:0.27520755814757397,pre:0.36007165808941605
Mot epoch 119 | train loss:1.0780079364776611,test loss:1.5334548950195312,acc:0.3633247010567297,recall:0.30496079851229935,f1:0.24700881683543555,pre:0.318565053358729
Mot epoch 120 | train loss:1.0737696886062622,test loss:1.2525988817214966,acc:0.4733384315906563,recall:0.3414547321408172,f1:0.33652227121461126,pre:0.37774020383510737
Mot epoch 121 | train loss:1.0557798147201538,test loss:1.4111546277999878,acc:0.473238494160178,recall:0.2659192351432053,f1:0.22817736247492718,pre:0.2921620333646198
Mot epoch 122 | train loss:1.0852091312408447,test loss:1.240917682647705,acc:0.4750243325917686,recall:0.3346799142606212,f1:0.32297952918874295,pre:0.36598818683645146
Mot epoch 123 | train loss:1.0786986351013184,test loss:1.283442497253418,acc:0.46411377224694106,recall:0.2572752459450201,f1:0.2258180567577567,pre:0.3387519174935956
Mot epoch 124 | train loss:1.0753155946731567,test loss:1.5032966136932373,acc:0.37365736234705227,recall:0.2848628237852116,f1:0.23958106312158522,pre:0.32800946319413216
Mot epoch 125 | train loss:1.0694621801376343,test loss:1.5592409372329712,acc:0.4515824874860957,recall:0.23714082696871883,f1:0.18711387398182505,pre:0.2153505226460773
Mot epoch 126 | train loss:1.0661513805389404,test loss:1.238901972770691,acc:0.4877989432703003,recall:0.2971838374106407,f1:0.28238379601638347,pre:0.3120240109662914
Mot epoch 127 | train loss:1.0660759210586548,test loss:1.364912986755371,acc:0.4759063890433815,recall:0.2730800243655358,f1:0.23687363044951665,pre:0.30189746899791414
Mot epoch 128 | train loss:1.0593820810317993,test loss:1.2729524374008179,acc:0.47103987068965514,recall:0.3403090105669208,f1:0.32366286328406507,pre:0.3657430116355483
Mot epoch 129 | train loss:1.0799778699874878,test loss:1.2090626955032349,acc:0.4768188612347052,recall:0.30425435506976484,f1:0.3014450571159248,pre:0.3500136869603273
Mot epoch 130 | train loss:1.0649497509002686,test loss:1.3951148986816406,acc:0.4661299012791991,recall:0.25209297814636233,f1:0.21409370546874656,pre:0.2936413884299347
Mot epoch 131 | train loss:1.0536514520645142,test loss:1.914332389831543,acc:0.4604551932703003,recall:0.2469332501058803,f1:0.20053060461528835,pre:0.21030372539110237
Mot epoch 132 | train loss:1.063468337059021,test loss:1.2712604999542236,acc:0.45408526835372637,recall:0.31470423595321184,f1:0.30705474748884126,pre:0.37166108293954964
Mot epoch 133 | train loss:1.060904622077942,test loss:1.3227615356445312,acc:0.43376755422691876,recall:0.31040374961934974,f1:0.28544622601194625,pre:0.3415756395873101
Mot epoch 134 | train loss:1.0554983615875244,test loss:1.2081663608551025,acc:0.4880075083426029,recall:0.30493274248815455,f1:0.302189441375591,pre:0.376223284568611
Mot epoch 135 | train loss:1.066042184829712,test loss:1.1948621273040771,acc:0.4865171370967742,recall:0.30116736966418184,f1:0.28709581407039864,pre:0.3321741656467285
Mot epoch 136 | train loss:1.0743228197097778,test loss:1.2644224166870117,acc:0.4658735400444939,recall:0.3330626700029576,f1:0.3250471036533354,pre:0.375840170110787
Mot epoch 137 | train loss:1.0626449584960938,test loss:1.224339246749878,acc:0.4848790322580645,recall:0.28685455736278215,f1:0.26532898443769565,pre:0.3239774469176563
Mot epoch 138 | train loss:1.0550651550292969,test loss:1.5620003938674927,acc:0.3749435136262514,recall:0.2865572347390316,f1:0.23152482499010313,pre:0.2957519105326128
Mot epoch 139 | train loss:1.0681174993515015,test loss:1.196974515914917,acc:0.49145752224694106,recall:0.30935209922551077,f1:0.30775379423907395,pre:0.3787372915806824
Mot epoch 140 | train loss:1.0534073114395142,test loss:1.3034276962280273,acc:0.4471548248053393,recall:0.3385771381244544,f1:0.31275852640766344,pre:0.3449858714279864
Mot epoch 141 | train loss:1.0586106777191162,test loss:1.225816011428833,acc:0.4770404616240267,recall:0.30634164806583297,f1:0.2990849399182627,pre:0.34183377550869243
Mot epoch 142 | train loss:1.063006043434143,test loss:1.249904990196228,acc:0.4686978587319243,recall:0.2715392785567554,f1:0.25676113971899595,pre:0.3295638689641047
Mot epoch 143 | train loss:1.0644134283065796,test loss:1.246071219444275,acc:0.4617196190211346,recall:0.3326858654737535,f1:0.31961987334517294,pre:0.36803029375106955
Mot epoch 144 | train loss:1.0638270378112793,test loss:1.2215213775634766,acc:0.47915652808676307,recall:0.27471876277814944,f1:0.2527697258866654,pre:0.3313356235369412
Mot epoch 145 | train loss:1.0544345378875732,test loss:1.2314155101776123,acc:0.48568722191323693,recall:0.282245830701027,f1:0.25946090852294007,pre:0.31264011681293363
Mot epoch 146 | train loss:1.0556037425994873,test loss:1.2219475507736206,acc:0.47675802975528364,recall:0.32044052763439734,f1:0.30233114299419767,pre:0.3148644062343887
Mot epoch 147 | train loss:1.0635430812835693,test loss:1.215905785560608,acc:0.4885549916573971,recall:0.3156764374373453,f1:0.3158233858524554,pre:0.36682163657130146
Mot epoch 148 | train loss:1.059285044670105,test loss:1.4738292694091797,acc:0.3900384107341491,recall:0.3087457388805593,f1:0.2651872719632363,pre:0.33913726827195867
Mot epoch 149 | train loss:1.0667929649353027,test loss:1.36614191532135,acc:0.46335337875417126,recall:0.252026174345256,f1:0.2163479488318194,pre:0.3147919427066462
Mot epoch 150 | train loss:1.0598176717758179,test loss:1.3502470254898071,acc:0.47270404616240264,recall:0.27187525147912134,f1:0.23709758486679228,pre:0.3312981530976603
training has finished used time : 3260.940216779709
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (16849, 18)
trait shape (1, 16849)
df shape (20087, 42195)
(5000, 32032) (11849, 32032)
train dataset already completed!
5000
test dataset already completed!
11849
P_FRM epoch 1 | train loss:1.0233615636825562,test loss:2.6824629306793213,acc:0.5925244421122404,recall:0.2948028673835123,f1:0.21913891783355174,pre:0.1748406966539009
epoch 1 : weight has update
P_FRM epoch 2 | train loss:0.8142813444137573,test loss:0.7968325018882751,acc:0.7005369439534542,recall:0.4374488703567321,f1:0.41562771598580034,pre:0.41295099128439244
epoch 2 : weight has update
P_FRM epoch 3 | train loss:0.7337019443511963,test loss:0.749125063419342,acc:0.7223771910443364,recall:0.4748029023215995,f1:0.435394050847392,pre:0.404644798749081
epoch 3 : weight has update
P_FRM epoch 4 | train loss:0.7115787267684937,test loss:0.6765105724334717,acc:0.7531852997495949,recall:0.5046659720963773,f1:0.46432654649466326,pre:0.43202984640962094
epoch 4 : weight has update
P_FRM epoch 5 | train loss:0.6927320957183838,test loss:0.7017078995704651,acc:0.7405039401973782,recall:0.5224445650142604,f1:0.4738213830304608,pre:0.5087357272525288
epoch 5 : weight has update
P_FRM epoch 6 | train loss:0.6736064553260803,test loss:0.6052221655845642,acc:0.7685398714832818,recall:0.5525425966775837,f1:0.5297158858126934,pre:0.5398702599314851
epoch 6 : weight has update
P_FRM epoch 7 | train loss:0.6439189314842224,test loss:0.6213204860687256,acc:0.7825066283694212,recall:0.5352522760955876,f1:0.48273943983648615,pre:0.44503148652773544
P_FRM epoch 8 | train loss:0.5964969992637634,test loss:0.5124281048774719,acc:0.8156668876123141,recall:0.5566143142902893,f1:0.5190770445861527,pre:0.5281425026232309
epoch 8 : weight has update
P_FRM epoch 9 | train loss:0.5766381025314331,test loss:0.5278003811836243,acc:0.8156876012667551,recall:0.5466439856922801,f1:0.5105788409251767,pre:0.4809046114969307
P_FRM epoch 10 | train loss:0.5728117227554321,test loss:0.5296742916107178,acc:0.8116772076152601,recall:0.5679312842386999,f1:0.5422597695490814,pre:0.5993721537882528
epoch 10 : weight has update
P_FRM epoch 11 | train loss:0.5537043213844299,test loss:0.5856776237487793,acc:0.8138187693327442,recall:0.5716106501202788,f1:0.5432101767315657,pre:0.6296663424078243
epoch 11 : weight has update
P_FRM epoch 12 | train loss:0.5605669021606445,test loss:0.49665287137031555,acc:0.8196795827809693,recall:0.5812239362388577,f1:0.5693698104881405,pre:0.6190914528434731
epoch 12 : weight has update
P_FRM epoch 13 | train loss:0.5485918521881104,test loss:0.5303789973258972,acc:0.8030235030932391,recall:0.5742171050985857,f1:0.5511665498408582,pre:0.6169354077994104
P_FRM epoch 14 | train loss:0.5524410009384155,test loss:0.5405579209327698,acc:0.8009866604065401,recall:0.5696430220396945,f1:0.5350397027597231,pre:0.6243841436431002
P_FRM epoch 15 | train loss:0.5519723296165466,test loss:0.5549336671829224,acc:0.8151835690086906,recall:0.5715056459776143,f1:0.5494825209970337,pre:0.6170309350398893
P_FRM epoch 16 | train loss:0.5441896319389343,test loss:0.5101318359375,acc:0.8188602426719694,recall:0.5888201739926039,f1:0.5828406780899588,pre:0.6252139915707602
epoch 16 : weight has update
P_FRM epoch 17 | train loss:0.5463054180145264,test loss:0.5487073063850403,acc:0.8045160369715717,recall:0.5511881591260928,f1:0.5056338458926043,pre:0.5210694536424272
P_FRM epoch 18 | train loss:0.5327752232551575,test loss:0.5628021955490112,acc:0.8128118555751952,recall:0.5429380766243951,f1:0.5143810962616515,pre:0.5228538642165916
P_FRM epoch 19 | train loss:0.5420823097229004,test loss:0.506065309047699,acc:0.8120339427750773,recall:0.5930566398386743,f1:0.5833502301559186,pre:0.6054582660510872
P_FRM epoch 20 | train loss:0.5351186394691467,test loss:0.874283492565155,acc:0.6656321347031964,recall:0.49685702148464367,f1:0.43393834371559004,pre:0.464866922986106
P_FRM epoch 21 | train loss:0.5359708666801453,test loss:0.538019061088562,acc:0.8151409909412285,recall:0.5547497626634812,f1:0.5225566941575125,pre:0.49759776102576037
P_FRM epoch 22 | train loss:0.5317872762680054,test loss:0.5361377596855164,acc:0.8166956657828841,recall:0.5435286955813043,f1:0.5106267223215781,pre:0.48425970382626404
P_FRM epoch 23 | train loss:0.5249251127243042,test loss:0.4865211844444275,acc:0.8250985049344528,recall:0.5798427184063437,f1:0.5680133769216413,pre:0.6536163657502134
epoch 23 : weight has update
P_FRM epoch 24 | train loss:0.53216552734375,test loss:0.5050170421600342,acc:0.8225357655766682,recall:0.5783994854523504,f1:0.5677338928268352,pre:0.6260180106031065
P_FRM epoch 25 | train loss:0.5355148911476135,test loss:0.5066316723823547,acc:0.8232285222418618,recall:0.5809234655151656,f1:0.5653233743259581,pre:0.6315951360683021
P_FRM epoch 26 | train loss:0.5401357412338257,test loss:0.513481855392456,acc:0.8185875128884962,recall:0.5467459459404096,f1:0.5077885343778409,pre:0.4812803105916215
P_FRM epoch 27 | train loss:0.5323599576950073,test loss:0.4973653554916382,acc:0.8266313153630874,recall:0.582316545025518,f1:0.562112658343322,pre:0.6716425730962841
epoch 27 : weight has update
P_FRM epoch 28 | train loss:0.5264631509780884,test loss:0.5155108571052551,acc:0.8221767288996907,recall:0.5870640295164212,f1:0.5772834826327025,pre:0.6381026005638408
P_FRM epoch 29 | train loss:0.5363774299621582,test loss:0.49223792552948,acc:0.8210018043894536,recall:0.5778019558961612,f1:0.5728723482673643,pre:0.6355380379731838
P_FRM epoch 30 | train loss:0.5320379734039307,test loss:0.5153573155403137,acc:0.8163400813816468,recall:0.5424579098779874,f1:0.5143722729959863,pre:0.5367983270851105
P_FRM epoch 31 | train loss:0.5285264849662781,test loss:0.5083639621734619,acc:0.8209177990131095,recall:0.588123240490602,f1:0.5756974004292332,pre:0.6327866181557984
P_FRM epoch 32 | train loss:0.5346807837486267,test loss:0.515516996383667,acc:0.8201191725585507,recall:0.5490739840573275,f1:0.5126321153795153,pre:0.4829930182855482
P_FRM epoch 33 | train loss:0.5286562442779541,test loss:0.5164550542831421,acc:0.8190696807335396,recall:0.5559881888235039,f1:0.5237151043257752,pre:0.5256553470270177
P_FRM epoch 34 | train loss:0.5187903046607971,test loss:0.4991861581802368,acc:0.8189430972897335,recall:0.5932895230812767,f1:0.5834232056960938,pre:0.6350527718855146
P_FRM epoch 35 | train loss:0.5277677178382874,test loss:0.525417685508728,acc:0.8210432316983356,recall:0.5544200470642882,f1:0.5259536078451604,pre:0.5656252969527525
P_FRM epoch 36 | train loss:0.5242074728012085,test loss:0.49001291394233704,acc:0.8229765061128296,recall:0.5851495456664582,f1:0.577030817200351,pre:0.6253482126860842
P_FRM epoch 37 | train loss:0.5307672023773193,test loss:0.4908446967601776,acc:0.8266934563264104,recall:0.5854539874292599,f1:0.5726275445791673,pre:0.6366500467677094
P_FRM epoch 38 | train loss:0.516842246055603,test loss:0.5399042367935181,acc:0.8153320168655178,recall:0.53858452944784,f1:0.5091846578066843,pre:0.5049744918705021
P_FRM epoch 39 | train loss:0.5192523002624512,test loss:0.5114141702651978,acc:0.8187946494329061,recall:0.5516063571249945,f1:0.5351760977365212,pre:0.6310007088844397
P_FRM epoch 40 | train loss:0.5195814967155457,test loss:0.5018690824508667,acc:0.8210443824569157,recall:0.5782664129245105,f1:0.5733120348252896,pre:0.6495586578796647
P_FRM epoch 41 | train loss:0.5134503245353699,test loss:0.4894647002220154,acc:0.8277440989100016,recall:0.5725196051992654,f1:0.5548104188892891,pre:0.648326490190977
P_FRM epoch 42 | train loss:0.5216382145881653,test loss:0.5226588845252991,acc:0.822428745028723,recall:0.569212531969073,f1:0.5461035343187328,pre:0.6201610597014391
P_FRM epoch 43 | train loss:0.518599808216095,test loss:0.4990074038505554,acc:0.8201398862129917,recall:0.5592835282713193,f1:0.523548264038656,pre:0.5266517618981225
P_FRM epoch 44 | train loss:0.515504777431488,test loss:0.48244163393974304,acc:0.8229960690086906,recall:0.5790520071021621,f1:0.5628398056103882,pre:0.6222082955000067
P_FRM epoch 45 | train loss:0.5120177865028381,test loss:0.548498272895813,acc:0.7946643927677124,recall:0.6040327069656144,f1:0.5895302451318921,pre:0.5935138531183063
P_FRM epoch 46 | train loss:0.5047167539596558,test loss:0.5030263066291809,acc:0.8244655877154221,recall:0.5887396068476561,f1:0.578882610915438,pre:0.6457661890056204
P_FRM epoch 47 | train loss:0.5269032716751099,test loss:0.48902443051338196,acc:0.8216105556783032,recall:0.5562993202569835,f1:0.5209182885702306,pre:0.523989268287071
P_FRM epoch 48 | train loss:0.5024510622024536,test loss:0.49494969844818115,acc:0.8226600475033142,recall:0.5685794734402817,f1:0.552893826554274,pre:0.629455255336289
P_FRM epoch 49 | train loss:0.5167368054389954,test loss:0.5056710243225098,acc:0.819428717410517,recall:0.5596887965210249,f1:0.5392494675616756,pre:0.6088772236366157
P_FRM epoch 50 | train loss:0.5118005275726318,test loss:0.4897381067276001,acc:0.8256635273972603,recall:0.5779273508391908,f1:0.5685566202304503,pre:0.6362275591120239
P_FRM epoch 51 | train loss:0.5003911852836609,test loss:0.5786715745925903,acc:0.8032548055678304,recall:0.6123991979711036,f1:0.6000263780404713,pre:0.611266507270617
P_FRM epoch 52 | train loss:0.5020603537559509,test loss:0.4897751212120056,acc:0.8242365867579909,recall:0.5852337026179665,f1:0.5664277859268063,pre:0.640326441723435
P_FRM epoch 53 | train loss:0.5074014663696289,test loss:1.0183290243148804,acc:0.6707345982471645,recall:0.38281767139453393,f1:0.36322257150319953,pre:0.47625518854098725
P_FRM epoch 54 | train loss:0.5065740942955017,test loss:0.5084156394004822,acc:0.824278014066873,recall:0.5582651922822369,f1:0.5346811854163327,pre:0.6210931431418565
P_FRM epoch 55 | train loss:0.4974457621574402,test loss:0.5545602440834045,acc:0.7992029846074533,recall:0.5936754480326895,f1:0.5755780208804036,pre:0.6068387686840293
P_FRM epoch 56 | train loss:0.5070676207542419,test loss:0.48239484429359436,acc:0.8251169170717337,recall:0.5795699578670799,f1:0.5632200991929942,pre:0.6420179764244975
P_FRM epoch 57 | train loss:0.5028124451637268,test loss:0.4934505820274353,acc:0.8245714575047872,recall:0.594204494602387,f1:0.5865152368810059,pre:0.6361851177715372
P_FRM epoch 58 | train loss:0.5053007006645203,test loss:0.5843328833580017,acc:0.785298368684637,recall:0.5922983479246982,f1:0.5732278059728558,pre:0.5848604707186531
P_FRM epoch 59 | train loss:0.5146671533584595,test loss:0.5027369856834412,acc:0.82339538223597,recall:0.5733600089473471,f1:0.5553430645520848,pre:0.625031873264029
P_FRM epoch 60 | train loss:0.5064459443092346,test loss:0.48665109276771545,acc:0.8253919483723671,recall:0.5748026601224651,f1:0.5576255198847142,pre:0.6322863685095523
P_FRM epoch 61 | train loss:0.5165792107582092,test loss:0.4931603670120239,acc:0.8253712347179261,recall:0.5821074377675848,f1:0.5742322452039605,pre:0.6382473600248044
P_FRM epoch 62 | train loss:0.49603232741355896,test loss:0.48612180352211,acc:0.8243827330976581,recall:0.5927924768151412,f1:0.5896261712295077,pre:0.63341032213761
P_FRM epoch 63 | train loss:0.4978597164154053,test loss:0.4873458743095398,acc:0.8261261323464428,recall:0.6026950669200375,f1:0.5942241465533573,pre:0.6541020430450406
epoch 63 : weight has update
P_FRM epoch 64 | train loss:0.5076168775558472,test loss:0.5319416522979736,acc:0.805774966858153,recall:0.6074711314923894,f1:0.5958640562756764,pre:0.6021730653557564
P_FRM epoch 65 | train loss:0.5016121864318848,test loss:0.49661219120025635,acc:0.8229143651495066,recall:0.5689000299699649,f1:0.5550836090192898,pre:0.6512889901202445
P_FRM epoch 66 | train loss:0.5082513093948364,test loss:0.4826606512069702,acc:0.8274495047135072,recall:0.5800935572784567,f1:0.5660359487420242,pre:0.6517979823544553
P_FRM epoch 67 | train loss:0.5020002126693726,test loss:0.4915820360183716,acc:0.8241928579319489,recall:0.5891989066192342,f1:0.5787122499778345,pre:0.6310706358849728
P_FRM epoch 68 | train loss:0.5071242451667786,test loss:0.4842194616794586,acc:0.8200788960082487,recall:0.5961859941101672,f1:0.5878467843796945,pre:0.631082415769043
P_FRM epoch 69 | train loss:0.4976527988910675,test loss:0.48562678694725037,acc:0.8262112884813669,recall:0.5750504386469601,f1:0.5583260659207605,pre:0.6457304441280008
P_FRM epoch 70 | train loss:0.49250951409339905,test loss:0.4910902678966522,acc:0.8275335100898513,recall:0.5701626459490207,f1:0.5517781183325904,pre:0.6312833658999136
P_FRM epoch 71 | train loss:0.5013427734375,test loss:0.4878920614719391,acc:0.8207290746059803,recall:0.5885568348438288,f1:0.5786912343323714,pre:0.6273997395826028
P_FRM epoch 72 | train loss:0.49617263674736023,test loss:0.5038762092590332,acc:0.8233965329945501,recall:0.5644006478506246,f1:0.5424945255615509,pre:0.6396101564305222
P_FRM epoch 73 | train loss:0.4994998276233673,test loss:0.5782459378242493,acc:0.791450324053616,recall:0.60126447143348,f1:0.5844982233284064,pre:0.58490213872012
P_FRM epoch 74 | train loss:0.49395331740379333,test loss:0.5275908708572388,acc:0.8152042826631316,recall:0.5555647494910474,f1:0.5373845304362825,pre:0.6056997311165783
P_FRM epoch 75 | train loss:0.5014957785606384,test loss:0.48969435691833496,acc:0.8267360343938724,recall:0.5839803475425586,f1:0.5738686364255028,pre:0.6382714968040768
P_FRM epoch 76 | train loss:0.49394646286964417,test loss:0.51054847240448,acc:0.8212952478273678,recall:0.5552305951951148,f1:0.528684855154939,pre:0.5880419084223496
P_FRM epoch 77 | train loss:0.49772095680236816,test loss:0.5068178772926331,acc:0.8225979065399912,recall:0.5616591505421142,f1:0.5372604281495629,pre:0.617479042586013
P_FRM epoch 78 | train loss:0.5008977651596069,test loss:0.5303470492362976,acc:0.8032973836352925,recall:0.5992360628196514,f1:0.5839953880562763,pre:0.6069339971257907
P_FRM epoch 79 | train loss:0.48753446340560913,test loss:0.5003606677055359,acc:0.8216117064368832,recall:0.5800005706781325,f1:0.5741577266439056,pre:0.6429958058742814
P_FRM epoch 80 | train loss:0.5154507756233215,test loss:0.4801074266433716,acc:0.8231019387980557,recall:0.5957879239640267,f1:0.5899988471199928,pre:0.6303786289660204
P_FRM epoch 81 | train loss:0.4868578314781189,test loss:0.5129505395889282,acc:0.8237946954632495,recall:0.5736129952029819,f1:0.5601490310520661,pre:0.6209834302634797
P_FRM epoch 82 | train loss:0.4959111511707306,test loss:0.48426613211631775,acc:0.8256623766386801,recall:0.5888581915411549,f1:0.5824638485619837,pre:0.6453368883337599
P_FRM epoch 83 | train loss:0.49363523721694946,test loss:0.5037663578987122,acc:0.8204770584769481,recall:0.6099422117638801,f1:0.6012613495547653,pre:0.6379685944686219
P_FRM epoch 84 | train loss:0.5009655356407166,test loss:0.48108944296836853,acc:0.8251825103107969,recall:0.5748257162351444,f1:0.5618391702712271,pre:0.6313427250989587
P_FRM epoch 85 | train loss:0.49403882026672363,test loss:0.5167043209075928,acc:0.817473578583002,recall:0.5625962777033396,f1:0.5499855125941273,pre:0.6529110153139253
P_FRM epoch 86 | train loss:0.4877331554889679,test loss:0.5075596570968628,acc:0.8139660664309913,recall:0.6076354660059984,f1:0.60228853331987,pre:0.6146013427069608
P_FRM epoch 87 | train loss:0.4897627830505371,test loss:0.5586279034614563,acc:0.7928392896597437,recall:0.5816665975088048,f1:0.56027634992612,pre:0.5887912178484553
P_FRM epoch 88 | train loss:0.49697548151016235,test loss:0.48074689507484436,acc:0.8271353476211519,recall:0.5778523943107869,f1:0.5648586036747019,pre:0.6440543273071859
P_FRM epoch 89 | train loss:0.4920457899570465,test loss:0.4850579500198364,acc:0.827241217410517,recall:0.5907250466593389,f1:0.5846222602482994,pre:0.6359212322494097
P_FRM epoch 90 | train loss:0.49248504638671875,test loss:0.4925495684146881,acc:0.8268614670790986,recall:0.5692202107862795,f1:0.5513868685385509,pre:0.6421448088162262
P_FRM epoch 91 | train loss:0.4892899990081787,test loss:0.6594551801681519,acc:0.7874203675062602,recall:0.5130366849406779,f1:0.4945992591543781,pre:0.4989733949249802
P_FRM epoch 92 | train loss:0.5081456899642944,test loss:0.5021378397941589,acc:0.8115943529974959,recall:0.6093843223456865,f1:0.6037591288854423,pre:0.6199820038737919
P_FRM epoch 93 | train loss:0.5077893137931824,test loss:0.5517369508743286,acc:0.7936563282515834,recall:0.6167226701818216,f1:0.6022489191681176,pre:0.6006283674367588
P_FRM epoch 94 | train loss:0.49607983231544495,test loss:0.48498156666755676,acc:0.825265364928561,recall:0.5814278726788304,f1:0.5739070191260568,pre:0.6352467145451758
P_FRM epoch 95 | train loss:0.49314817786216736,test loss:0.4852614104747772,acc:0.8220731606274857,recall:0.6075181864847603,f1:0.6017347149234142,pre:0.6256731867387327
P_FRM epoch 96 | train loss:0.5007236003875732,test loss:0.49159252643585205,acc:0.8271560612755929,recall:0.5726427042710176,f1:0.5633557184898319,pre:0.6530396043969758
P_FRM epoch 97 | train loss:0.4963529706001282,test loss:0.5598147511482239,acc:0.7960729212697011,recall:0.6147452532812046,f1:0.5995019733602883,pre:0.6024686072813066
P_FRM epoch 98 | train loss:0.49489492177963257,test loss:0.4957614541053772,acc:0.814512676756518,recall:0.6063621377856149,f1:0.5981855801397373,pre:0.6144433965642945
P_FRM epoch 99 | train loss:0.4947949945926666,test loss:0.4906527101993561,acc:0.8216519829871852,recall:0.5956035893094842,f1:0.583061060000837,pre:0.6310956040425844
P_FRM epoch 100 | train loss:0.4882318079471588,test loss:0.5054003596305847,acc:0.8207083609515393,recall:0.5815637429267349,f1:0.573527715728724,pre:0.6275018709779498
P_FRM epoch 101 | train loss:0.4903792440891266,test loss:0.6059326529502869,acc:0.8070154846074533,recall:0.539061680162096,f1:0.5118195929998917,pre:0.4962595532183944
P_FRM epoch 102 | train loss:0.49211257696151733,test loss:0.656298816204071,acc:0.778473219546325,recall:0.5047809672488744,f1:0.48949226010080454,pre:0.5093777786964383
P_FRM epoch 103 | train loss:0.4794716536998749,test loss:0.5541682243347168,acc:0.7960729212697011,recall:0.5935245054159042,f1:0.5746206980839293,pre:0.61155611478317
P_FRM epoch 104 | train loss:0.4985239505767822,test loss:0.5025715827941895,acc:0.8166553892325822,recall:0.6061266939600773,f1:0.5995988884753969,pre:0.6153634272542563
P_FRM epoch 105 | train loss:0.5035123825073242,test loss:0.49172642827033997,acc:0.8258752669759906,recall:0.5839668603383701,f1:0.574661890919525,pre:0.6323345944519995
P_FRM epoch 106 | train loss:0.4853455424308777,test loss:0.5194958448410034,acc:0.8151628553542496,recall:0.609073388659463,f1:0.602416593191545,pre:0.6149083911968415
P_FRM epoch 107 | train loss:0.49702024459838867,test loss:0.49779149889945984,acc:0.8190915451465607,recall:0.587941798817412,f1:0.577890919327681,pre:0.626257875617279
P_FRM epoch 108 | train loss:0.4945605993270874,test loss:0.5057135820388794,acc:0.8210432316983356,recall:0.5984790095153103,f1:0.5910499147604306,pre:0.6238272225679435
P_FRM epoch 109 | train loss:0.48350852727890015,test loss:0.4800097644329071,acc:0.8275542237442923,recall:0.586030672299752,f1:0.5818591391190535,pre:0.6493012302142044
P_FRM epoch 110 | train loss:0.48208296298980713,test loss:0.4933306872844696,acc:0.8203297613787008,recall:0.5713837217601745,f1:0.5497990036419266,pre:0.6176165959187299
P_FRM epoch 111 | train loss:0.49269208312034607,test loss:0.5260773301124573,acc:0.8193435612755929,recall:0.5502038453798483,f1:0.5245246186788302,pre:0.5760719721670218
P_FRM epoch 112 | train loss:0.4883058965206146,test loss:0.4859119653701782,acc:0.8250144995581088,recall:0.5943672739087388,f1:0.5886243802365502,pre:0.6297479658394184
P_FRM epoch 113 | train loss:0.48820364475250244,test loss:0.49419379234313965,acc:0.8150155582560025,recall:0.6202273863062476,f1:0.6166299098784295,pre:0.626926241342853
epoch 113 : weight has update
P_FRM epoch 114 | train loss:0.4919666349887848,test loss:0.5575317144393921,acc:0.810667992340551,recall:0.546019268415952,f1:0.5221439118253358,pre:0.5732010240001723
P_FRM epoch 115 | train loss:0.487254798412323,test loss:0.49658238887786865,acc:0.8164033731035499,recall:0.6208215944560411,f1:0.6166504852521469,pre:0.6279540200868896
epoch 115 : weight has update
P_FRM epoch 116 | train loss:0.48978424072265625,test loss:0.5638603568077087,acc:0.807749668581529,recall:0.5349025296109865,f1:0.5176236904606056,pre:0.588475299402293
P_FRM epoch 117 | train loss:0.4911192059516907,test loss:0.4834458827972412,acc:0.8248453380468406,recall:0.5792142925811964,f1:0.5698702956734251,pre:0.6460059665095655
P_FRM epoch 118 | train loss:0.4891434609889984,test loss:0.48871538043022156,acc:0.8244678892325822,recall:0.5681170926765471,f1:0.5464421400375672,pre:0.6365398652447873
P_FRM epoch 119 | train loss:0.49290505051612854,test loss:0.503051221370697,acc:0.8207083609515393,recall:0.5973513196663484,f1:0.589503153814858,pre:0.6390227547110942
P_FRM epoch 120 | train loss:0.4888129234313965,test loss:0.5879279375076294,acc:0.7801314626601855,recall:0.60299470346896,f1:0.5832377437819162,pre:0.5899380776261125
P_FRM epoch 121 | train loss:0.4946165382862091,test loss:0.4938693642616272,acc:0.8265691743997643,recall:0.5827413642700859,f1:0.5694564639864916,pre:0.6469897466559488
P_FRM epoch 122 | train loss:0.49008721113204956,test loss:0.5647908449172974,acc:0.7718367948151422,recall:0.6244012989443003,f1:0.6024725133554595,pre:0.5942039148606358
P_FRM epoch 123 | train loss:0.4915568232536316,test loss:0.49842435121536255,acc:0.8181456215937547,recall:0.5738499146268276,f1:0.5573710381155853,pre:0.6229532398858018
P_FRM epoch 124 | train loss:0.4911080300807953,test loss:0.5402940511703491,acc:0.8131467263219915,recall:0.597672467082232,f1:0.5823596306825287,pre:0.6286905335068351
P_FRM epoch 125 | train loss:0.49304646253585815,test loss:0.4877285361289978,acc:0.8244886028870232,recall:0.5703821941807264,f1:0.555409630073393,pre:0.6435800078157526
P_FRM epoch 126 | train loss:0.486163467168808,test loss:0.4918121099472046,acc:0.8215277010605392,recall:0.5683052021513836,f1:0.5528467039954541,pre:0.6394498894088313
P_FRM epoch 127 | train loss:0.4854312241077423,test loss:0.5070151686668396,acc:0.8192158270732067,recall:0.6051421665296465,f1:0.599199084573274,pre:0.6267023132387317
P_FRM epoch 128 | train loss:0.4933215379714966,test loss:0.5207744836807251,acc:0.8182503406245397,recall:0.5977598030436453,f1:0.5893175344025994,pre:0.6255087067903294
P_FRM epoch 129 | train loss:0.49941176176071167,test loss:0.5116394758224487,acc:0.8224517602003241,recall:0.5649249446955856,f1:0.5479032453715539,pre:0.6564625746367453
P_FRM epoch 130 | train loss:0.4838988184928894,test loss:0.5406492948532104,acc:0.7999567314773898,recall:0.6159299504815791,f1:0.6037048973177133,pre:0.6038082651432706
P_FRM epoch 131 | train loss:0.4947076141834259,test loss:0.5115782022476196,acc:0.8130834346000885,recall:0.6158281621509674,f1:0.6081023308040672,pre:0.6188984776809533
P_FRM epoch 132 | train loss:0.48793038725852966,test loss:0.4943019449710846,acc:0.8215702791280012,recall:0.5678286011466258,f1:0.5449072198848224,pre:0.6192317624397817
P_FRM epoch 133 | train loss:0.5032914876937866,test loss:0.5122342109680176,acc:0.8168855409485933,recall:0.5973384305182045,f1:0.5871719740432886,pre:0.6178225665732243
P_FRM epoch 134 | train loss:0.4895659387111664,test loss:0.49467241764068604,acc:0.824319441375755,recall:0.5762752684284267,f1:0.5562864169723085,pre:0.656645775175279
P_FRM epoch 135 | train loss:0.49339208006858826,test loss:0.7430166602134705,acc:0.7351252945941964,recall:0.5623730113592386,f1:0.5312242560143335,pre:0.5624538913308189
P_FRM epoch 136 | train loss:0.4855857789516449,test loss:0.6255049705505371,acc:0.7551197249226691,recall:0.5992027747271322,f1:0.5742924171348843,pre:0.5695660548122885
P_FRM epoch 137 | train loss:0.48757973313331604,test loss:0.5664448142051697,acc:0.8146806875092061,recall:0.5390688322929879,f1:0.5076423918327532,pre:0.4826333463112812
P_FRM epoch 138 | train loss:0.49575215578079224,test loss:0.5471363663673401,acc:0.8157094656797762,recall:0.5468600528180285,f1:0.5272496195460017,pre:0.6131358985290764
P_FRM epoch 139 | train loss:0.49213409423828125,test loss:0.48477423191070557,acc:0.8247394682574753,recall:0.5882479970588188,f1:0.5822809514439438,pre:0.6475155559929694
P_FRM epoch 140 | train loss:0.49024534225463867,test loss:0.557599663734436,acc:0.8071823446015615,recall:0.5529123178515077,f1:0.5485928490528328,pre:0.6556951518727883
P_FRM epoch 141 | train loss:0.48172324895858765,test loss:0.5583174228668213,acc:0.8136311956841951,recall:0.541345750462418,f1:0.5242503140512613,pre:0.6282319416082031
P_FRM epoch 142 | train loss:0.49143850803375244,test loss:0.48136088252067566,acc:0.8248660517012816,recall:0.5663502408739005,f1:0.5480016525326681,pre:0.6408820754775195
P_FRM epoch 143 | train loss:0.4793241024017334,test loss:0.485407292842865,acc:0.8221571660038298,recall:0.5894263825582073,f1:0.5840675658630377,pre:0.625931190116236
P_FRM epoch 144 | train loss:0.49059203267097473,test loss:0.4901716113090515,acc:0.8247187546030343,recall:0.5982488027098669,f1:0.598667960931269,pre:0.6422421092051485
P_FRM epoch 145 | train loss:0.4950862228870392,test loss:0.497223436832428,acc:0.8218614210487554,recall:0.5990006825337794,f1:0.5949333456332648,pre:0.6503541421066509
P_FRM epoch 146 | train loss:0.48536351323127747,test loss:0.48109519481658936,acc:0.8279535369715717,recall:0.5898834337560239,f1:0.5814054781627006,pre:0.6457418400378304
P_FRM epoch 147 | train loss:0.48342010378837585,test loss:0.49198117852211,acc:0.8228280582560025,recall:0.5679805495453336,f1:0.5524089999167863,pre:0.6492724351984948
P_FRM epoch 148 | train loss:0.479142427444458,test loss:0.4935334324836731,acc:0.8225760421269702,recall:0.5866201551203587,f1:0.5816878747001395,pre:0.6273622508621678
P_FRM epoch 149 | train loss:0.473353773355484,test loss:0.5012882947921753,acc:0.819427566651937,recall:0.5974411200432098,f1:0.5845256157551154,pre:0.622198927674345
P_FRM epoch 150 | train loss:0.49926406145095825,test loss:0.5304797887802124,acc:0.8199085837384005,recall:0.5706709872231407,f1:0.5660450992817238,pre:0.642850936054407
training has finished used time : 4058.1601848602295
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (16780, 18)
trait shape (1, 16780)
df shape (20087, 42195)
(5000, 32032) (11780, 32032)
train dataset already completed!
5000
test dataset already completed!
11780
P_DENS epoch 1 | train loss:0.7399612665176392,test loss:1.9880497455596924,acc:0.6491935483870968,recall:0.5053763440860215,f1:0.3984613916278562,pre:0.3299731182795699
epoch 1 : weight has update
P_DENS epoch 2 | train loss:0.5703733563423157,test loss:1.3015538454055786,acc:0.6465893817204301,recall:0.5,f1:0.39226636017603,pre:0.32329469086021506
P_DENS epoch 3 | train loss:0.5244349241256714,test loss:0.5072929263114929,acc:0.7731854838709677,recall:0.6976966215352434,f1:0.7091070106318702,pre:0.7914916193467357
epoch 3 : weight has update
P_DENS epoch 4 | train loss:0.4785672724246979,test loss:0.7178888916969299,acc:0.7848622311827957,recall:0.7132921169728734,f1:0.7257625323614081,pre:0.8245508229275924
epoch 4 : weight has update
P_DENS epoch 5 | train loss:0.4651835560798645,test loss:1.0315353870391846,acc:0.6465893817204301,recall:0.5,f1:0.39214511725797024,pre:0.32329469086021506
P_DENS epoch 6 | train loss:0.4552914500236511,test loss:0.555884063243866,acc:0.6492775537634409,recall:0.5105111066295709,f1:0.42250367262201133,pre:0.6980772942082224
P_DENS epoch 7 | train loss:0.42429107427597046,test loss:0.7973299622535706,acc:0.6490255376344086,recall:0.5072997016776127,f1:0.4066454926683692,pre:0.5602200792582162
P_DENS epoch 8 | train loss:0.42801812291145325,test loss:0.38913553953170776,acc:0.8474462365591398,recall:0.8215600066011176,f1:0.8274249366365423,pre:0.8395530151634623
epoch 8 : weight has update
P_DENS epoch 9 | train loss:0.4145764112472534,test loss:0.3936016857624054,acc:0.8408938172043011,recall:0.8072886507501494,f1:0.8170453326586299,pre:0.8401496943717055
P_DENS epoch 10 | train loss:0.4043358564376831,test loss:0.38988611102104187,acc:0.8450940860215054,recall:0.82159514721577,f1:0.8260284515378825,pre:0.8348517165563959
P_DENS epoch 11 | train loss:0.40036487579345703,test loss:0.37462493777275085,acc:0.8412298387096774,recall:0.8211162581652186,f1:0.823351935279377,pre:0.8287089421621615
P_DENS epoch 12 | train loss:0.39351409673690796,test loss:0.37820136547088623,acc:0.8377016129032258,recall:0.818529116687616,f1:0.8183170545101757,pre:0.8209298481430786
P_DENS epoch 13 | train loss:0.3908787667751312,test loss:0.5219628810882568,acc:0.816448252688172,recall:0.8236564052787424,f1:0.8061503857897214,pre:0.8021675826164804
P_DENS epoch 14 | train loss:0.3960318863391876,test loss:0.4008753299713135,acc:0.8276209677419355,recall:0.8026178259875271,f1:0.8063335680389908,pre:0.8142629017091333
P_DENS epoch 15 | train loss:0.396061509847641,test loss:0.49194392561912537,acc:0.8365255376344086,recall:0.8381736128922426,f1:0.8253802987535269,pre:0.8203847830416144
P_DENS epoch 16 | train loss:0.3955228924751282,test loss:0.451930969953537,acc:0.8262768817204301,recall:0.8338789190996433,f1:0.815774435378585,pre:0.8112141527214741
P_DENS epoch 17 | train loss:0.3982084095478058,test loss:0.5021246075630188,acc:0.7596606182795699,recall:0.6721082296875855,f1:0.6788923555165197,pre:0.8226575614006529
P_DENS epoch 18 | train loss:0.3957553505897522,test loss:0.37674036622047424,acc:0.8439180107526881,recall:0.829380975205279,f1:0.8283818476588526,pre:0.829733130355298
P_DENS epoch 19 | train loss:0.397691547870636,test loss:0.38734981417655945,acc:0.8356854838709677,recall:0.8359781748513231,f1:0.8239561405768385,pre:0.8195806122805108
P_DENS epoch 20 | train loss:0.3901576101779938,test loss:0.4421784281730652,acc:0.8143481182795699,recall:0.8216942712256399,f1:0.8035704261836462,pre:0.7997477797848096
P_DENS epoch 21 | train loss:0.39446553587913513,test loss:0.4793902039527893,acc:0.8156922043010753,recall:0.8299033906110573,f1:0.8068617914017595,pre:0.8054896784779337
P_DENS epoch 22 | train loss:0.398088663816452,test loss:0.38565412163734436,acc:0.8424059139784946,recall:0.8069031453669409,f1:0.8176560270700882,pre:0.8427122180974483
P_DENS epoch 23 | train loss:0.39292067289352417,test loss:0.3724602460861206,acc:0.8404737903225806,recall:0.8158666446738864,f1:0.8207301000777667,pre:0.8320674685254794
P_DENS epoch 24 | train loss:0.3846222460269928,test loss:0.4289799630641937,acc:0.8184643817204301,recall:0.7600142845828528,f1:0.7756046093521203,pre:0.8315789430661514
P_DENS epoch 25 | train loss:0.3918049931526184,test loss:0.3739005923271179,acc:0.8430779569892473,recall:0.8349231353871615,f1:0.8294794274960673,pre:0.8272609931052302
P_DENS epoch 26 | train loss:0.38800248503685,test loss:0.42210325598716736,acc:0.8225806451612904,recall:0.7693672507303807,f1:0.7856766571757077,pre:0.8392534329623844
P_DENS epoch 27 | train loss:0.39093396067619324,test loss:0.4291810095310211,acc:0.8275369623655914,recall:0.7787201550112127,f1:0.7945593731925998,pre:0.8413657837002169
P_DENS epoch 28 | train loss:0.38730114698410034,test loss:0.36776459217071533,acc:0.848622311827957,recall:0.8394893534720836,f1:0.8347943091119925,pre:0.8331359455860556
epoch 28 : weight has update
P_DENS epoch 29 | train loss:0.39036446809768677,test loss:0.3725721836090088,acc:0.8403897849462365,recall:0.828244629025675,f1:0.8250115292826531,pre:0.8254058583510608
P_DENS epoch 30 | train loss:0.38448888063430786,test loss:0.38315102458000183,acc:0.8419858870967742,recall:0.8232102889532164,f1:0.8242607284894445,pre:0.8298605083315127
P_DENS epoch 31 | train loss:0.3874562680721283,test loss:0.38057926297187805,acc:0.8442540322580645,recall:0.8137471522031201,f1:0.8220560792254121,pre:0.8396015429265561
P_DENS epoch 32 | train loss:0.3830907940864563,test loss:0.36992722749710083,acc:0.8461021505376344,recall:0.8262036103652626,f1:0.8271402272334253,pre:0.8306177876083126
P_DENS epoch 33 | train loss:0.3770085871219635,test loss:0.38901975750923157,acc:0.8402217741935484,recall:0.8079180763766471,f1:0.8171698656578068,pre:0.8349789748618159
P_DENS epoch 34 | train loss:0.373140424489975,test loss:0.3970774710178375,acc:0.8303931451612904,recall:0.7890203444283195,f1:0.8012607385548869,pre:0.8318501324489821
P_DENS epoch 35 | train loss:0.38498857617378235,test loss:0.36805835366249084,acc:0.8449260752688172,recall:0.83882221676537,f1:0.8323085361813474,pre:0.8290954973732972
P_DENS epoch 36 | train loss:0.3797937035560608,test loss:0.38753989338874817,acc:0.8371975806451613,recall:0.8094326385483328,f1:0.8159066698809816,pre:0.8299725091853206
P_DENS epoch 37 | train loss:0.37835368514060974,test loss:0.3941200375556946,acc:0.838877688172043,recall:0.8029552963060861,f1:0.8136696444780811,pre:0.8400490946846353
P_DENS epoch 38 | train loss:0.37983012199401855,test loss:0.3713270127773285,acc:0.8421538978494624,recall:0.8270031310813518,f1:0.8258807480710113,pre:0.8275032621832107
P_DENS epoch 39 | train loss:0.38135960698127747,test loss:0.37249791622161865,acc:0.8455141129032258,recall:0.8271493136542106,f1:0.828715646036431,pre:0.8325329968285786
P_DENS epoch 40 | train loss:0.37303921580314636,test loss:0.3980225622653961,acc:0.8396337365591398,recall:0.8071922752766276,f1:0.8163513460583887,pre:0.8369517113617171
P_DENS epoch 41 | train loss:0.3769167959690094,test loss:0.3695853054523468,acc:0.84375,recall:0.8244914323465569,f1:0.8247391069022252,pre:0.8274493811134711
P_DENS epoch 42 | train loss:0.3767017424106598,test loss:0.42928609251976013,acc:0.8269489247311828,recall:0.7828871523201051,f1:0.796611100923008,pre:0.8341899671144046
P_DENS epoch 43 | train loss:0.3735264539718628,test loss:0.37230226397514343,acc:0.8417338709677419,recall:0.8154316424255054,f1:0.8188498061550743,pre:0.8273565691853025
P_DENS epoch 44 | train loss:0.37025225162506104,test loss:0.41431644558906555,acc:0.8370295698924731,recall:0.7944124722664415,f1:0.8062571671575058,pre:0.8364893499318466
P_DENS epoch 45 | train loss:0.37586545944213867,test loss:0.44988319277763367,acc:0.8303931451612904,recall:0.7795568089091407,f1:0.7942325308517115,pre:0.8385801654333673
P_DENS epoch 46 | train loss:0.3807748854160309,test loss:0.38878464698791504,acc:0.8293850806451613,recall:0.8344421152630628,f1:0.8189253773810665,pre:0.8144028300340402
P_DENS epoch 47 | train loss:0.3774842917919159,test loss:0.38763439655303955,acc:0.8440020161290323,recall:0.8143249953507865,f1:0.8220575642659914,pre:0.8399935026332649
P_DENS epoch 48 | train loss:0.3801965117454529,test loss:0.3625730276107788,acc:0.84375,recall:0.8332876422070434,f1:0.8294894771360913,pre:0.828404399773239
P_DENS epoch 49 | train loss:0.37074166536331177,test loss:0.3694247603416443,acc:0.8429939516129032,recall:0.8285100899826209,f1:0.8274201076613426,pre:0.8283166582798538
P_DENS epoch 50 | train loss:0.3671405017375946,test loss:0.36879581212997437,acc:0.8426579301075269,recall:0.8316711683519499,f1:0.8278573095318591,pre:0.8270935655461178
P_DENS epoch 51 | train loss:0.373431921005249,test loss:0.37262439727783203,acc:0.8402217741935484,recall:0.8210320873763014,f1:0.8203985642536753,pre:0.8223616518163368
P_DENS epoch 52 | train loss:0.37483543157577515,test loss:0.3788549304008484,acc:0.8395497311827957,recall:0.8300701662687168,f1:0.8233407760725517,pre:0.8207409186185991
P_DENS epoch 53 | train loss:0.3724394738674164,test loss:0.3694288730621338,acc:0.8484543010752689,recall:0.8168347947231862,f1:0.8263691601388318,pre:0.8453345864010404
P_DENS epoch 54 | train loss:0.3660873770713806,test loss:0.39021337032318115,acc:0.839801747311828,recall:0.8067628819129682,f1:0.8143807596117142,pre:0.830977953754929
P_DENS epoch 55 | train loss:0.3653404712677002,test loss:0.36894160509109497,acc:0.8382056451612904,recall:0.8368677796817507,f1:0.8262992658311119,pre:0.8225902398781658
P_DENS epoch 56 | train loss:0.3653581738471985,test loss:0.3837517499923706,acc:0.8451780913978495,recall:0.8218188273084417,f1:0.826414047492763,pre:0.8359578674530016
P_DENS epoch 57 | train loss:0.3726530969142914,test loss:0.3682347238063812,acc:0.8448420698924731,recall:0.8273290172180104,f1:0.8282198849702017,pre:0.8326086473691203
P_DENS epoch 58 | train loss:0.3536125719547272,test loss:0.4037696123123169,acc:0.8440020161290323,recall:0.8099033960704709,f1:0.8203960571908051,pre:0.8419329915067266
P_DENS epoch 59 | train loss:0.3625521659851074,test loss:0.38399508595466614,acc:0.846690188172043,recall:0.8210947614543639,f1:0.8267210901907942,pre:0.8390268240540711
P_DENS epoch 60 | train loss:0.36117491126060486,test loss:0.376468688249588,acc:0.8414818548387096,recall:0.8258304857423899,f1:0.8254537735396208,pre:0.8275908481392271
P_DENS epoch 61 | train loss:0.36572158336639404,test loss:0.36768049001693726,acc:0.8500504032258065,recall:0.8324984420327164,f1:0.8340841517434635,pre:0.8377394374134699
P_DENS epoch 62 | train loss:0.35955196619033813,test loss:0.37804946303367615,acc:0.8470262096774194,recall:0.8158349130199646,f1:0.8252353300388926,pre:0.8424943202850734
P_DENS epoch 63 | train loss:0.36313411593437195,test loss:0.38054370880126953,acc:0.8431619623655914,recall:0.8239941001378014,f1:0.825370965474158,pre:0.8334453725245375
P_DENS epoch 64 | train loss:0.36055850982666016,test loss:0.37220555543899536,acc:0.8424899193548387,recall:0.8343296723694615,f1:0.8290376052357037,pre:0.8266969776632167
P_DENS epoch 65 | train loss:0.3520568907260895,test loss:0.3810599446296692,acc:0.8471942204301075,recall:0.8208075699675355,f1:0.8271523316820931,pre:0.8395529642725829
P_DENS epoch 66 | train loss:0.3647163510322571,test loss:0.3740912675857544,acc:0.8450100806451613,recall:0.8195160081896457,f1:0.8252591163577729,pre:0.8382109677964817
P_DENS epoch 67 | train loss:0.365962952375412,test loss:0.39388909935951233,acc:0.8458501344086021,recall:0.8188039894214004,f1:0.8255919962019648,pre:0.8387782222667624
P_DENS epoch 68 | train loss:0.3610329031944275,test loss:0.403292179107666,acc:0.8210685483870968,recall:0.8301642856236712,f1:0.8094851499390804,pre:0.8070408540807091
P_DENS epoch 69 | train loss:0.3569454848766327,test loss:0.39387863874435425,acc:0.8441700268817204,recall:0.8168845889073878,f1:0.8234569341751637,pre:0.8375635501194727
P_DENS epoch 70 | train loss:0.36170169711112976,test loss:0.37658941745758057,acc:0.8465221774193549,recall:0.8269770452625466,f1:0.828662371154053,pre:0.8354723727919975
P_DENS epoch 71 | train loss:0.3484315276145935,test loss:0.379852294921875,acc:0.8442540322580645,recall:0.8226419481993493,f1:0.8257692140519468,pre:0.8325448739104413
P_DENS epoch 72 | train loss:0.35441556572914124,test loss:0.38350406289100647,acc:0.8415658602150538,recall:0.8298491507243353,f1:0.8265667939996402,pre:0.8272809951451767
P_DENS epoch 73 | train loss:0.3523954749107361,test loss:0.37779366970062256,acc:0.8399697580645161,recall:0.82160420917613,f1:0.8228586285491709,pre:0.8267499662934409
P_DENS epoch 74 | train loss:0.356899619102478,test loss:0.37744444608688354,acc:0.8423219086021505,recall:0.8384760966725399,f1:0.8299735663457047,pre:0.8262003099494268
P_DENS epoch 75 | train loss:0.36870288848876953,test loss:0.36778485774993896,acc:0.8436659946236559,recall:0.8212763290333304,f1:0.8227432231188009,pre:0.828358364063259
P_DENS epoch 76 | train loss:0.35950952768325806,test loss:0.3650895357131958,acc:0.8466061827956989,recall:0.8300258038515594,f1:0.8306300742227051,pre:0.8356295799710947
P_DENS epoch 77 | train loss:0.3628290295600891,test loss:0.37217602133750916,acc:0.8452620967741935,recall:0.8220547545116985,f1:0.8259617738671209,pre:0.8362272251927078
P_DENS epoch 78 | train loss:0.35866186022758484,test loss:0.36950749158859253,acc:0.845682123655914,recall:0.8195658918614793,f1:0.825610789067319,pre:0.8385474348000501
P_DENS epoch 79 | train loss:0.37552499771118164,test loss:0.36553308367729187,acc:0.8434139784946236,recall:0.8315784925740836,f1:0.8276584764243349,pre:0.8260125795773774
P_DENS epoch 80 | train loss:0.35633641481399536,test loss:0.36707553267478943,acc:0.8498823924731183,recall:0.8263161339226782,f1:0.8310163839726166,pre:0.8405327978620927
P_DENS epoch 81 | train loss:0.3527110517024994,test loss:0.37126556038856506,acc:0.8415658602150538,recall:0.8289116668619697,f1:0.8259967248982828,pre:0.828313877258703
P_DENS epoch 82 | train loss:0.3562973737716675,test loss:0.3713580369949341,acc:0.842825940860215,recall:0.8244992137917039,f1:0.823534002353237,pre:0.8249488348921669
P_DENS epoch 83 | train loss:0.356508731842041,test loss:0.3756413757801056,acc:0.8392137096774194,recall:0.8305782055065266,f1:0.8254203234728879,pre:0.8242012846075617
P_DENS epoch 84 | train loss:0.3557004928588867,test loss:0.3695424497127533,acc:0.8451780913978495,recall:0.8431722465248552,f1:0.8335421118191475,pre:0.8294536080798482
P_DENS epoch 85 | train loss:0.35289281606674194,test loss:0.39668455719947815,acc:0.8348454301075269,recall:0.8330387608744231,f1:0.8226568012983088,pre:0.8195223727750642
P_DENS epoch 86 | train loss:0.36304086446762085,test loss:0.37983202934265137,acc:0.8433299731182796,recall:0.8102758346188451,f1:0.8200137247998047,pre:0.8409688233680546
P_DENS epoch 87 | train loss:0.35300496220588684,test loss:0.36499547958374023,acc:0.8459341397849462,recall:0.8326159082563371,f1:0.8308596593983343,pre:0.831336622712485
P_DENS epoch 88 | train loss:0.3599868714809418,test loss:0.3835917115211487,acc:0.8465221774193549,recall:0.8133726289859375,f1:0.8235502128457338,pre:0.8442696448725624
P_DENS epoch 89 | train loss:0.35255947709083557,test loss:0.3745069205760956,acc:0.8429939516129032,recall:0.8149619459611889,f1:0.8198471659954042,pre:0.8315723239269445
P_DENS epoch 90 | train loss:0.3526153862476349,test loss:0.3764789402484894,acc:0.8377016129032258,recall:0.821393606695409,f1:0.8201654773540797,pre:0.8218273059478393
P_DENS epoch 91 | train loss:0.3473113477230072,test loss:0.3607074022293091,acc:0.8479502688172043,recall:0.8311009109534188,f1:0.8314785218262548,pre:0.835694208767711
P_DENS epoch 92 | train loss:0.3508639335632324,test loss:0.3814385235309601,acc:0.8455981182795699,recall:0.8242043148273578,f1:0.8249013988971479,pre:0.8285651050109145
P_DENS epoch 93 | train loss:0.3557208776473999,test loss:0.370005339384079,acc:0.8413138440860215,recall:0.8382307435390992,f1:0.8289544412454147,pre:0.827756430042634
P_DENS epoch 94 | train loss:0.35288116335868835,test loss:0.3704894781112671,acc:0.844674059139785,recall:0.8269869615023144,f1:0.8278186831120211,pre:0.8351167682738403
P_DENS epoch 95 | train loss:0.35007616877555847,test loss:0.4097759425640106,acc:0.8331653225806451,recall:0.8406350113532841,f1:0.8238348362219604,pre:0.8189083277059747
P_DENS epoch 96 | train loss:0.3522624671459198,test loss:0.3669036626815796,acc:0.8383736559139785,recall:0.8321042213411712,f1:0.8252265009641786,pre:0.8237670133691376
P_DENS epoch 97 | train loss:0.35081273317337036,test loss:0.38168856501579285,acc:0.8450940860215054,recall:0.8346305864993581,f1:0.8308586505437053,pre:0.8297914291403045
P_DENS epoch 98 | train loss:0.35195791721343994,test loss:0.415982186794281,acc:0.8287970430107527,recall:0.8325277154588129,f1:0.8156200666424338,pre:0.8111110874204582
P_DENS epoch 99 | train loss:0.34349358081817627,test loss:0.36830782890319824,acc:0.8444220430107527,recall:0.8348270740014146,f1:0.8304785238281429,pre:0.8291558820000915
P_DENS epoch 100 | train loss:0.3609951138496399,test loss:0.42645326256752014,acc:0.8315692204301075,recall:0.8394459754112985,f1:0.8221241824368203,pre:0.8177684217260797
P_DENS epoch 101 | train loss:0.3514246344566345,test loss:0.38683852553367615,acc:0.8502184139784946,recall:0.8213497546673735,f1:0.829407057953327,pre:0.8445539301394424
P_DENS epoch 102 | train loss:0.34498125314712524,test loss:0.3717460334300995,acc:0.8463541666666666,recall:0.8333053591334343,f1:0.8312279206072192,pre:0.8315342487262274
P_DENS epoch 103 | train loss:0.3533085584640503,test loss:0.3714458644390106,acc:0.8440020161290323,recall:0.8078650309485946,f1:0.8192618605832523,pre:0.8439471233935146
P_DENS epoch 104 | train loss:0.3518941104412079,test loss:0.42384326457977295,acc:0.8327452956989247,recall:0.8371128683532206,f1:0.8219535663826151,pre:0.8167909964237899
P_DENS epoch 105 | train loss:0.3531363010406494,test loss:0.3611389100551605,acc:0.8459341397849462,recall:0.833130178710068,f1:0.8311599412167022,pre:0.8315608846696376
P_DENS epoch 106 | train loss:0.34824126958847046,test loss:0.44465410709381104,acc:0.8203125,recall:0.8363729859750452,f1:0.812834303982289,pre:0.8107394033842034
P_DENS epoch 107 | train loss:0.34925949573516846,test loss:0.40440642833709717,acc:0.8328293010752689,recall:0.7871666411056559,f1:0.8002602005270262,pre:0.8340785696513207
P_DENS epoch 108 | train loss:0.3479236662387848,test loss:0.3722243309020996,acc:0.8472782258064516,recall:0.8430440254460433,f1:0.8347978837536496,pre:0.8309386202724118
epoch 108 : weight has update
P_DENS epoch 109 | train loss:0.34305158257484436,test loss:0.38334786891937256,acc:0.8421538978494624,recall:0.8370547336831303,f1:0.829309484252354,pre:0.8261333067018792
P_DENS epoch 110 | train loss:0.34431031346321106,test loss:0.379427433013916,acc:0.8413978494623656,recall:0.8176980003493387,f1:0.8212188754123604,pre:0.8329584232295475
P_DENS epoch 111 | train loss:0.340389221906662,test loss:0.37819433212280273,acc:0.8422379032258065,recall:0.8398846188712784,f1:0.830413155951775,pre:0.8260536950140289
P_DENS epoch 112 | train loss:0.34235531091690063,test loss:0.3669681251049042,acc:0.8431619623655914,recall:0.8359878143849849,f1:0.8297737657618159,pre:0.8274550809734197
P_DENS epoch 113 | train loss:0.3382497727870941,test loss:0.3920411169528961,acc:0.8492943548387096,recall:0.8221313421430855,f1:0.829234318194502,pre:0.8433290858494622
P_DENS epoch 114 | train loss:0.3443835377693176,test loss:0.3767250180244446,acc:0.8434139784946236,recall:0.8112972735353504,f1:0.8191896313537416,pre:0.8337059811659725
P_DENS epoch 115 | train loss:0.33811917901039124,test loss:0.3676656484603882,acc:0.8463541666666666,recall:0.8274044567186801,f1:0.8293812371993583,pre:0.8338832728723973
P_DENS epoch 116 | train loss:0.3511878252029419,test loss:0.36744460463523865,acc:0.8459341397849462,recall:0.8406169478815844,f1:0.8334312261197292,pre:0.8302608684770023
P_DENS epoch 117 | train loss:0.3407122492790222,test loss:0.36438000202178955,acc:0.8490423387096774,recall:0.8365423711014682,f1:0.8343064545478277,pre:0.834798659535063
P_DENS epoch 118 | train loss:0.33789780735969543,test loss:0.3671359121799469,acc:0.8477822580645161,recall:0.835725448737592,f1:0.8333604245353096,pre:0.8332762346864534
P_DENS epoch 119 | train loss:0.34905460476875305,test loss:0.38183626532554626,acc:0.8401377688172043,recall:0.8324222653113335,f1:0.8242679317798738,pre:0.819932863178226
P_DENS epoch 120 | train loss:0.3427812457084656,test loss:0.36870577931404114,acc:0.84375,recall:0.8261645304973773,f1:0.8268582536453997,pre:0.8305681248875476
P_DENS epoch 121 | train loss:0.3368772268295288,test loss:0.38806673884391785,acc:0.8429099462365591,recall:0.8072498010098679,f1:0.8185278209100111,pre:0.842644124442459
P_DENS epoch 122 | train loss:0.34201404452323914,test loss:0.4180719554424286,acc:0.8198084677419355,recall:0.8297894463046365,f1:0.807889602334255,pre:0.8055873623567785
P_DENS epoch 123 | train loss:0.33919835090637207,test loss:0.3751913607120514,acc:0.8429099462365591,recall:0.8408868899224208,f1:0.8309592698539994,pre:0.826108119041181
P_DENS epoch 124 | train loss:0.3444559574127197,test loss:0.3583168089389801,acc:0.8483702956989247,recall:0.8261143161485144,f1:0.8281364790527098,pre:0.8332258074275201
P_DENS epoch 125 | train loss:0.34373873472213745,test loss:0.3776100277900696,acc:0.8445900537634409,recall:0.8331317137026978,f1:0.8298861028746879,pre:0.8290674051540018
P_DENS epoch 126 | train loss:0.3612390160560608,test loss:0.3607150614261627,acc:0.8478662634408602,recall:0.8199032680766947,f1:0.8273574134133874,pre:0.843519544852621
P_DENS epoch 127 | train loss:0.3500491678714752,test loss:0.3680238723754883,acc:0.8430779569892473,recall:0.815583820754664,f1:0.8220697706782832,pre:0.8347000596542686
P_DENS epoch 128 | train loss:0.33734726905822754,test loss:0.36467042565345764,acc:0.8472782258064516,recall:0.835969228914747,f1:0.832943968727974,pre:0.8323259742316238
P_DENS epoch 129 | train loss:0.34896042943000793,test loss:0.3762809932231903,acc:0.842741935483871,recall:0.8103056490675536,f1:0.8191604310543417,pre:0.8412338397396069
P_DENS epoch 130 | train loss:0.3427095115184784,test loss:0.37651315331459045,acc:0.8381216397849462,recall:0.840594835137527,f1:0.8273346808416858,pre:0.8220753232694541
P_DENS epoch 131 | train loss:0.3357546329498291,test loss:0.36525487899780273,acc:0.8482022849462365,recall:0.8235663235955838,f1:0.8292274434120129,pre:0.8393384296181262
P_DENS epoch 132 | train loss:0.34190186858177185,test loss:0.3924013078212738,acc:0.8423219086021505,recall:0.8216801573763843,f1:0.8242472177858173,pre:0.8300758206470752
P_DENS epoch 133 | train loss:0.342710942029953,test loss:0.36228519678115845,acc:0.8416498655913979,recall:0.8365797908301187,f1:0.8290455907982327,pre:0.8268298888882608
P_DENS epoch 134 | train loss:0.3412618637084961,test loss:0.37254711985588074,acc:0.8417338709677419,recall:0.8333290482024736,f1:0.8279965908707343,pre:0.8269721399534047
P_DENS epoch 135 | train loss:0.33002856373786926,test loss:0.370806485414505,acc:0.8347614247311828,recall:0.8316965079178911,f1:0.8214632045479335,pre:0.8185310970464464
P_DENS epoch 136 | train loss:0.33592650294303894,test loss:0.3599708676338196,acc:0.8475302419354839,recall:0.8308030055752441,f1:0.8314392706255984,pre:0.8349643382260657
P_DENS epoch 137 | train loss:0.34414806962013245,test loss:0.4189535677433014,acc:0.8354334677419355,recall:0.7903659156214977,f1:0.8052114783804954,pre:0.8448874600554469
P_DENS epoch 138 | train loss:0.3396073579788208,test loss:0.3697220981121063,acc:0.8392137096774194,recall:0.8347931770865219,f1:0.8263994038412261,pre:0.8252789536975181
P_DENS epoch 139 | train loss:0.34062767028808594,test loss:0.3692481815814972,acc:0.8463541666666666,recall:0.8265717914198872,f1:0.828358008449952,pre:0.8350704868734872
P_DENS epoch 140 | train loss:0.33479276299476624,test loss:0.37497177720069885,acc:0.8405577956989247,recall:0.8426881203428324,f1:0.8300551030076946,pre:0.8262905646110461
P_DENS epoch 141 | train loss:0.33736851811408997,test loss:0.39432233572006226,acc:0.8424899193548387,recall:0.8065798878345873,f1:0.8166633184196204,pre:0.8365438126394327
P_DENS epoch 142 | train loss:0.32589662075042725,test loss:0.39013126492500305,acc:0.8434139784946236,recall:0.8171825075669841,f1:0.8230804376117677,pre:0.8367191669343428
P_DENS epoch 143 | train loss:0.3338603377342224,test loss:0.4011555314064026,acc:0.8409778225806451,recall:0.8007835570134679,f1:0.8138549021174059,pre:0.8453418569438698
P_DENS epoch 144 | train loss:0.343729704618454,test loss:0.3585190176963806,acc:0.8499663978494624,recall:0.8381213397198605,f1:0.8357746027382018,pre:0.8363971354127022
epoch 144 : weight has update
P_DENS epoch 145 | train loss:0.3353753387928009,test loss:0.3830218017101288,acc:0.8387096774193549,recall:0.8432832099954405,f1:0.8287326469461587,pre:0.8232942664702018
P_DENS epoch 146 | train loss:0.3379206359386444,test loss:0.3729701638221741,acc:0.8377016129032258,recall:0.8347342231702312,f1:0.825409504864423,pre:0.821751768825398
P_DENS epoch 147 | train loss:0.33915847539901733,test loss:0.3635602295398712,acc:0.847698252688172,recall:0.827096489984276,f1:0.827599111978986,pre:0.8318478049042746
P_DENS epoch 148 | train loss:0.3342006504535675,test loss:0.403176873922348,acc:0.8303091397849462,recall:0.8351155872768428,f1:0.819494974853672,pre:0.815239682795232
P_DENS epoch 149 | train loss:0.3326999247074127,test loss:0.3751291334629059,acc:0.8443380376344086,recall:0.8187985675370087,f1:0.8245629492324713,pre:0.8367787716616727
P_DENS epoch 150 | train loss:0.3396175503730774,test loss:0.3868970572948456,acc:0.8298051075268817,recall:0.8283772794374488,f1:0.8167404088196293,pre:0.8139579339167012
training has finished used time : 3819.7943365573883
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (16667, 18)
trait shape (1, 16667)
df shape (20087, 42195)
(5000, 32032) (11667, 32032)
train dataset already completed!
5000
test dataset already completed!
11667
POD epoch 1 | train loss:0.8933879137039185,test loss:0.904531717300415,acc:0.6677229333524027,recall:0.34161736655128794,f1:0.29274416945983334,pre:0.37319668764069924
epoch 1 : weight has update
POD epoch 2 | train loss:0.80899977684021,test loss:0.865635871887207,acc:0.6673832594393593,recall:0.33242753623188365,f1:0.2658623225623863,pre:0.22186665713196027
POD epoch 3 | train loss:0.8212735056877136,test loss:0.7967554330825806,acc:0.667870423340961,recall:0.33242753623188365,f1:0.2659544783608411,pre:0.222029045099161
POD epoch 4 | train loss:0.8185362219810486,test loss:0.8075888156890869,acc:0.6688447511441648,recall:0.3342391304347822,f1:0.26772377297780237,pre:0.22357806242848965
POD epoch 5 | train loss:0.8146959543228149,test loss:0.7943292856216431,acc:0.6659217677345538,recall:0.33242753623188365,f1:0.2654210292200748,pre:0.22137241669050334
POD epoch 6 | train loss:0.8166056275367737,test loss:0.8267006278038025,acc:0.6683575872425629,recall:0.3342391304347822,f1:0.26756230996828423,pre:0.22339556219012205
POD epoch 7 | train loss:0.8142505884170532,test loss:0.7667969465255737,acc:0.6703062428489702,recall:0.3342391304347822,f1:0.26823769642633616,pre:0.22448311463100684
POD epoch 8 | train loss:0.7866014242172241,test loss:0.9734414219856262,acc:0.6673832594393593,recall:0.33242753623188365,f1:0.2658327572801687,pre:0.22183835097254007
POD epoch 9 | train loss:0.7446213364601135,test loss:0.8114450573921204,acc:0.6716917548627002,recall:0.44231035736116586,f1:0.4269101679221164,pre:0.41643879397930056
epoch 9 : weight has update
POD epoch 10 | train loss:0.7108954787254333,test loss:0.727319061756134,acc:0.6778908037757436,recall:0.438322822323856,f1:0.4261106080927666,pre:0.41717841296932606
epoch 10 : weight has update
POD epoch 11 | train loss:0.6997747421264648,test loss:0.7129903435707092,acc:0.6867670194508009,recall:0.4730874153932593,f1:0.446683930242358,pre:0.43383284433007185
epoch 11 : weight has update
POD epoch 12 | train loss:0.6821274161338806,test loss:1.301619291305542,acc:0.28288132866132726,recall:0.33258438771752846,f1:0.14624341147933945,pre:0.10751431285173306
POD epoch 13 | train loss:0.6712557673454285,test loss:0.694487988948822,acc:0.7048501859267735,recall:0.37977300509178713,f1:0.35447827378890534,pre:0.5276915029593382
POD epoch 14 | train loss:0.6518316864967346,test loss:0.6502243876457214,acc:0.7394567005148742,recall:0.44954903524073,f1:0.44909517399211507,pre:0.4785286734364046
epoch 14 : weight has update
POD epoch 15 | train loss:0.6409943103790283,test loss:0.6513813734054565,acc:0.7291815646453089,recall:0.4802243168767733,f1:0.4674192312677546,pre:0.4580030580602741
epoch 15 : weight has update
POD epoch 16 | train loss:0.6284635663032532,test loss:0.6362602710723877,acc:0.7493072439931351,recall:0.44733610317388445,f1:0.44861419890254484,pre:0.500951626328281
epoch 16 : weight has update
POD epoch 17 | train loss:0.6375787258148193,test loss:0.6841205358505249,acc:0.6951516018306636,recall:0.4898145241983906,f1:0.4582490357552105,pre:0.4463093609282688
POD epoch 18 | train loss:0.6243948936462402,test loss:0.7092307806015015,acc:0.681944543764302,recall:0.487155476715273,f1:0.4502560631424624,pre:0.4412083710912304
POD epoch 19 | train loss:0.6075631976127625,test loss:0.6694477200508118,acc:0.7230003933066361,recall:0.505593416381184,f1:0.47842351312927717,pre:0.463901054485358
epoch 19 : weight has update
POD epoch 20 | train loss:0.6165326833724976,test loss:1.2911572456359863,acc:0.37906714816933634,recall:0.3760488982765004,f1:0.2417638637307546,pre:0.4123705447166598
POD epoch 21 | train loss:0.5973970293998718,test loss:0.6821051836013794,acc:0.7080994350686499,recall:0.4997296001700092,f1:0.4677570315496303,pre:0.4546264848012747
POD epoch 22 | train loss:0.5934445261955261,test loss:0.6052462458610535,acc:0.754295087242563,recall:0.4818412090082089,f1:0.47661878307935307,pre:0.4804403783079056
epoch 22 : weight has update
POD epoch 23 | train loss:0.5898302793502808,test loss:0.9919772148132324,acc:0.4796285040045767,recall:0.4228345426701849,f1:0.3237305079922022,pre:0.42489296649215286
POD epoch 24 | train loss:0.5821900367736816,test loss:0.8557460904121399,acc:0.7077999856979404,recall:0.3787151222620075,f1:0.3533570114511695,pre:0.5414319081473125
POD epoch 25 | train loss:0.5760970711708069,test loss:0.5868625640869141,acc:0.7616785254576659,recall:0.5033484463385403,f1:0.49322080985455324,pre:0.48720653506565464
epoch 25 : weight has update
POD epoch 26 | train loss:0.5679001212120056,test loss:0.6404569745063782,acc:0.7318095680778032,recall:0.5128865607747217,f1:0.48536563695471596,pre:0.46964345717417755
POD epoch 27 | train loss:0.5615093111991882,test loss:0.5891930460929871,acc:0.7712966604691075,recall:0.5155824754784896,f1:0.5157280392464922,pre:0.5563951695451125
epoch 27 : weight has update
POD epoch 28 | train loss:0.5586337447166443,test loss:0.6025200486183167,acc:0.7631668335240274,recall:0.4654926493963952,f1:0.46817133465470856,pre:0.5127213026021152
POD epoch 29 | train loss:0.5552980303764343,test loss:0.6124991178512573,acc:0.7639310998283753,recall:0.5252143751183915,f1:0.5228912180545813,pre:0.5668588166551921
epoch 29 : weight has update
POD epoch 30 | train loss:0.5402013659477234,test loss:0.6371157765388489,acc:0.7388622711670481,recall:0.5520522416795381,f1:0.5366766604190457,pre:0.6075615208679082
epoch 30 : weight has update
POD epoch 31 | train loss:0.5380700826644897,test loss:0.5747582316398621,acc:0.7737995208810069,recall:0.5060995721528287,f1:0.5208482888984706,pre:0.6140345082906532
POD epoch 32 | train loss:0.5366609692573547,test loss:0.7741568088531494,acc:0.679245030034325,recall:0.5751962078776939,f1:0.542185183034534,pre:0.5737406983439958
POD epoch 33 | train loss:0.5403637290000916,test loss:0.5758553743362427,acc:0.7659289187643021,recall:0.525984585449907,f1:0.5222921436483786,pre:0.571925966876126
POD epoch 34 | train loss:0.5341376662254333,test loss:0.5953821539878845,acc:0.7714039259153317,recall:0.49204606514919924,f1:0.5032687855750354,pre:0.5823849403115101
POD epoch 35 | train loss:0.5229724645614624,test loss:0.5600505471229553,acc:0.7734419693935927,recall:0.5190077773104301,f1:0.5281025542562423,pre:0.6073987752809396
POD epoch 36 | train loss:0.5205386281013489,test loss:1.1170405149459839,acc:0.41441558209382157,recall:0.39492682366460874,f1:0.2726448441321411,pre:0.4240246430474727
POD epoch 37 | train loss:0.5188114643096924,test loss:1.01536226272583,acc:0.4708014516590389,recall:0.4430120257008781,f1:0.352207554941889,pre:0.5307999918851879
POD epoch 38 | train loss:0.5091982483863831,test loss:0.6793943643569946,acc:0.7229601687643021,recall:0.5714228654117841,f1:0.5633565151880845,pre:0.6351101381693695
epoch 38 : weight has update
POD epoch 39 | train loss:0.5030341148376465,test loss:0.5509622097015381,acc:0.7858400672196796,recall:0.5352604978747609,f1:0.552216435502944,pre:0.6602440066773005
epoch 39 : weight has update
POD epoch 40 | train loss:0.5064219236373901,test loss:0.6159859895706177,acc:0.7429338887299771,recall:0.5636441910805055,f1:0.5601410668012419,pre:0.6224716860660522
POD epoch 41 | train loss:0.5152732729911804,test loss:0.670944333076477,acc:0.7233177202517161,recall:0.5668440734653543,f1:0.5529935433766066,pre:0.6241881014567353
POD epoch 42 | train loss:0.5000050663948059,test loss:0.7000688314437866,acc:0.6906911470251716,recall:0.5351141448766866,f1:0.5039493538359906,pre:0.5898699690443174
POD epoch 43 | train loss:0.5077199339866638,test loss:0.6387532949447632,acc:0.734486734839817,recall:0.5491183994393489,f1:0.5319343854069353,pre:0.5967187222180119
POD epoch 44 | train loss:0.4960973262786865,test loss:0.5399779081344604,acc:0.7885574585240274,recall:0.5505102873481486,f1:0.5711547485246552,pre:0.6738175056877155
epoch 44 : weight has update
POD epoch 45 | train loss:0.48866650462150574,test loss:0.7657206058502197,acc:0.6833255863844393,recall:0.5978192852412447,f1:0.5611241015739357,pre:0.5867836588083677
POD epoch 46 | train loss:0.4931144416332245,test loss:0.599553644657135,acc:0.7463976687643021,recall:0.5683857970558958,f1:0.5692336500167713,pre:0.6586710585333438
POD epoch 47 | train loss:0.4850389063358307,test loss:0.610615611076355,acc:0.7511754505148742,recall:0.5751868179139877,f1:0.5758338265197102,pre:0.6419375757888482
POD epoch 48 | train loss:0.47454848885536194,test loss:0.8946897387504578,acc:0.5830368635583524,recall:0.5738174591499547,f1:0.4945151320625748,pre:0.5412328900020903
POD epoch 49 | train loss:0.4980016350746155,test loss:0.7455352544784546,acc:0.6606344751144164,recall:0.5622453548608953,f1:0.5297885270998812,pre:0.5981481171134484
POD epoch 50 | train loss:0.4871063828468323,test loss:0.6798250675201416,acc:0.7087162113844394,recall:0.5766433642720544,f1:0.556496393627228,pre:0.6125204058225017
POD epoch 51 | train loss:0.4818238615989685,test loss:0.690631091594696,acc:0.7046401244279177,recall:0.5627998688986612,f1:0.5422186028666663,pre:0.6178051055237785
POD epoch 52 | train loss:0.48438596725463867,test loss:1.165063500404358,acc:0.45288365274599546,recall:0.48052144742986475,f1:0.3632277533726782,pre:0.48388351296111665
POD epoch 53 | train loss:0.4843907058238983,test loss:0.7075765132904053,acc:0.6966309711098397,recall:0.5637093289475349,f1:0.5403452897376865,pre:0.6221194674631908
POD epoch 54 | train loss:0.4721943736076355,test loss:0.5465291142463684,acc:0.7772007294050344,recall:0.5658759943583617,f1:0.5721795100089478,pre:0.6435083405078746
POD epoch 55 | train loss:0.4678643047809601,test loss:0.5399767756462097,acc:0.7913150743707094,recall:0.5418863478563957,f1:0.5633071408039584,pre:0.6739068719784871
POD epoch 56 | train loss:0.4670001268386841,test loss:0.6100003719329834,acc:0.7434433995995423,recall:0.5702208401724791,f1:0.5628028156000537,pre:0.6423791269159668
POD epoch 57 | train loss:0.47330933809280396,test loss:0.7104251980781555,acc:0.6945527030892449,recall:0.5692613703436029,f1:0.5456022478355232,pre:0.6026809929150859
POD epoch 58 | train loss:0.46847641468048096,test loss:0.5720959901809692,acc:0.7667334096109839,recall:0.616691650012729,f1:0.6179922164457492,pre:0.6507738370768383
epoch 58 : weight has update
POD epoch 59 | train loss:0.45785385370254517,test loss:0.8012875318527222,acc:0.6281688000572082,recall:0.5569622955016785,f1:0.5121961830308915,pre:0.5906993015107435
POD epoch 60 | train loss:0.4467318654060364,test loss:0.6722142696380615,acc:0.7206673698512587,recall:0.6200758231342148,f1:0.5959936710902813,pre:0.6184902292660203
POD epoch 61 | train loss:0.46080926060676575,test loss:0.6013078689575195,acc:0.760789116132723,recall:0.6032477118188214,f1:0.6067621640266289,pre:0.6839028982938091
epoch 61 : weight has update
POD epoch 62 | train loss:0.4564323425292969,test loss:0.5739206075668335,acc:0.768521167048055,recall:0.6057848621956505,f1:0.6157428409944611,pre:0.688854469542591
epoch 62 : weight has update
POD epoch 63 | train loss:0.4467698037624359,test loss:0.739614725112915,acc:0.6822618707093822,recall:0.6061681492821167,f1:0.5609850649937906,pre:0.5787762574417867
POD epoch 64 | train loss:0.4569874405860901,test loss:0.9066426157951355,acc:0.5932047339816934,recall:0.5561297240231454,f1:0.4920339793620548,pre:0.5554508711436175
POD epoch 65 | train loss:0.43687865138053894,test loss:0.6001433730125427,acc:0.7445071152745996,recall:0.5861553730681991,f1:0.5828619412591756,pre:0.6590814701693788
POD epoch 66 | train loss:0.44984814524650574,test loss:0.7612475752830505,acc:0.6660424413615561,recall:0.6378206620262895,f1:0.5673577141112509,pre:0.5709347173141847
POD epoch 67 | train loss:0.45312002301216125,test loss:0.5495669841766357,acc:0.7880702946224257,recall:0.5295118593816671,f1:0.5579116889677025,pre:0.7012794557939352
POD epoch 68 | train loss:0.45423102378845215,test loss:0.5585503578186035,acc:0.7760520952517161,recall:0.576688844209481,f1:0.5856076229646223,pre:0.6790589156231791
POD epoch 69 | train loss:0.4467465281486511,test loss:0.7484490275382996,acc:0.6678257294050344,recall:0.5604344184115537,f1:0.5271929216225603,pre:0.6080712591932224
POD epoch 70 | train loss:0.4420762360095978,test loss:0.5280765295028687,acc:0.7959230191647597,recall:0.5954168815154602,f1:0.6214840076804571,pre:0.7271870805355741
epoch 70 : weight has update
POD epoch 71 | train loss:0.4445416331291199,test loss:0.7129925489425659,acc:0.6902263300915332,recall:0.5923116123999324,f1:0.5669888981935536,pre:0.6277738910325334
POD epoch 72 | train loss:0.43427199125289917,test loss:0.5307030081748962,acc:0.7949039974256292,recall:0.5784807343180334,f1:0.6032233424309403,pre:0.7214990477500948
POD epoch 73 | train loss:0.4498828947544098,test loss:0.5789628624916077,acc:0.7618081378718535,recall:0.5801799116478863,f1:0.5875087386829104,pre:0.6685427975079542
POD epoch 74 | train loss:0.43591055274009705,test loss:0.6843764781951904,acc:0.7060390446224257,recall:0.6137855850048014,f1:0.5870982753894392,pre:0.6283031943882847
POD epoch 75 | train loss:0.4338209629058838,test loss:0.8775462508201599,acc:0.5873408895881006,recall:0.5239329648676803,f1:0.47206050309652703,pre:0.6073286385122745
POD epoch 76 | train loss:0.43380269408226013,test loss:0.5323377251625061,acc:0.7914893807208239,recall:0.594762672211804,f1:0.6178866997758865,pre:0.7050892012413026
POD epoch 77 | train loss:0.43821755051612854,test loss:0.5380920171737671,acc:0.785545087242563,recall:0.5711304257699109,f1:0.6005590453262514,pre:0.7195569464557042
POD epoch 78 | train loss:0.43204358220100403,test loss:0.5359380841255188,acc:0.7855227402745996,recall:0.6009366398221253,f1:0.6165605222162162,pre:0.7161497083073054
POD epoch 79 | train loss:0.42561623454093933,test loss:0.589844822883606,acc:0.7503664902745996,recall:0.6224480293275798,f1:0.6227811209958741,pre:0.6946751611266998
POD epoch 80 | train loss:0.43373504281044006,test loss:0.533988893032074,acc:0.7916994422196796,recall:0.5754160051470167,f1:0.5945013283783047,pre:0.7064314393675621
POD epoch 81 | train loss:0.43339622020721436,test loss:0.6354537010192871,acc:0.7691513515446224,recall:0.4807490407745559,f1:0.5007258437097374,pre:0.6630380517965161
POD epoch 82 | train loss:0.42725425958633423,test loss:0.5218544006347656,acc:0.7992974113272311,recall:0.5766347231622532,f1:0.6044181033057573,pre:0.7169248747537237
POD epoch 83 | train loss:0.43648606538772583,test loss:0.537083625793457,acc:0.7902334811212814,recall:0.6355009074320103,f1:0.6511428347280741,pre:0.7066974029775589
epoch 83 : weight has update
POD epoch 84 | train loss:0.4263792932033539,test loss:0.7948379516601562,acc:0.655709203375286,recall:0.6000164550613982,f1:0.554579583859342,pre:0.5975730107189636
POD epoch 85 | train loss:0.4207744598388672,test loss:0.5332421064376831,acc:0.7857998426773456,recall:0.5868862607669852,f1:0.6086935320462845,pre:0.6983440180362465
POD epoch 86 | train loss:0.430042564868927,test loss:0.5264190435409546,acc:0.7936302202517161,recall:0.5915148464947322,f1:0.6182828033463281,pre:0.7253877312096616
POD epoch 87 | train loss:0.43246880173683167,test loss:0.5581921935081482,acc:0.7890893163615561,recall:0.5484483880596277,f1:0.5710261045190999,pre:0.6814063576784622
POD epoch 88 | train loss:0.4286070168018341,test loss:0.5343242883682251,acc:0.7865238844393593,recall:0.5837903077767391,f1:0.6059701039214348,pre:0.7225070960485367
POD epoch 89 | train loss:0.43167436122894287,test loss:0.5869960188865662,acc:0.752341962242563,recall:0.6056155289258066,f1:0.608275855603415,pre:0.7040688664402243
POD epoch 90 | train loss:0.42266952991485596,test loss:0.5299187898635864,acc:0.789491561784897,recall:0.5816934658060796,f1:0.607762597789687,pre:0.7200573233599061
POD epoch 91 | train loss:0.42169418931007385,test loss:0.5735223889350891,acc:0.7552068435354692,recall:0.5919600008270518,f1:0.5941200753893083,pre:0.6705618044386975
POD epoch 92 | train loss:0.42132481932640076,test loss:0.5347245931625366,acc:0.7884725400457665,recall:0.6048628462118613,f1:0.625740834487892,pre:0.7112958624656344
POD epoch 93 | train loss:0.42091473937034607,test loss:0.6616541743278503,acc:0.7297983409610984,recall:0.6781669713309565,f1:0.6295401568517791,pre:0.6232563917096783
POD epoch 94 | train loss:0.41316741704940796,test loss:0.5336704850196838,acc:0.792441361556064,recall:0.5522326836130057,f1:0.5776949787782342,pre:0.7022949914176297
POD epoch 95 | train loss:0.4179997742176056,test loss:0.5561403036117554,acc:0.7722084167620137,recall:0.625466996156318,f1:0.6338375834762712,pre:0.7128232128179206
POD epoch 96 | train loss:0.4128021001815796,test loss:0.6325231194496155,acc:0.7218785755148742,recall:0.5905237476593084,f1:0.5788451994545201,pre:0.6467050267962042
POD epoch 97 | train loss:0.4214058518409729,test loss:0.672893226146698,acc:0.7035987557208239,recall:0.6330058850477633,f1:0.6061273567669352,pre:0.6554333265785202
POD epoch 98 | train loss:0.4285569489002228,test loss:0.576381266117096,acc:0.7671803489702518,recall:0.6203406004176258,f1:0.6257861557134202,pre:0.6967615623566202
POD epoch 99 | train loss:0.40776604413986206,test loss:0.573745846748352,acc:0.7666261441647597,recall:0.6322902799545222,f1:0.6353990045055464,pre:0.6945687134974822
POD epoch 100 | train loss:0.4236203730106354,test loss:0.5557865500450134,acc:0.7767984839816934,recall:0.6176565693048187,f1:0.6335141355805222,pre:0.7042364834041274
POD epoch 101 | train loss:0.4193617105484009,test loss:0.5380434989929199,acc:0.7923787900457665,recall:0.6272791566991037,f1:0.6475370708349635,pre:0.7192149688626008
epoch 101 : weight has update
POD epoch 102 | train loss:0.4107493460178375,test loss:0.5460052490234375,acc:0.7805348970251716,recall:0.6161781865938307,f1:0.6307847656811117,pre:0.7045363370311731
POD epoch 103 | train loss:0.4226120114326477,test loss:0.5346546769142151,acc:0.7901887871853547,recall:0.6110474056534906,f1:0.6297721659214962,pre:0.7230655138068645
POD epoch 104 | train loss:0.4284324645996094,test loss:0.5332303047180176,acc:0.7955833452517161,recall:0.594918629431407,f1:0.6244540611576758,pre:0.737253094497341
POD epoch 105 | train loss:0.40632039308547974,test loss:0.590292751789093,acc:0.7622103832951944,recall:0.6637925026004524,f1:0.6476265404502192,pre:0.6565362773042517
POD epoch 106 | train loss:0.4138422906398773,test loss:0.606267511844635,acc:0.7428489702517161,recall:0.6476836723544988,f1:0.620895291330353,pre:0.62273785478833
POD epoch 107 | train loss:0.41340237855911255,test loss:0.5685853958129883,acc:0.7762666261441649,recall:0.6109569372763137,f1:0.6261730645858767,pre:0.7152577956661578
POD epoch 108 | train loss:0.41053304076194763,test loss:0.5264968276023865,acc:0.79271846395881,recall:0.6039968371408803,f1:0.6368633676461483,pre:0.7314248571598571
POD epoch 109 | train loss:0.4180518090724945,test loss:0.5381982922554016,acc:0.7916145237414187,recall:0.5575156417653359,f1:0.5898160767322004,pre:0.7174132476503622
POD epoch 110 | train loss:0.43012747168540955,test loss:0.6412023305892944,acc:0.7127476044050344,recall:0.5967382583127376,f1:0.5854224548759107,pre:0.6991773101146412
POD epoch 111 | train loss:0.4167156219482422,test loss:0.5372432470321655,acc:0.7911899313501144,recall:0.5548945907818741,f1:0.5890807806557444,pre:0.7328429247868873
POD epoch 112 | train loss:0.4192570447921753,test loss:0.5404089689254761,acc:0.7845439430778032,recall:0.5843089378975445,f1:0.6066458883162508,pre:0.6986371149685778
POD epoch 113 | train loss:0.4072819650173187,test loss:0.5639907121658325,acc:0.7770308924485126,recall:0.6565737657270457,f1:0.6542612269355863,pre:0.6789426481419248
POD epoch 114 | train loss:0.41265982389450073,test loss:0.5268133282661438,acc:0.7988728189359268,recall:0.601937092975567,f1:0.6324021725637475,pre:0.7503419732155202
POD epoch 115 | train loss:0.4136630892753601,test loss:0.5452879667282104,acc:0.7908055635011442,recall:0.5403263457521025,f1:0.5757011620353635,pre:0.7480548315682259
POD epoch 116 | train loss:0.4039783179759979,test loss:0.6109803915023804,acc:0.748198834382151,recall:0.6588540312846977,f1:0.6350203784757211,pre:0.6452515754492875
POD epoch 117 | train loss:0.4229263961315155,test loss:0.5288074612617493,acc:0.7856702302631579,recall:0.641468966517637,f1:0.6491104020819555,pre:0.6795894360987016
POD epoch 118 | train loss:0.41535577178001404,test loss:0.6845306158065796,acc:0.7079921696224257,recall:0.6263180766511575,f1:0.609025857475972,pre:0.6668433021306885
POD epoch 119 | train loss:0.41772007942199707,test loss:0.5626586675643921,acc:0.7819338172196796,recall:0.6243341009355781,f1:0.6388005428996198,pre:0.7029827450666347
POD epoch 120 | train loss:0.40213435888290405,test loss:0.5791963338851929,acc:0.7678373498283753,recall:0.6227626821622217,f1:0.6229054303653904,pre:0.6678501195590046
POD epoch 121 | train loss:0.4125043451786041,test loss:0.5979909896850586,acc:0.7548850471967963,recall:0.6496341901516491,f1:0.6368457593617822,pre:0.6540864182335993
POD epoch 122 | train loss:0.4017390310764313,test loss:0.5314492583274841,acc:0.7931654033180778,recall:0.6342356068436792,f1:0.6537426689630369,pre:0.7094442338133867
epoch 122 : weight has update
POD epoch 123 | train loss:0.3958826959133148,test loss:0.5394439101219177,acc:0.79662471395881,recall:0.5983139704188651,f1:0.6332068581414995,pre:0.7523925491966594
POD epoch 124 | train loss:0.41516026854515076,test loss:0.5760900974273682,acc:0.7862870065789475,recall:0.5180418387863258,f1:0.538639894923916,pre:0.6585013539748169
POD epoch 125 | train loss:0.41212403774261475,test loss:0.581152617931366,acc:0.7704921696224257,recall:0.649776786895159,f1:0.64030780272453,pre:0.6562831135737578
POD epoch 126 | train loss:0.4046042859554291,test loss:0.7679606676101685,acc:0.6484062142448512,recall:0.5855854057589795,f1:0.5463859843678307,pre:0.6123434394312454
POD epoch 127 | train loss:0.41014933586120605,test loss:0.5680881142616272,acc:0.7756275028604118,recall:0.6248066178908831,f1:0.6334233055818715,pre:0.6996683725756567
POD epoch 128 | train loss:0.4288616180419922,test loss:0.5237497091293335,acc:0.8010181278604118,recall:0.5742201641872378,f1:0.6025152491322794,pre:0.7336805891876288
POD epoch 129 | train loss:0.40294867753982544,test loss:0.6356133222579956,acc:0.734915796624714,recall:0.6250781580792123,f1:0.6130156364701579,pre:0.66283675486262
POD epoch 130 | train loss:0.40224191546440125,test loss:0.5288596153259277,acc:0.7921240346109839,recall:0.5960741551008769,f1:0.618804852873993,pre:0.7186984978978116
POD epoch 131 | train loss:0.40005940198898315,test loss:0.5480744242668152,acc:0.7890222754576659,recall:0.5541474672362536,f1:0.5896407400379028,pre:0.7253969619448262
POD epoch 132 | train loss:0.40842366218566895,test loss:0.5269139409065247,acc:0.7967319794050344,recall:0.5590082215279469,f1:0.5838519714030808,pre:0.7066361171063449
POD epoch 133 | train loss:0.39676976203918457,test loss:0.5899674296379089,acc:0.7804902030892448,recall:0.6715414720508117,f1:0.6625853784471165,pre:0.6754330033126397
POD epoch 134 | train loss:0.39700740575790405,test loss:0.606660008430481,acc:0.799976759153318,recall:0.5645620256617192,f1:0.590411221787497,pre:0.7073002093075899
POD epoch 135 | train loss:0.4026564955711365,test loss:0.5760605335235596,acc:0.7725927846109839,recall:0.6054816332484698,f1:0.6161562525952359,pre:0.6901666239407332
POD epoch 136 | train loss:0.40095096826553345,test loss:0.6412326097488403,acc:0.7190539187643021,recall:0.5900485533227406,f1:0.5824018599459856,pre:0.6916016062177924
POD epoch 137 | train loss:0.39783361554145813,test loss:0.5314075946807861,acc:0.7889820509153317,recall:0.5905826986585859,f1:0.6172826795955919,pre:0.7116366053188057
POD epoch 138 | train loss:0.4049069285392761,test loss:0.5655242204666138,acc:0.7821885726544622,recall:0.5378367266076257,f1:0.5745489939005659,pre:0.7433441976192153
POD epoch 139 | train loss:0.40693002939224243,test loss:0.7132786512374878,acc:0.7090111913615561,recall:0.6683809658887251,f1:0.6044511194804794,pre:0.5945308583507133
POD epoch 140 | train loss:0.39481157064437866,test loss:0.6338657140731812,acc:0.741257866132723,recall:0.6728110942771075,f1:0.6281164631249863,pre:0.61568592309226
POD epoch 141 | train loss:0.41700276732444763,test loss:0.5350585579872131,acc:0.7943095680778032,recall:0.6017267522932118,f1:0.6320216139295711,pre:0.7235693414881021
POD epoch 142 | train loss:0.3968997597694397,test loss:0.5419906377792358,acc:0.7930581378718535,recall:0.6376625259815283,f1:0.6546434473308812,pre:0.7083671638701555
epoch 142 : weight has update
POD epoch 143 | train loss:0.41353803873062134,test loss:0.5457698702812195,acc:0.787498212242563,recall:0.6476631639646274,f1:0.6527440234100941,pre:0.6806674509438826
POD epoch 144 | train loss:0.4049498438835144,test loss:0.5337145924568176,acc:0.7832925128718535,recall:0.6256250439424312,f1:0.6393414452770473,pre:0.6975054975896195
POD epoch 145 | train loss:0.40489646792411804,test loss:0.75069260597229,acc:0.6889704304919908,recall:0.635590706341484,f1:0.5868846943410212,pre:0.600224433461874
POD epoch 146 | train loss:0.4083576500415802,test loss:0.5312272310256958,acc:0.7854601687643021,recall:0.5858156296569618,f1:0.6078796262481021,pre:0.7031844814458705
POD epoch 147 | train loss:0.3948230743408203,test loss:0.617489218711853,acc:0.7507061641876431,recall:0.650507369102365,f1:0.6377952613202797,pre:0.6644154003322877
POD epoch 148 | train loss:0.39978331327438354,test loss:0.6839309930801392,acc:0.6965683995995423,recall:0.604248431008244,f1:0.5783043974335641,pre:0.6265467957873146
POD epoch 149 | train loss:0.3994532525539398,test loss:0.5329182744026184,acc:0.7911050128718535,recall:0.5954593810764987,f1:0.6245036490743111,pre:0.7436237066257753
POD epoch 150 | train loss:0.3962002694606781,test loss:0.6249583959579468,acc:0.7285424413615561,recall:0.6458138640093819,f1:0.6189123100031034,pre:0.6387995516543372
training has finished used time : 3659.952210664749
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (16948, 18)
trait shape (1, 16948)
df shape (20087, 42195)
(5000, 32032) (11948, 32032)
train dataset already completed!
5000
test dataset already completed!
11948
SC_L epoch 1 | train loss:1.0078858137130737,test loss:1.094478964805603,acc:0.20843659332688588,recall:0.2881205673758863,f1:0.09928842049316698,pre:0.060274243431657
epoch 1 : weight has update
SC_L epoch 2 | train loss:0.9108344912528992,test loss:1.1227030754089355,acc:0.16500695116054157,recall:0.29025587374021605,f1:0.08466553151285747,pre:0.12572653876387224
epoch 2 : weight has update
SC_L epoch 3 | train loss:0.8979417681694031,test loss:1.2209515571594238,acc:0.16857319874274662,recall:0.29713711354315947,f1:0.08603616208959493,pre:0.1171153587731035
epoch 3 : weight has update
SC_L epoch 4 | train loss:0.8996692895889282,test loss:0.9552605748176575,acc:0.6205648573500967,recall:0.2916666666666665,f1:0.22345902374065751,pre:0.1814183641602192
epoch 4 : weight has update
SC_L epoch 5 | train loss:0.8775528073310852,test loss:1.080394983291626,acc:0.4574921421663443,recall:0.4087469245946832,f1:0.3286687293948071,pre:0.49417823303605274
epoch 5 : weight has update
SC_L epoch 6 | train loss:0.8740067481994629,test loss:1.023834228515625,acc:0.4820478723404255,recall:0.43214116445551526,f1:0.37328215700889067,pre:0.4702274894536763
epoch 6 : weight has update
SC_L epoch 7 | train loss:0.8613223433494568,test loss:0.8723511695861816,acc:0.6433223525145068,recall:0.33551660330079247,f1:0.3068576281322569,pre:0.5736412498760006
epoch 7 : weight has update
SC_L epoch 8 | train loss:0.8467271327972412,test loss:0.8504868149757385,acc:0.6538548718568665,recall:0.3477999485809289,f1:0.31956005524270836,pre:0.44362713865543424
SC_L epoch 9 | train loss:0.8160077929496765,test loss:0.8548234105110168,acc:0.6714065522243714,recall:0.39292521179823386,f1:0.39658102446266197,pre:0.5891288034470008
epoch 9 : weight has update
SC_L epoch 10 | train loss:0.795488178730011,test loss:0.8386754393577576,acc:0.6427405705996131,recall:0.4668394528215588,f1:0.46887617300497825,pre:0.4996681720868982
epoch 10 : weight has update
SC_L epoch 11 | train loss:0.7929087281227112,test loss:0.8574807047843933,acc:0.6552828820116053,recall:0.45668573440265303,f1:0.4589184287929547,pre:0.5128065848823476
epoch 11 : weight has update
SC_L epoch 12 | train loss:0.7806695699691772,test loss:0.825564444065094,acc:0.664765171663443,recall:0.45132790013429597,f1:0.46574643409294797,pre:0.5188461471689885
epoch 12 : weight has update
SC_L epoch 13 | train loss:0.7824238538742065,test loss:0.8124634623527527,acc:0.6587584622823984,recall:0.35573575350875336,f1:0.3304918154484638,pre:0.4367256926514651
SC_L epoch 14 | train loss:0.7686115503311157,test loss:0.7976620197296143,acc:0.6848404255319149,recall:0.45361215244528974,f1:0.4736905210636538,pre:0.5646291310893923
epoch 14 : weight has update
SC_L epoch 15 | train loss:0.767806887626648,test loss:0.7886273264884949,acc:0.67164833172147,recall:0.41926626345495316,f1:0.4278891297520485,pre:0.5592857071644073
SC_L epoch 16 | train loss:0.7680485844612122,test loss:0.8219313025474548,acc:0.6593477998065764,recall:0.3564956701301892,f1:0.3431313016957081,pre:0.6028454068438904
SC_L epoch 17 | train loss:0.7575396299362183,test loss:0.8004773259162903,acc:0.6664425169245648,recall:0.45979636977815436,f1:0.45673018565345264,pre:0.5684991037391597
SC_L epoch 18 | train loss:0.7618837952613831,test loss:0.7860661745071411,acc:0.6788790498065764,recall:0.437331033082547,f1:0.4569866827599649,pre:0.5917597980773799
SC_L epoch 19 | train loss:0.7534341216087341,test loss:0.7685215473175049,acc:0.6794154980657641,recall:0.4324040577293414,f1:0.45079045024452646,pre:0.5747360373740663
SC_L epoch 20 | train loss:0.7509335875511169,test loss:0.9269664287567139,acc:0.6494801740812379,recall:0.34059565574339706,f1:0.3072709929310731,pre:0.4732090368029195
SC_L epoch 21 | train loss:0.7440658807754517,test loss:0.8406071662902832,acc:0.6321627176015474,recall:0.5432526241074852,f1:0.5171417724122879,pre:0.5083919193146443
epoch 21 : weight has update
SC_L epoch 22 | train loss:0.7462067008018494,test loss:0.7605083584785461,acc:0.68246040860735,recall:0.45679064138261194,f1:0.47527293821232103,pre:0.5482554067364097
SC_L epoch 23 | train loss:0.7274231314659119,test loss:0.7601543664932251,acc:0.6854524298839458,recall:0.47037219346987574,f1:0.48815369815511295,pre:0.5624763961458881
epoch 23 : weight has update
SC_L epoch 24 | train loss:0.7259571552276611,test loss:0.8020778298377991,acc:0.6566277804642167,recall:0.5159362223967487,f1:0.5095567139663125,pre:0.5217511297735349
SC_L epoch 25 | train loss:0.7226012945175171,test loss:0.820555567741394,acc:0.6570811170212766,recall:0.5269502576654986,f1:0.5147736067424233,pre:0.5167932772651934
epoch 25 : weight has update
SC_L epoch 26 | train loss:0.7194302082061768,test loss:0.759088933467865,acc:0.6941413805609283,recall:0.4732782589480105,f1:0.49595962905968993,pre:0.5826979460400034
epoch 26 : weight has update
SC_L epoch 27 | train loss:0.7174098491668701,test loss:0.7481880784034729,acc:0.6933555971953579,recall:0.47961959140996574,f1:0.5022139306624234,pre:0.589463464684763
epoch 27 : weight has update
SC_L epoch 28 | train loss:0.7089606523513794,test loss:0.7506716847419739,acc:0.6925244801740813,recall:0.4565944564095861,f1:0.4808969472731983,pre:0.6046402382648647
SC_L epoch 29 | train loss:0.7049066424369812,test loss:0.7704466581344604,acc:0.6797932785299806,recall:0.5064270250961936,f1:0.5127260079203396,pre:0.5328044158438769
SC_L epoch 30 | train loss:0.7023208141326904,test loss:0.751331090927124,acc:0.6946551619922631,recall:0.4528133327217181,f1:0.4753159632243575,pre:0.5953461888347054
SC_L epoch 31 | train loss:0.6986654996871948,test loss:0.7912322282791138,acc:0.6615238152804642,recall:0.5024185643842685,f1:0.5029349958444536,pre:0.5385382883880117
SC_L epoch 32 | train loss:0.6989737749099731,test loss:0.7454503178596497,acc:0.6931138176982592,recall:0.4861273765157461,f1:0.5067871910791868,pre:0.5842317212328405
epoch 32 : weight has update
SC_L epoch 33 | train loss:0.6933860778808594,test loss:0.7824045419692993,acc:0.679755500483559,recall:0.5002397336568244,f1:0.5070559975754886,pre:0.5366021070423709
SC_L epoch 34 | train loss:0.6921222805976868,test loss:0.7758300304412842,acc:0.6866008824951644,recall:0.53530788509049,f1:0.5387713900813195,pre:0.5534549233175355
epoch 34 : weight has update
SC_L epoch 35 | train loss:0.6800140142440796,test loss:0.7471610307693481,acc:0.6908471349129595,recall:0.4983902899530385,f1:0.5146242890747557,pre:0.5672405855490275
SC_L epoch 36 | train loss:0.6791520118713379,test loss:0.7479307055473328,acc:0.6867444390715667,recall:0.4836373025803702,f1:0.4996750057719886,pre:0.5609339673403566
SC_L epoch 37 | train loss:0.6860387921333313,test loss:0.7315177917480469,acc:0.6966800652804642,recall:0.49349508502495626,f1:0.5128584483818608,pre:0.5737952487636551
SC_L epoch 38 | train loss:0.6724797487258911,test loss:0.7355431914329529,acc:0.6939071566731142,recall:0.4514804316802501,f1:0.47307357267531003,pre:0.5912293855173342
SC_L epoch 39 | train loss:0.6778458952903748,test loss:0.7657673358917236,acc:0.6774510396518375,recall:0.5259073768329893,f1:0.526477660905888,pre:0.5341726651467732
SC_L epoch 40 | train loss:0.6732022166252136,test loss:0.7322652339935303,acc:0.6988938588007738,recall:0.48412382143742233,f1:0.5084954497062316,pre:0.5892263607239918
SC_L epoch 41 | train loss:0.6696692109107971,test loss:0.7787088751792908,acc:0.6723283365570599,recall:0.5208441807748826,f1:0.5186264888860378,pre:0.5477046542701411
SC_L epoch 42 | train loss:0.6710500121116638,test loss:0.7474366426467896,acc:0.6967253989361702,recall:0.4925630017422858,f1:0.5112392410985179,pre:0.5726757454322534
SC_L epoch 43 | train loss:0.6679196357727051,test loss:0.8143482208251953,acc:0.6513312983558994,recall:0.5528606848894982,f1:0.5294292483746593,pre:0.5204401263583475
SC_L epoch 44 | train loss:0.6616710424423218,test loss:0.7644845247268677,acc:0.6715501088007737,recall:0.5531796707987251,f1:0.5428837126857365,pre:0.5404942691727964
SC_L epoch 45 | train loss:0.6659731864929199,test loss:0.7782567143440247,acc:0.6700843205996131,recall:0.5381750718162452,f1:0.5285431994316624,pre:0.5338506330368373
SC_L epoch 46 | train loss:0.6644008755683899,test loss:0.7387262582778931,acc:0.6962796179883947,recall:0.5172358084946704,f1:0.5288996742624809,pre:0.5605178119118839
SC_L epoch 47 | train loss:0.6553624272346497,test loss:0.7746037244796753,acc:0.6757888056092843,recall:0.5339380139126256,f1:0.5299962853724633,pre:0.5346499538823986
SC_L epoch 48 | train loss:0.6548395156860352,test loss:0.8071486949920654,acc:0.6530313104448743,recall:0.5560909404646166,f1:0.5283131232644414,pre:0.5210093678019768
SC_L epoch 49 | train loss:0.6566359996795654,test loss:0.7338621020317078,acc:0.7048099008704063,recall:0.5168353472276369,f1:0.5341504708293023,pre:0.5850688385170876
epoch 49 : weight has update
SC_L epoch 50 | train loss:0.6477935314178467,test loss:0.7369830012321472,acc:0.6950782761121856,recall:0.5249204235920951,f1:0.5371820902936196,pre:0.5664670722890882
SC_L epoch 51 | train loss:0.6469119191169739,test loss:0.7436679005622864,acc:0.691700918762089,recall:0.5030027699895847,f1:0.5165261366085329,pre:0.5693479911471985
SC_L epoch 52 | train loss:0.648963451385498,test loss:0.7380982041358948,acc:0.6982742988394585,recall:0.5043365379347544,f1:0.522709153577023,pre:0.5812353479497797
SC_L epoch 53 | train loss:0.6451725959777832,test loss:0.911186933517456,acc:0.662589156189555,recall:0.3581510263286056,f1:0.34602979923210414,pre:0.6308388123864371
SC_L epoch 54 | train loss:0.6435447335243225,test loss:0.749009370803833,acc:0.6872657761121856,recall:0.5184107339240743,f1:0.5212417919402437,pre:0.5517202880323853
SC_L epoch 55 | train loss:0.6490048170089722,test loss:0.7906944155693054,acc:0.6787279376208897,recall:0.5571375233138576,f1:0.5438499834738473,pre:0.5401303397487589
SC_L epoch 56 | train loss:0.6270295977592468,test loss:0.7718679904937744,acc:0.6797177224371374,recall:0.5438782698747129,f1:0.5362265990615102,pre:0.538966110016173
SC_L epoch 57 | train loss:0.6429764032363892,test loss:0.7718419432640076,acc:0.6858830996131527,recall:0.4197297288063611,f1:0.43650350955049927,pre:0.6323194004843575
SC_L epoch 58 | train loss:0.6325442790985107,test loss:0.7432908415794373,acc:0.6903711315280464,recall:0.5304553318613933,f1:0.5351144996324866,pre:0.5491044962920495
SC_L epoch 59 | train loss:0.6288136839866638,test loss:0.7357489466667175,acc:0.7003974250483559,recall:0.4971028168946426,f1:0.5157999031738923,pre:0.5718181044665485
SC_L epoch 60 | train loss:0.6293588876724243,test loss:0.7522449493408203,acc:0.698130742263056,recall:0.5084970781943501,f1:0.5213225456915614,pre:0.5732437776441796
SC_L epoch 61 | train loss:0.6284042596817017,test loss:0.7220253348350525,acc:0.6982894100580271,recall:0.5168517285279328,f1:0.5321056281801936,pre:0.5751611286137444
SC_L epoch 62 | train loss:0.6286669969558716,test loss:0.9086970686912537,acc:0.6021896155705997,recall:0.5154147432536346,f1:0.4804355725350351,pre:0.5280930180916197
SC_L epoch 63 | train loss:0.6178022623062134,test loss:0.7987326383590698,acc:0.667991416827853,recall:0.554512285333402,f1:0.5352627149565016,pre:0.5311105700598661
SC_L epoch 64 | train loss:0.6337714195251465,test loss:0.8535801768302917,acc:0.6274555730174082,recall:0.5680372869642389,f1:0.5246576910648504,pre:0.5182406779649361
SC_L epoch 65 | train loss:0.6158231496810913,test loss:0.7480709552764893,acc:0.6992338612185687,recall:0.5129293509270533,f1:0.5296253938882165,pre:0.5705072706822173
SC_L epoch 66 | train loss:0.6335074305534363,test loss:0.7368220686912537,acc:0.6919200314313346,recall:0.5369794251804285,f1:0.5411458242960074,pre:0.5558691087891823
SC_L epoch 67 | train loss:0.6263641715049744,test loss:0.7748153209686279,acc:0.6712856624758221,recall:0.5649821566650326,f1:0.5487445026709616,pre:0.5440034211414445
SC_L epoch 68 | train loss:0.6181001663208008,test loss:0.8561211824417114,acc:0.6202475217601547,recall:0.5551276602865638,f1:0.5129692698131795,pre:0.5159874607113571
SC_L epoch 69 | train loss:0.6160924434661865,test loss:0.7659286856651306,acc:0.6739905705996131,recall:0.5561510917833141,f1:0.5424745706428804,pre:0.5385533147852066
SC_L epoch 70 | train loss:0.6149890422821045,test loss:0.7572231292724609,acc:0.6774888176982592,recall:0.5551151792456871,f1:0.5424898894299736,pre:0.5378445445108758
SC_L epoch 71 | train loss:0.6120298504829407,test loss:0.819438636302948,acc:0.6414032277562862,recall:0.5637468124468749,f1:0.5265754362003393,pre:0.5208790946178047
SC_L epoch 72 | train loss:0.608289897441864,test loss:0.7546873688697815,acc:0.6820221832688589,recall:0.5291195828966223,f1:0.5278712806445761,pre:0.5340860222695906
SC_L epoch 73 | train loss:0.608992874622345,test loss:0.7637237906455994,acc:0.6756301378143134,recall:0.513247306104309,f1:0.5130800850244328,pre:0.53816219816069
SC_L epoch 74 | train loss:0.605664074420929,test loss:0.7363645434379578,acc:0.7030645551257254,recall:0.49757737188920587,f1:0.5174959664735777,pre:0.5754893070189107
SC_L epoch 75 | train loss:0.6047370433807373,test loss:0.7333168387413025,acc:0.6981987427466151,recall:0.5037925525277324,f1:0.519556876191864,pre:0.5628758756706247
SC_L epoch 76 | train loss:0.6049795150756836,test loss:0.7885563969612122,acc:0.6671074105415861,recall:0.5622278007544932,f1:0.5367082330890103,pre:0.5273613743372328
SC_L epoch 77 | train loss:0.6073378324508667,test loss:0.7978084683418274,acc:0.6578820116054159,recall:0.5394628884023989,f1:0.5229564533654815,pre:0.5218157308887796
SC_L epoch 78 | train loss:0.6101004481315613,test loss:0.765552818775177,acc:0.6880062258220504,recall:0.44202242667126385,f1:0.46100647966787867,pre:0.6013639621342575
SC_L epoch 79 | train loss:0.6165256500244141,test loss:0.7412340641021729,acc:0.695244499516441,recall:0.4904191678131143,f1:0.509402687141213,pre:0.5653056805269019
SC_L epoch 80 | train loss:0.6117084622383118,test loss:0.7417533993721008,acc:0.7004805367504835,recall:0.5152219025835946,f1:0.5313167248681964,pre:0.5771142578677046
SC_L epoch 81 | train loss:0.6130692362785339,test loss:0.9284583330154419,acc:0.5882117383945841,recall:0.562404170198587,f1:0.497993449424841,pre:0.5005790268059499
SC_L epoch 82 | train loss:0.6152987480163574,test loss:0.8569832444190979,acc:0.6173159453578337,recall:0.571800720182124,f1:0.5183371461467934,pre:0.5120450717248655
SC_L epoch 83 | train loss:0.6011465191841125,test loss:0.7429152131080627,acc:0.6938013781431335,recall:0.4715893727034632,f1:0.4915212907581649,pre:0.5770734338413267
SC_L epoch 84 | train loss:0.5943493247032166,test loss:0.7466455698013306,acc:0.7021201039651837,recall:0.5232313684515862,f1:0.5347666133695731,pre:0.564299384355777
SC_L epoch 85 | train loss:0.6026379466056824,test loss:0.7948206663131714,acc:0.6621055971953578,recall:0.5711562001279511,f1:0.5437248900929922,pre:0.5346318686727572
SC_L epoch 86 | train loss:0.590660572052002,test loss:0.7557201385498047,acc:0.6885502296905223,recall:0.542227581922069,f1:0.5406276783997284,pre:0.5501612209414105
SC_L epoch 87 | train loss:0.5926442742347717,test loss:0.9462552666664124,acc:0.5777925531914894,recall:0.5672294892657433,f1:0.49113278344179884,pre:0.4993063070974921
SC_L epoch 88 | train loss:0.6006773710250854,test loss:0.7463846802711487,acc:0.691156914893617,recall:0.5296861903822523,f1:0.5359447072268836,pre:0.557771811167145
SC_L epoch 89 | train loss:0.5879420042037964,test loss:0.8017093539237976,acc:0.6551846590909091,recall:0.5594080871276107,f1:0.5290124491433376,pre:0.5178541764179567
SC_L epoch 90 | train loss:0.6001211404800415,test loss:0.7429226040840149,acc:0.6942698259187622,recall:0.5025393928610511,f1:0.5198858171333545,pre:0.5715350630119295
SC_L epoch 91 | train loss:0.585721492767334,test loss:0.7789503335952759,acc:0.6816368471953579,recall:0.5379089831038378,f1:0.5337881244780572,pre:0.5424425619616757
SC_L epoch 92 | train loss:0.5988526344299316,test loss:0.7384287714958191,acc:0.6985689676015474,recall:0.5030051862753262,f1:0.5198661621548127,pre:0.565629310273469
SC_L epoch 93 | train loss:0.5898232460021973,test loss:0.7400499582290649,acc:0.6927813708897486,recall:0.5281243285475242,f1:0.5374983174307898,pre:0.5618625113696336
SC_L epoch 94 | train loss:0.5967336297035217,test loss:0.7591217160224915,acc:0.6936804883945841,recall:0.45198446060142256,f1:0.47486078994276865,pre:0.5911781192541258
SC_L epoch 95 | train loss:0.5836844444274902,test loss:0.7844038605690002,acc:0.6773377055125726,recall:0.5501908779467171,f1:0.5410032554085512,pre:0.5408996256833891
SC_L epoch 96 | train loss:0.5845370888710022,test loss:0.791501522064209,acc:0.6644402804642167,recall:0.563156841652275,f1:0.542124529101005,pre:0.5338638605497383
SC_L epoch 97 | train loss:0.5875256061553955,test loss:0.8828704953193665,acc:0.6164697171179884,recall:0.5714583539098289,f1:0.521167662328402,pre:0.5174838946038149
SC_L epoch 98 | train loss:0.5849784016609192,test loss:0.7387404441833496,acc:0.7028227756286267,recall:0.5020672241586093,f1:0.5233565002985501,pre:0.5888293809007437
SC_L epoch 99 | train loss:0.5934199690818787,test loss:0.8063258528709412,acc:0.6581615691489362,recall:0.5609759600790536,f1:0.5325895925431727,pre:0.5228877929301513
SC_L epoch 100 | train loss:0.5876505970954895,test loss:0.7699379324913025,acc:0.6780705996131529,recall:0.5569701461040099,f1:0.5444930889632239,pre:0.5410683094534026
SC_L epoch 101 | train loss:0.5859783887863159,test loss:0.7607783675193787,acc:0.6880137814313346,recall:0.5529291680954216,f1:0.5453790849791955,pre:0.5477966012563381
SC_L epoch 102 | train loss:0.594167172908783,test loss:0.7982918620109558,acc:0.6625438225338491,recall:0.5444666059465841,f1:0.5314874648346761,pre:0.5438125749394611
SC_L epoch 103 | train loss:0.5844576954841614,test loss:0.7936579585075378,acc:0.6734012330754352,recall:0.5585333554261599,f1:0.5414521639017359,pre:0.5386203016820506
SC_L epoch 104 | train loss:0.579562783241272,test loss:0.7300234436988831,acc:0.6974280705996132,recall:0.48620086680168123,f1:0.5060480442253175,pre:0.5846031974340786
SC_L epoch 105 | train loss:0.579620361328125,test loss:0.7414898872375488,acc:0.7005787596711799,recall:0.5280072324713735,f1:0.5388838272318899,pre:0.5743750420884403
epoch 105 : weight has update
SC_L epoch 106 | train loss:0.5753452777862549,test loss:0.8622703552246094,acc:0.6256271155705997,recall:0.5686611994770183,f1:0.5182375569538885,pre:0.5100617496179688
SC_L epoch 107 | train loss:0.5862374305725098,test loss:0.7552652955055237,acc:0.6889506769825919,recall:0.5483418482444643,f1:0.5482790029250929,pre:0.5552490778365103
SC_L epoch 108 | train loss:0.5837054252624512,test loss:0.8125665187835693,acc:0.6543006528046422,recall:0.570893263692062,f1:0.537998391584281,pre:0.5269205099649835
SC_L epoch 109 | train loss:0.5770449638366699,test loss:0.7487785220146179,acc:0.695380500483559,recall:0.5309655004880769,f1:0.5378410499781168,pre:0.5563706310805454
SC_L epoch 110 | train loss:0.5754136443138123,test loss:0.9139897227287292,acc:0.6130470261121856,recall:0.5630399618893063,f1:0.5104095950728008,pre:0.507493228153954
SC_L epoch 111 | train loss:0.5750936269760132,test loss:0.827681839466095,acc:0.6528575314313346,recall:0.5436516266516043,f1:0.5225107453108778,pre:0.5307464957011475
SC_L epoch 112 | train loss:0.5736022591590881,test loss:1.114741563796997,acc:0.5094898452611218,recall:0.5336176125091517,f1:0.4428899650306766,pre:0.4857674759686464
SC_L epoch 113 | train loss:0.576032817363739,test loss:0.7839129567146301,acc:0.68059417311412,recall:0.5570960782951572,f1:0.5436506818954794,pre:0.5393150293492011
SC_L epoch 114 | train loss:0.5739032030105591,test loss:0.7829238772392273,acc:0.6742021276595744,recall:0.5513175770685261,f1:0.5380164633530362,pre:0.5435104688499169
SC_L epoch 115 | train loss:0.5780542492866516,test loss:0.8269622325897217,acc:0.6430503505802708,recall:0.5729037302669129,f1:0.533709215241633,pre:0.5229791794343756
SC_L epoch 116 | train loss:0.5821301937103271,test loss:0.7548347115516663,acc:0.6952142770793037,recall:0.4577366556781924,f1:0.48204618392110965,pre:0.6271613370471099
SC_L epoch 117 | train loss:0.5780102014541626,test loss:0.836959719657898,acc:0.6510819632495165,recall:0.5643645703111139,f1:0.5349249744218114,pre:0.527445566371411
SC_L epoch 118 | train loss:0.5673015713691711,test loss:0.8194292783737183,acc:0.6697443181818181,recall:0.5608721605912148,f1:0.5431600647960073,pre:0.5368584033888286
SC_L epoch 119 | train loss:0.5699569582939148,test loss:1.9347916841506958,acc:0.3228587403288201,recall:0.45810300366246975,f1:0.2931978434653249,pre:0.47816820696347956
SC_L epoch 120 | train loss:0.582809567451477,test loss:0.7644177675247192,acc:0.7004049806576403,recall:0.49515945913332426,f1:0.5186591623437891,pre:0.5908943284549457
SC_L epoch 121 | train loss:0.5681320428848267,test loss:0.7879058122634888,acc:0.7053463491295937,recall:0.5067871518012399,f1:0.52815495852173,pre:0.5887028293530271
SC_L epoch 122 | train loss:0.5662859678268433,test loss:0.7614623308181763,acc:0.6875453336557059,recall:0.5575973493690549,f1:0.5478088927182755,pre:0.5460191077563005
SC_L epoch 123 | train loss:0.5673718452453613,test loss:0.9783017039299011,acc:0.5584955270793037,recall:0.5580962592799523,f1:0.4803549515613538,pre:0.4970672997843138
SC_L epoch 124 | train loss:0.570193886756897,test loss:0.8084464073181152,acc:0.6700918762088975,recall:0.5472371740406398,f1:0.5294171269963877,pre:0.5250394149705315
SC_L epoch 125 | train loss:0.5785147547721863,test loss:0.7633451819419861,acc:0.702807664410058,recall:0.5209395598113059,f1:0.5373529387170695,pre:0.5788775260962471
SC_L epoch 126 | train loss:0.5744040608406067,test loss:0.840196967124939,acc:0.643239240812379,recall:0.5657172675646156,f1:0.52900313176777,pre:0.5189261507927267
SC_L epoch 127 | train loss:0.5589560866355896,test loss:0.8812611699104309,acc:0.6263600096711799,recall:0.5695061645645008,f1:0.5228694270321523,pre:0.5152176068926052
SC_L epoch 128 | train loss:0.5788652896881104,test loss:0.748282253742218,acc:0.7008658728239845,recall:0.4840784732032611,f1:0.5070601120648591,pre:0.5961420378461848
SC_L epoch 129 | train loss:0.5649628043174744,test loss:0.7306014895439148,acc:0.7014552103481624,recall:0.5130871822338057,f1:0.5313822504051,pre:0.5801965610191971
SC_L epoch 130 | train loss:0.5717390775680542,test loss:0.748624324798584,acc:0.6915951402321083,recall:0.5326057583833423,f1:0.5383407310620472,pre:0.5574925668234644
SC_L epoch 131 | train loss:0.5897485613822937,test loss:1.0219755172729492,acc:0.5451296542553191,recall:0.5422669232567165,f1:0.4652611504781166,pre:0.49086714546031224
SC_L epoch 132 | train loss:0.5587390661239624,test loss:0.7841171622276306,acc:0.6829137451644101,recall:0.5514718848650538,f1:0.5400204214524871,pre:0.5421491448060227
SC_L epoch 133 | train loss:0.573681652545929,test loss:0.8886894583702087,acc:0.6079318786266925,recall:0.5574178478107031,f1:0.5057534248171517,pre:0.5044652568880257
SC_L epoch 134 | train loss:0.5671685338020325,test loss:0.8648343086242676,acc:0.6146185928433269,recall:0.5507772882401927,f1:0.5073855190871456,pre:0.5036069141257898
SC_L epoch 135 | train loss:0.5615121722221375,test loss:0.8451576828956604,acc:0.6765141441005803,recall:0.3882081518236012,f1:0.3922709143068381,pre:0.6481214993179026
SC_L epoch 136 | train loss:0.5774008631706238,test loss:0.7483214139938354,acc:0.6950858317214701,recall:0.47088269864504206,f1:0.4935872528860682,pre:0.5843697835246012
SC_L epoch 137 | train loss:0.5603430867195129,test loss:0.741693913936615,acc:0.7017045454545454,recall:0.5384034705087001,f1:0.5446390837871369,pre:0.5665279620182192
epoch 137 : weight has update
SC_L epoch 138 | train loss:0.5596715807914734,test loss:0.7560880780220032,acc:0.6842208655705996,recall:0.5530808380136045,f1:0.5460071317489377,pre:0.5466950436954814
SC_L epoch 139 | train loss:0.5591194033622742,test loss:0.8324213624000549,acc:0.6382298718568665,recall:0.5718315181981797,f1:0.5331410724321681,pre:0.5284509311710551
SC_L epoch 140 | train loss:0.5747091174125671,test loss:0.7740098237991333,acc:0.6986898573500967,recall:0.4800861115344427,f1:0.5052658515901725,pre:0.604318677347385
SC_L epoch 141 | train loss:0.5718786716461182,test loss:0.8152847290039062,acc:0.696015171663443,recall:0.45336251482103507,f1:0.47954199049352925,pre:0.6158201093366095
SC_L epoch 142 | train loss:0.5487143993377686,test loss:0.7283938527107239,acc:0.6998005319148937,recall:0.5363411271106324,f1:0.5444047094042068,pre:0.5643372062502381
SC_L epoch 143 | train loss:0.5636957883834839,test loss:0.8198052048683167,acc:0.6501601789168279,recall:0.5779939089426434,f1:0.5412387709558792,pre:0.5297388475358626
SC_L epoch 144 | train loss:0.566290020942688,test loss:0.7434839606285095,acc:0.6959773936170213,recall:0.5306398641139065,f1:0.5406998939161745,pre:0.5685800937001574
SC_L epoch 145 | train loss:0.5673674941062927,test loss:0.9685981273651123,acc:0.6754790256286267,recall:0.392423429811064,f1:0.3954402672144951,pre:0.6370068870417468
SC_L epoch 146 | train loss:0.5666239261627197,test loss:0.9798214435577393,acc:0.6689509792069632,recall:0.3771622699610594,f1:0.3758298290482668,pre:0.6383072711039446
SC_L epoch 147 | train loss:0.5646093487739563,test loss:1.081544280052185,acc:0.5105249637330754,recall:0.5385655796158044,f1:0.4448285838601785,pre:0.4889668659476974
SC_L epoch 148 | train loss:0.5742302536964417,test loss:1.0101431608200073,acc:0.5624168882978723,recall:0.5307250091211037,f1:0.47237358849440486,pre:0.500365344679746
SC_L epoch 149 | train loss:0.5690987706184387,test loss:0.7622300386428833,acc:0.7004049806576403,recall:0.47218949856390957,f1:0.49536442735358094,pre:0.5859984253082401
SC_L epoch 150 | train loss:0.5688677430152893,test loss:0.7701466083526611,acc:0.6795439434235977,recall:0.5510186949423735,f1:0.5388701925142695,pre:0.5341446233037719
training has finished used time : 4161.45056271553
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (16114, 18)
trait shape (1, 16114)
df shape (20087, 42195)
(5000, 32032) (11114, 32032)
train dataset already completed!
5000
test dataset already completed!
11114
SC_CLR epoch 1 | train loss:0.884625256061554,test loss:1.4216428995132446,acc:0.7572940387117761,recall:0.24827586206896549,f1:0.21383045164834028,pre:0.1880304062296682
epoch 1 : weight has update
SC_CLR epoch 2 | train loss:0.7922304272651672,test loss:1.1407464742660522,acc:0.7573313137063544,recall:0.2492337164750958,f1:0.21473308956686044,pre:0.18881049844574568
epoch 2 : weight has update
SC_CLR epoch 3 | train loss:0.7433435320854187,test loss:1.4968193769454956,acc:0.7572008512253307,recall:0.24827586206896554,f1:0.21387823127775366,pre:0.18802955907070049
SC_CLR epoch 4 | train loss:0.7074778079986572,test loss:0.849546492099762,acc:0.7618551425937974,recall:0.2629478141910666,f1:0.240756928162189,pre:0.315054613404867
epoch 4 : weight has update
SC_CLR epoch 5 | train loss:0.6759809255599976,test loss:1.0481946468353271,acc:0.7591764259379744,recall:0.2533278212074988,f1:0.2225185525816868,pre:0.23911986217240086
SC_CLR epoch 6 | train loss:0.6588362455368042,test loss:0.6907169818878174,acc:0.780047034265886,recall:0.3597373880851727,f1:0.36685979908369665,pre:0.428548078441363
epoch 6 : weight has update
SC_CLR epoch 7 | train loss:0.6356568336486816,test loss:0.6109905242919922,acc:0.794077681088701,recall:0.34924799785668786,f1:0.3330062935754863,pre:0.3379402332201043
SC_CLR epoch 8 | train loss:0.5968228578567505,test loss:0.6405497193336487,acc:0.8010142187161137,recall:0.38842731718820706,f1:0.36289405826874016,pre:0.4221793749118952
epoch 8 : weight has update
SC_CLR epoch 9 | train loss:0.5343079566955566,test loss:0.5883665084838867,acc:0.8149482894166125,recall:0.40346657776887246,f1:0.4304114180076344,pre:0.5828192054671975
epoch 9 : weight has update
SC_CLR epoch 10 | train loss:0.5092843174934387,test loss:0.5488335490226746,acc:0.8109564763608762,recall:0.4130442285332756,f1:0.4040593804038196,pre:0.491846608768956
SC_CLR epoch 11 | train loss:0.49851545691490173,test loss:0.5275216102600098,acc:0.8235249268054652,recall:0.41422446697798837,f1:0.452268535238525,pre:0.6045333078210049
epoch 11 : weight has update
SC_CLR epoch 12 | train loss:0.49493202567100525,test loss:0.5068261027336121,acc:0.8346142376924746,recall:0.46900257373375653,f1:0.4786873204537785,pre:0.5503412757438211
epoch 12 : weight has update
SC_CLR epoch 13 | train loss:0.47509583830833435,test loss:0.5945687890052795,acc:0.8019427049446974,recall:0.37437376562858354,f1:0.36779294694504583,pre:0.46824579202921907
SC_CLR epoch 14 | train loss:0.46337056159973145,test loss:0.5829282402992249,acc:0.8139757509217089,recall:0.4308183059335054,f1:0.4001749959196505,pre:0.5077778957329293
SC_CLR epoch 15 | train loss:0.47023528814315796,test loss:0.5486181378364563,acc:0.8178404901322923,recall:0.42514582743407137,f1:0.419720606897246,pre:0.5357746389080268
SC_CLR epoch 16 | train loss:0.47568708658218384,test loss:0.5096084475517273,acc:0.8305021280633269,recall:0.4604918912267497,f1:0.470899480693342,pre:0.5903086880776869
epoch 16 : weight has update
SC_CLR epoch 17 | train loss:0.4574403166770935,test loss:0.5125493407249451,acc:0.8271609330947733,recall:0.4580099628625155,f1:0.44165083978144587,pre:0.5579730093011643
SC_CLR epoch 18 | train loss:0.4508450925350189,test loss:0.4504201114177704,acc:0.8676229397093906,recall:0.5600631117488,f1:0.5631086120233021,pre:0.5825230020845188
epoch 18 : weight has update
SC_CLR epoch 19 | train loss:0.4415125250816345,test loss:0.5291839838027954,acc:0.8288823601171112,recall:0.442918317104917,f1:0.4582996884218547,pre:0.577269748831413
SC_CLR epoch 20 | train loss:0.4256850481033325,test loss:0.45383936166763306,acc:0.8570673389720235,recall:0.5190370450356772,f1:0.5361525055059505,pre:0.5899933969560437
SC_CLR epoch 21 | train loss:0.4370548725128174,test loss:0.49700674414634705,acc:0.8423555763391889,recall:0.4790626766323259,f1:0.5000918010222667,pre:0.5895715978408006
SC_CLR epoch 22 | train loss:0.4423661530017853,test loss:0.47513264417648315,acc:0.8555407585122533,recall:0.5269761752217765,f1:0.5286698151899604,pre:0.5852001417096095
SC_CLR epoch 23 | train loss:0.41792306303977966,test loss:0.44503289461135864,acc:0.8631889096725223,recall:0.5357349027875381,f1:0.5485211124919632,pre:0.6090954392647504
SC_CLR epoch 24 | train loss:0.4068789780139923,test loss:0.41041576862335205,acc:0.872512741270874,recall:0.5795754830451937,f1:0.5906429937573598,pre:0.6403488747793036
epoch 24 : weight has update
SC_CLR epoch 25 | train loss:0.40005189180374146,test loss:0.4091661870479584,acc:0.8752067067881154,recall:0.5737057710343254,f1:0.608283145738125,pre:0.7242705977720129
epoch 25 : weight has update
SC_CLR epoch 26 | train loss:0.4167271554470062,test loss:0.45736685395240784,acc:0.8554102960312298,recall:0.5315416303538366,f1:0.5533085456600738,pre:0.6490619335460464
SC_CLR epoch 27 | train loss:0.41631394624710083,test loss:0.42034661769866943,acc:0.8689207872478855,recall:0.5704679961430903,f1:0.5698028438931028,pre:0.595459225912406
SC_CLR epoch 28 | train loss:0.40508148074150085,test loss:0.46056661009788513,acc:0.8568691037735848,recall:0.5461055900167213,f1:0.5644636010797122,pre:0.6664116719690415
SC_CLR epoch 29 | train loss:0.4108123481273651,test loss:0.5166515707969666,acc:0.8380045678811537,recall:0.46603316846259746,f1:0.48724120156836254,pre:0.6093611368413868
SC_CLR epoch 30 | train loss:0.39625561237335205,test loss:0.43758729100227356,acc:0.8626721427022337,recall:0.534872760136465,f1:0.560822671972579,pre:0.6364662754198892
SC_CLR epoch 31 | train loss:0.3882824778556824,test loss:0.40285658836364746,acc:0.8742002819345044,recall:0.5710102395574964,f1:0.5747702700174805,pre:0.6004752870559832
SC_CLR epoch 32 | train loss:0.39067816734313965,test loss:0.44283750653266907,acc:0.8613065224463241,recall:0.5365610826111447,f1:0.5623195466712213,pre:0.6405482706191457
SC_CLR epoch 33 | train loss:0.38563650846481323,test loss:0.4995056092739105,acc:0.8405104641075688,recall:0.5032887981111229,f1:0.49798632318796604,pre:0.611303054982675
SC_CLR epoch 34 | train loss:0.3772376775741577,test loss:0.4120885133743286,acc:0.8760335339405769,recall:0.5847717118121005,f1:0.622765848720643,pre:0.7444827173858244
epoch 34 : weight has update
SC_CLR epoch 35 | train loss:0.37952280044555664,test loss:0.47351744771003723,acc:0.848697408371286,recall:0.5015398020004735,f1:0.5196990208696636,pre:0.6182008730990216
SC_CLR epoch 36 | train loss:0.3870755434036255,test loss:0.48894202709198,acc:0.8510813137063544,recall:0.5475625728101765,f1:0.5420794102063907,pre:0.619999798005207
SC_CLR epoch 37 | train loss:0.3790625333786011,test loss:0.4258451461791992,acc:0.8696425666883539,recall:0.5513449384634712,f1:0.5866138364842173,pre:0.6892955785035205
SC_CLR epoch 38 | train loss:0.3708801865577698,test loss:0.42118769884109497,acc:0.8700881723053567,recall:0.6329072950908569,f1:0.6369215745508163,pre:0.6831340194314479
SC_CLR epoch 39 | train loss:0.3721076250076294,test loss:0.41111138463020325,acc:0.8777210746042073,recall:0.6338741132687096,f1:0.6438936047752686,pre:0.6977918454418031
epoch 39 : weight has update
SC_CLR epoch 40 | train loss:0.37190133333206177,test loss:0.37428876757621765,acc:0.8849761440034699,recall:0.6154586174252279,f1:0.6379169076838502,pre:0.7246208297688798
epoch 40 : weight has update
SC_CLR epoch 41 | train loss:0.38820791244506836,test loss:0.3863091766834259,acc:0.8819755069399263,recall:0.6017325535296485,f1:0.6319107833745529,pre:0.7267885889347808
SC_CLR epoch 42 | train loss:0.36093488335609436,test loss:0.4243409037590027,acc:0.8706456029060942,recall:0.5965458802447771,f1:0.6181245132678921,pre:0.7251132321561915
SC_CLR epoch 43 | train loss:0.357068806886673,test loss:0.4028293490409851,acc:0.8833970396877033,recall:0.6629176977811921,f1:0.6753977286443882,pre:0.7248312428259396
epoch 43 : weight has update
SC_CLR epoch 44 | train loss:0.3714413046836853,test loss:0.3847322165966034,acc:0.886146917696812,recall:0.6200811454644384,f1:0.6501949281386444,pre:0.760051790207483
SC_CLR epoch 45 | train loss:0.37337610125541687,test loss:0.5022414326667786,acc:0.8458052076556061,recall:0.48370257500657093,f1:0.5378315701704958,pre:0.7165202533293785
SC_CLR epoch 46 | train loss:0.34991782903671265,test loss:0.44659942388534546,acc:0.8574604207330297,recall:0.6362643732248409,f1:0.6347337619692203,pre:0.6795015213733234
SC_CLR epoch 47 | train loss:0.362641304731369,test loss:0.45159056782722473,acc:0.8590022500542183,recall:0.5233649031565796,f1:0.5706622221154255,pre:0.712015854323828
SC_CLR epoch 48 | train loss:0.3536990284919739,test loss:0.5989791750907898,acc:0.8216645657124267,recall:0.46886246753846833,f1:0.43440745155092786,pre:0.5454546795068377
SC_CLR epoch 49 | train loss:0.3481864333152771,test loss:0.5056629180908203,acc:0.8539209905660378,recall:0.507298004764245,f1:0.5428388140104843,pre:0.6825546339751052
SC_CLR epoch 50 | train loss:0.3545152544975281,test loss:0.5196611881256104,acc:0.8445141373888528,recall:0.4886567558121407,f1:0.5014938448137599,pre:0.6133494071673181
SC_CLR epoch 51 | train loss:0.3526819944381714,test loss:0.5273215174674988,acc:0.837199766861852,recall:0.49757108887763063,f1:0.49090465991753535,pre:0.607068925738147
SC_CLR epoch 52 | train loss:0.3656734526157379,test loss:0.41353440284729004,acc:0.868449766861852,recall:0.5864656151455947,f1:0.601151450005296,pre:0.7153184675822353
SC_CLR epoch 53 | train loss:0.3486728370189667,test loss:0.4333326816558838,acc:0.8687445781826069,recall:0.5527064620881674,f1:0.589907414071675,pre:0.7049686468984158
SC_CLR epoch 54 | train loss:0.35439229011535645,test loss:0.4158658981323242,acc:0.8770026837996097,recall:0.6519498206803901,f1:0.6703570534459092,pre:0.7421523243697762
SC_CLR epoch 55 | train loss:0.34613919258117676,test loss:0.43788665533065796,acc:0.861265858815875,recall:0.5451871418607681,f1:0.572308761549479,pre:0.6862513098925634
SC_CLR epoch 56 | train loss:0.34561946988105774,test loss:0.377897709608078,acc:0.8870076312079809,recall:0.6533728115025111,f1:0.6781239253100455,pre:0.751995944493278
epoch 56 : weight has update
SC_CLR epoch 57 | train loss:0.345069020986557,test loss:0.387776643037796,acc:0.8868432823682497,recall:0.6276583796846238,f1:0.6575812660273155,pre:0.7608274136875234
SC_CLR epoch 58 | train loss:0.32847079634666443,test loss:0.5865875482559204,acc:0.8289907964649751,recall:0.4555508532760282,f1:0.4570102586669942,pre:0.5941403878200539
SC_CLR epoch 59 | train loss:0.3476450443267822,test loss:0.42963629961013794,acc:0.865201759379744,recall:0.568218918506977,f1:0.5885714189623847,pre:0.6992860955205233
SC_CLR epoch 60 | train loss:0.33091118931770325,test loss:0.40426474809646606,acc:0.8799694345044459,recall:0.6282410749699493,f1:0.6581616837315396,pre:0.7666620469673293
SC_CLR epoch 61 | train loss:0.34098753333091736,test loss:0.4784106910228729,acc:0.8580890126870527,recall:0.5136714645253789,f1:0.5365012641508192,pre:0.6073877116603296
SC_CLR epoch 62 | train loss:0.34655284881591797,test loss:0.37851062417030334,acc:0.8838121475818694,recall:0.6127511953602638,f1:0.6338869375781258,pre:0.7288838674494396
SC_CLR epoch 63 | train loss:0.32867318391799927,test loss:0.36571386456489563,acc:0.8918381316417263,recall:0.6467231018266633,f1:0.6757468764493836,pre:0.7659109681999475
epoch 63 : weight has update
SC_CLR epoch 64 | train loss:0.33091527223587036,test loss:0.4878825843334198,acc:0.8508119171546302,recall:0.5049406599617504,f1:0.5328094814884606,pre:0.6567813265902614
SC_CLR epoch 65 | train loss:0.3269701302051544,test loss:0.643229603767395,acc:0.8219339622641509,recall:0.43714255088156084,f1:0.4191428665065196,pre:0.5261345201098393
SC_CLR epoch 66 | train loss:0.326063871383667,test loss:0.3930608332157135,acc:0.880470952613316,recall:0.5989711791550326,f1:0.6325031230053376,pre:0.7482524735565335
SC_CLR epoch 67 | train loss:0.3265562355518341,test loss:0.4026465117931366,acc:0.8754913522012578,recall:0.5769659022926708,f1:0.6245907880703206,pre:0.7764739612737235
SC_CLR epoch 68 | train loss:0.32165399193763733,test loss:0.37465813755989075,acc:0.8867907585122533,recall:0.6377428214434915,f1:0.6661276102841546,pre:0.7611770083216308
SC_CLR epoch 69 | train loss:0.3319839835166931,test loss:0.5406951904296875,acc:0.839212616569074,recall:0.4726463469381194,f1:0.48240558284628215,pre:0.595652675270587
SC_CLR epoch 70 | train loss:0.31905028223991394,test loss:0.4063955843448639,acc:0.8790341710041205,recall:0.5876678389073592,f1:0.6410150621645684,pre:0.7915574688719241
SC_CLR epoch 71 | train loss:0.3302132189273834,test loss:0.4068225920200348,acc:0.8753490294946865,recall:0.5720768561342389,f1:0.6044276397155017,pre:0.7097804571426738
SC_CLR epoch 72 | train loss:0.3289346396923065,test loss:0.48637130856513977,acc:0.8529586179787465,recall:0.5269547986838548,f1:0.5765986887440078,pre:0.7641365440164176
SC_CLR epoch 73 | train loss:0.320392370223999,test loss:0.3765648901462555,acc:0.8869584959878551,recall:0.6207487810926852,f1:0.6571323045760523,pre:0.7701386630780569
SC_CLR epoch 74 | train loss:0.3203984200954437,test loss:0.5336679220199585,acc:0.8348124728909131,recall:0.6500384517666608,f1:0.6156179002783584,pre:0.6289016258412424
SC_CLR epoch 75 | train loss:0.3271995186805725,test loss:0.3941863477230072,acc:0.8791764937106918,recall:0.5971628719315467,f1:0.650298585030436,pre:0.7861955162925369
SC_CLR epoch 76 | train loss:0.3250332772731781,test loss:0.467238187789917,acc:0.862650116569074,recall:0.53183421265048,f1:0.572283893509949,pre:0.7018895999410115
SC_CLR epoch 77 | train loss:0.3193405270576477,test loss:0.421070396900177,acc:0.8712928323574062,recall:0.6014390586877434,f1:0.622548823781482,pre:0.7285155455423987
SC_CLR epoch 78 | train loss:0.33261269330978394,test loss:0.5383484363555908,acc:0.8469200688570809,recall:0.4956531836235193,f1:0.505311565179938,pre:0.6076843349816402
SC_CLR epoch 79 | train loss:0.3168626129627228,test loss:0.38399413228034973,acc:0.8857318098026459,recall:0.6236014528655193,f1:0.6672525515581773,pre:0.7858350504417141
SC_CLR epoch 80 | train loss:0.3174533247947693,test loss:0.4002428948879242,acc:0.879232406202559,recall:0.5987064235778079,f1:0.6230723960155492,pre:0.7276637714079564
SC_CLR epoch 81 | train loss:0.32530495524406433,test loss:0.4887244999408722,acc:0.8552899994578184,recall:0.5174830175966864,f1:0.550247680372597,pre:0.7128535922411914
SC_CLR epoch 82 | train loss:0.32662084698677063,test loss:0.38973310589790344,acc:0.8825176886792452,recall:0.6435918582731596,f1:0.6711022446446038,pre:0.7546243371339794
SC_CLR epoch 83 | train loss:0.3266056180000305,test loss:0.43973445892333984,acc:0.8634803323574062,recall:0.5488459361994409,f1:0.6011876059070717,pre:0.7557754580834741
SC_CLR epoch 84 | train loss:0.3191536068916321,test loss:0.4158938527107239,acc:0.8710200471698114,recall:0.5684301918041308,f1:0.6217633750871836,pre:0.7727661384481236
SC_CLR epoch 85 | train loss:0.3100423216819763,test loss:0.46283823251724243,acc:0.8599968146822815,recall:0.5287403453107655,f1:0.5698817125556705,pre:0.7085650126424758
SC_CLR epoch 86 | train loss:0.30431389808654785,test loss:0.4422336518764496,acc:0.869766251897636,recall:0.5693206819735062,f1:0.5952670629990018,pre:0.7112561614272176
SC_CLR epoch 87 | train loss:0.34442368149757385,test loss:0.4189135730266571,acc:0.8771297576447624,recall:0.5954053844677122,f1:0.6303633091717543,pre:0.7632204773509284
SC_CLR epoch 88 | train loss:0.32768237590789795,test loss:0.46255239844322205,acc:0.861916476903058,recall:0.5335397595860787,f1:0.5752451436893757,pre:0.7645788698283996
SC_CLR epoch 89 | train loss:0.3148082494735718,test loss:0.6061989068984985,acc:0.8352428296464975,recall:0.4628676113731515,f1:0.474636221746217,pre:0.5986031976390531
SC_CLR epoch 90 | train loss:0.30717965960502625,test loss:0.4027632772922516,acc:0.8800372072218607,recall:0.5878919441629153,f1:0.6217940008046019,pre:0.7238210856259271
SC_CLR epoch 91 | train loss:0.29569539427757263,test loss:0.3983593285083771,acc:0.8789070971589678,recall:0.5900596252517095,f1:0.6141410721640029,pre:0.7017478286854737
SC_CLR epoch 92 | train loss:0.3122592270374298,test loss:0.4728405475616455,acc:0.8585041205812188,recall:0.5254843365255705,f1:0.5443942605122843,pre:0.6421277017963491
SC_CLR epoch 93 | train loss:0.3160635530948639,test loss:0.4131711721420288,acc:0.8760487828019953,recall:0.6399819110509917,f1:0.6584680187457946,pre:0.7360589793047975
SC_CLR epoch 94 | train loss:0.30958274006843567,test loss:0.4386499226093292,acc:0.8733954809152028,recall:0.5807213128928437,f1:0.6149152926815723,pre:0.7433904473438249
SC_CLR epoch 95 | train loss:0.303790807723999,test loss:0.4097553491592407,acc:0.8775940007590544,recall:0.5988392174336874,f1:0.6579508661773383,pre:0.8181515772297174
SC_CLR epoch 96 | train loss:0.3100631535053253,test loss:0.36693960428237915,acc:0.8923769247451746,recall:0.6958993781459636,f1:0.7064006699517905,pre:0.7509434842963322
epoch 96 : weight has update
SC_CLR epoch 97 | train loss:0.3206421136856079,test loss:0.36524486541748047,acc:0.8912129283235741,recall:0.6757352417742833,f1:0.6998125405979561,pre:0.7742154384044494
SC_CLR epoch 98 | train loss:0.30719074606895447,test loss:0.4059348702430725,acc:0.8740359330947733,recall:0.6013830810449997,f1:0.6309737553075989,pre:0.7609926529258602
SC_CLR epoch 99 | train loss:0.33414965867996216,test loss:0.59437096118927,acc:0.8256496014964216,recall:0.4431821052549253,f1:0.438766074315901,pre:0.575821693044025
SC_CLR epoch 100 | train loss:0.3073081374168396,test loss:0.38956406712532043,acc:0.8865925233138148,recall:0.6111016406662775,f1:0.648773863876867,pre:0.7586659085746927
SC_CLR epoch 101 | train loss:0.2943657338619232,test loss:0.4307456612586975,acc:0.869078358815875,recall:0.5785196855141912,f1:0.594241170141783,pre:0.6911736770313731
SC_CLR epoch 102 | train loss:0.30350884795188904,test loss:0.4181160628795624,acc:0.8734480047711992,recall:0.5995594983266613,f1:0.6434356837029481,pre:0.7862044028146707
SC_CLR epoch 103 | train loss:0.31373727321624756,test loss:0.37360361218452454,acc:0.8880174446974626,recall:0.6217515892788029,f1:0.6663786113763418,pre:0.7755811430504395
SC_CLR epoch 104 | train loss:0.30567416548728943,test loss:0.47982674837112427,acc:0.8524689600954239,recall:0.5371606687958866,f1:0.5459771644308362,pre:0.6818417709419979
SC_CLR epoch 105 | train loss:0.3114185929298401,test loss:0.4084184467792511,acc:0.8743764909997831,recall:0.5760466265808647,f1:0.6244256704838695,pre:0.7647285654914924
SC_CLR epoch 106 | train loss:0.3019355535507202,test loss:0.4604991674423218,acc:0.8579280524831923,recall:0.5453895730225115,f1:0.575916543100047,pre:0.7199019295656436
SC_CLR epoch 107 | train loss:0.3106873035430908,test loss:0.4060561954975128,acc:0.8792662925612665,recall:0.6005960222203176,f1:0.6417139687561987,pre:0.7770577476976569
SC_CLR epoch 108 | train loss:0.30792394280433655,test loss:0.39822426438331604,acc:0.8750423579483844,recall:0.580542841164969,f1:0.6181798835469018,pre:0.7462600057565615
SC_CLR epoch 109 | train loss:0.29281532764434814,test loss:0.4086182713508606,acc:0.8761724680112774,recall:0.6501277532191345,f1:0.6551280084792452,pre:0.7218851356657673
SC_CLR epoch 110 | train loss:0.3111567497253418,test loss:0.39946794509887695,acc:0.8835766373888528,recall:0.6279109650056186,f1:0.6678040457287109,pre:0.7878493598100301
SC_CLR epoch 111 | train loss:0.3048222064971924,test loss:0.39324599504470825,acc:0.8858927700065062,recall:0.6392465876375288,f1:0.6740428216686268,pre:0.7823343546002568
SC_CLR epoch 112 | train loss:0.30456337332725525,test loss:0.40792950987815857,acc:0.8785631506180872,recall:0.5948367693295209,f1:0.6476372725619985,pre:0.7932449157919946
SC_CLR epoch 113 | train loss:0.3050157427787781,test loss:0.49474671483039856,acc:0.8484127629581435,recall:0.5040958998791014,f1:0.5470258339155057,pre:0.7278197034706961
SC_CLR epoch 114 | train loss:0.3071626126766205,test loss:0.3680969178676605,acc:0.8909587806332682,recall:0.6458801794073606,f1:0.6877918410108468,pre:0.7988219247595942
SC_CLR epoch 115 | train loss:0.30230197310447693,test loss:0.4615239202976227,acc:0.8701068098026459,recall:0.5876396555727155,f1:0.6094886108680964,pre:0.7363088197804505
SC_CLR epoch 116 | train loss:0.31051746010780334,test loss:0.38735291361808777,acc:0.8856047359574929,recall:0.6227837964933477,f1:0.6725838153252301,pre:0.8013793808683743
SC_CLR epoch 117 | train loss:0.29169392585754395,test loss:0.37256085872650146,acc:0.8910824658425504,recall:0.6370056134473819,f1:0.6755671899449995,pre:0.7807232367586825
SC_CLR epoch 118 | train loss:0.2868654727935791,test loss:0.37858346104621887,acc:0.8870601550639775,recall:0.6286912588853701,f1:0.6689872117169424,pre:0.7893023534582206
SC_CLR epoch 119 | train loss:0.30304375290870667,test loss:0.4555506706237793,acc:0.8627026404250704,recall:0.6724916765350257,f1:0.653225774649985,pre:0.6965173065262549
SC_CLR epoch 120 | train loss:0.3073883652687073,test loss:0.723063051700592,acc:0.8003042995011928,recall:0.3681948498648028,f1:0.36416291521749045,pre:0.4182097323985088
SC_CLR epoch 121 | train loss:0.3131018877029419,test loss:0.36524611711502075,acc:0.8922718770331816,recall:0.6548539571602442,f1:0.6889410656494211,pre:0.7916558006071289
SC_CLR epoch 122 | train loss:0.3044901490211487,test loss:0.3880806863307953,acc:0.8803066037735848,recall:0.6075159602361563,f1:0.6530395427056533,pre:0.791314108507469
SC_CLR epoch 123 | train loss:0.3095359802246094,test loss:0.40109801292419434,acc:0.8847999349381913,recall:0.6165040737374888,f1:0.6641310683873978,pre:0.7955415262638971
SC_CLR epoch 124 | train loss:0.3146809935569763,test loss:0.5036054849624634,acc:0.8532212372587291,recall:0.5234677089341746,f1:0.5550670124962965,pre:0.7003645876439617
SC_CLR epoch 125 | train loss:0.3128032982349396,test loss:0.4544127881526947,acc:0.8633193721535458,recall:0.5458278019652144,f1:0.590891589362966,pre:0.7427491494725972
SC_CLR epoch 126 | train loss:0.297226220369339,test loss:0.4002891480922699,acc:0.8781887063543701,recall:0.6338884655890188,f1:0.6557569212070559,pre:0.7590291353585557
SC_CLR epoch 127 | train loss:0.3032665550708771,test loss:0.42356228828430176,acc:0.8687750759054436,recall:0.6317935724938837,f1:0.6451583453666658,pre:0.7464079731553821
SC_CLR epoch 128 | train loss:0.29370397329330444,test loss:0.3736901879310608,acc:0.8890543672739103,recall:0.6404985934881527,f1:0.6891985385935537,pre:0.8099694326364336
SC_CLR epoch 129 | train loss:0.30747830867767334,test loss:0.4034585654735565,acc:0.8852116541964866,recall:0.6329278568481764,f1:0.671569274190818,pre:0.7909661472744065
SC_CLR epoch 130 | train loss:0.29663437604904175,test loss:0.47770893573760986,acc:0.8641733083929733,recall:0.5439195473939118,f1:0.5984132877675671,pre:0.7649052243907818
SC_CLR epoch 131 | train loss:0.28865495324134827,test loss:0.4553823471069336,acc:0.8739495228800694,recall:0.5862340582114246,f1:0.6334300802383451,pre:0.7700552529569711
SC_CLR epoch 132 | train loss:0.30100172758102417,test loss:0.3708321154117584,acc:0.8902031148340924,recall:0.6378492791770384,f1:0.6603345264718861,pre:0.7589400361985585
SC_CLR epoch 133 | train loss:0.3054420053958893,test loss:0.3616337478160858,acc:0.8912281771849924,recall:0.6692712793736905,f1:0.6898127725664152,pre:0.7608083310360612
SC_CLR epoch 134 | train loss:0.30204543471336365,test loss:0.38642680644989014,acc:0.887673498156582,recall:0.6737554898227374,f1:0.6965153023732126,pre:0.7509532485048722
SC_CLR epoch 135 | train loss:0.2936825156211853,test loss:0.3879694938659668,acc:0.885353976903058,recall:0.6615348302228199,f1:0.6813895870974858,pre:0.7674879472276892
SC_CLR epoch 136 | train loss:0.30293533205986023,test loss:0.37723860144615173,acc:0.8819788955757969,recall:0.6349883314600625,f1:0.6742474809661416,pre:0.7659486682962486
SC_CLR epoch 137 | train loss:0.30273470282554626,test loss:0.42542022466659546,acc:0.88003381858599,recall:0.602922695540313,f1:0.6377729798203593,pre:0.7548139529517777
SC_CLR epoch 138 | train loss:0.2953750491142273,test loss:0.3899551331996918,acc:0.8856606484493601,recall:0.6196914733811785,f1:0.6674504193058495,pre:0.7931614819094813
SC_CLR epoch 139 | train loss:0.2943463623523712,test loss:0.36690980195999146,acc:0.888388500325309,recall:0.6473441245524165,f1:0.6920527583669472,pre:0.8016141269510964
SC_CLR epoch 140 | train loss:0.2883756756782532,test loss:0.40521836280822754,acc:0.8788664335285187,recall:0.6756208133513308,f1:0.6821563307477173,pre:0.72288257838
SC_CLR epoch 141 | train loss:0.2954149842262268,test loss:0.44629016518592834,acc:0.8557322164389504,recall:0.5386395318750946,f1:0.5962843343738844,pre:0.8038854323079418
SC_CLR epoch 142 | train loss:0.2940483093261719,test loss:0.39022043347358704,acc:0.8822482921275211,recall:0.6162366571870832,f1:0.662214969314807,pre:0.7851276322236903
SC_CLR epoch 143 | train loss:0.299390584230423,test loss:0.40760448575019836,acc:0.8798237231620039,recall:0.5987417688681553,f1:0.6400405422136054,pre:0.7628669852020904
SC_CLR epoch 144 | train loss:0.28801780939102173,test loss:0.9846805334091187,acc:0.6589202450661462,recall:0.5356517758144739,f1:0.41522487633527255,pre:0.48701369461370075
SC_CLR epoch 145 | train loss:0.29418379068374634,test loss:0.39584726095199585,acc:0.88445259976144,recall:0.6182860630242456,f1:0.6628053264803677,pre:0.7894846839452432
SC_CLR epoch 146 | train loss:0.3021288514137268,test loss:0.4076539874076843,acc:0.8748847863803946,recall:0.5794591134952674,f1:0.6395606106772801,pre:0.7923179786023099
SC_CLR epoch 147 | train loss:0.29693087935447693,test loss:0.5253804922103882,acc:0.8385094746258946,recall:0.4707607656893033,f1:0.5223472661204115,pre:0.724691695441986
SC_CLR epoch 148 | train loss:0.2941257655620575,test loss:0.44094154238700867,acc:0.8720789958794188,recall:0.5880938302984112,f1:0.639778050161899,pre:0.7683253248080274
SC_CLR epoch 149 | train loss:0.29508599638938904,test loss:0.4329470098018646,acc:0.8709895494469747,recall:0.5984836424507288,f1:0.6257355625647198,pre:0.7509192156709797
SC_CLR epoch 150 | train loss:0.28579071164131165,test loss:0.3636550307273865,acc:0.8938357324875298,recall:0.6810002867976972,f1:0.7064901161710304,pre:0.7790232292946521
epoch 150 : weight has update
training has finished used time : 3649.7706100940704
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (11114, 18)
trait shape (1, 11114)
df shape (20087, 42195)
(5000, 32032) (6114, 32032)
train dataset already completed!
5000
test dataset already completed!
6114
Stem term epoch 1 | train loss:1.5727342367172241,test loss:1.8213832378387451,acc:0.27334117240646255,recall:0.19979924067832414,f1:0.08592993158943522,pre:0.058933460605370754
epoch 1 : weight has update
Stem term epoch 2 | train loss:1.2792139053344727,test loss:2.2631540298461914,acc:0.2757095025510204,recall:0.20137642995918295,f1:0.08853930040217517,pre:0.10901010188086606
epoch 2 : weight has update
Stem term epoch 3 | train loss:1.1786177158355713,test loss:1.2170921564102173,acc:0.529296875,recall:0.35395336755952195,f1:0.3039900624177737,pre:0.37323302292090127
epoch 3 : weight has update
Stem term epoch 4 | train loss:1.156857967376709,test loss:1.1935068368911743,acc:0.5083273543792517,recall:0.35872488027303323,f1:0.31642303824456924,pre:0.42250759947738176
epoch 4 : weight has update
Stem term epoch 5 | train loss:1.1427114009857178,test loss:1.1594445705413818,acc:0.5522925967261905,recall:0.3752824814592209,f1:0.3371431586111269,pre:0.3156928679562903
Stem term epoch 6 | train loss:1.1437987089157104,test loss:1.1727666854858398,acc:0.4984454719387755,recall:0.4606397282369899,f1:0.4398866577475402,pre:0.5209646441288837
epoch 6 : weight has update
Stem term epoch 7 | train loss:1.1230597496032715,test loss:1.0714240074157715,acc:0.5854093590561225,recall:0.4850530205923191,f1:0.48535632977866844,pre:0.5522879804779136
epoch 7 : weight has update
Stem term epoch 8 | train loss:1.1000102758407593,test loss:1.0827643871307373,acc:0.5698375053146258,recall:0.4576006756842333,f1:0.4535176517372607,pre:0.5506690783585121
Stem term epoch 9 | train loss:1.0848699808120728,test loss:1.0324771404266357,acc:0.5872495482568028,recall:0.48021211472086756,f1:0.48681813792671275,pre:0.5683463802056707
epoch 9 : weight has update
Stem term epoch 10 | train loss:1.059924602508545,test loss:1.1830475330352783,acc:0.5110411352040817,recall:0.3396965915895751,f1:0.2730641974485361,pre:0.35477961086967014
Stem term epoch 11 | train loss:1.0506086349487305,test loss:1.0952513217926025,acc:0.5528340242346939,recall:0.413635993742338,f1:0.37287007594330496,pre:0.477804876982084
Stem term epoch 12 | train loss:1.0480197668075562,test loss:1.1066644191741943,acc:0.5723254145408163,recall:0.4498376412364,f1:0.44398554213537644,pre:0.5645457369816611
Stem term epoch 13 | train loss:1.0421864986419678,test loss:1.086596965789795,acc:0.556726987670068,recall:0.39660836147331197,f1:0.36564757003601506,pre:0.5268808546678503
Stem term epoch 14 | train loss:1.0417810678482056,test loss:1.0124036073684692,acc:0.5922220450680272,recall:0.5281602848339032,f1:0.5059149489428608,pre:0.5339819432117451
epoch 14 : weight has update
Stem term epoch 15 | train loss:1.0338796377182007,test loss:1.0380455255508423,acc:0.5807756696428571,recall:0.4495854806623773,f1:0.43797116066428593,pre:0.5623767618674169
Stem term epoch 16 | train loss:1.0244128704071045,test loss:1.1168805360794067,acc:0.5793872236394558,recall:0.46792281721191825,f1:0.4374099160779344,pre:0.5591092041727348
Stem term epoch 17 | train loss:1.0153967142105103,test loss:1.0628962516784668,acc:0.5956998033588435,recall:0.48842760805950364,f1:0.48762143162427507,pre:0.5863330874464204
Stem term epoch 18 | train loss:1.0222575664520264,test loss:1.144555687904358,acc:0.553408668154762,recall:0.5159231422518104,f1:0.46220875316406396,pre:0.49461057329067953
Stem term epoch 19 | train loss:1.0158733129501343,test loss:1.0265873670578003,acc:0.5966398278061225,recall:0.5008844773311749,f1:0.5088053375756149,pre:0.5648289795260936
epoch 19 : weight has update
Stem term epoch 20 | train loss:1.0095088481903076,test loss:1.1107730865478516,acc:0.569033668154762,recall:0.4376971928144389,f1:0.42214630766683,pre:0.5825679105941824
Stem term epoch 21 | train loss:0.9972085356712341,test loss:1.004194736480713,acc:0.5996824511054422,recall:0.5102055855971194,f1:0.5200566410341475,pre:0.5838677437266994
epoch 21 : weight has update
Stem term epoch 22 | train loss:0.9862260222434998,test loss:0.9972132444381714,acc:0.5886147427721088,recall:0.46099042277016217,f1:0.45589321142557787,pre:0.5775839792031264
Stem term epoch 23 | train loss:0.988618791103363,test loss:1.0237596035003662,acc:0.5906176923894558,recall:0.46870988990445595,f1:0.4628303931580613,pre:0.571745873490974
Stem term epoch 24 | train loss:0.9820655584335327,test loss:0.9935032725334167,acc:0.6011705463435374,recall:0.5349950893557355,f1:0.5249916749447252,pre:0.5582636425409863
epoch 24 : weight has update
Stem term epoch 25 | train loss:0.968427300453186,test loss:1.067468523979187,acc:0.5818784545068028,recall:0.540615465299263,f1:0.5211631733545368,pre:0.5408106177369877
Stem term epoch 26 | train loss:0.9698904156684875,test loss:0.9849449992179871,acc:0.6053159545068028,recall:0.5112625594228783,f1:0.5052401054054788,pre:0.5676074653945161
Stem term epoch 27 | train loss:0.9490149021148682,test loss:1.0388891696929932,acc:0.5950255102040817,recall:0.5558543034102094,f1:0.5296570419472127,pre:0.5397952306382406
epoch 27 : weight has update
Stem term epoch 28 | train loss:0.9507091641426086,test loss:0.9733304977416992,acc:0.6146065848214286,recall:0.5279795155733227,f1:0.5305114933577445,pre:0.5847324436227633
epoch 28 : weight has update
Stem term epoch 29 | train loss:0.957804262638092,test loss:0.9958080053329468,acc:0.6079466943027211,recall:0.5405534528033624,f1:0.5403018132262597,pre:0.5685944681123417
Stem term epoch 30 | train loss:0.9403862953186035,test loss:0.9721447825431824,acc:0.6097968484268708,recall:0.5336804929298341,f1:0.5320964867552002,pre:0.5792578650390238
Stem term epoch 31 | train loss:0.9323272705078125,test loss:0.9879118204116821,acc:0.6035887011054422,recall:0.506660671714222,f1:0.5110437703382272,pre:0.5876853442110203
Stem term epoch 32 | train loss:0.9356211423873901,test loss:0.994779109954834,acc:0.6098998193027211,recall:0.5586343196900555,f1:0.5261038878864818,pre:0.5566822681997242
Stem term epoch 33 | train loss:0.9328521490097046,test loss:0.976170539855957,acc:0.6129158694727891,recall:0.5456531064001419,f1:0.5282166018989602,pre:0.5682326463249056
Stem term epoch 34 | train loss:0.9310555458068848,test loss:0.9707416296005249,acc:0.6111753295068028,recall:0.5269446038152921,f1:0.5311364182325142,pre:0.5840197134251233
Stem term epoch 35 | train loss:0.9417018294334412,test loss:0.9904605746269226,acc:0.6119758450255102,recall:0.5396783543465774,f1:0.5403857084231015,pre:0.5697611030883857
epoch 35 : weight has update
Stem term epoch 36 | train loss:0.9248775839805603,test loss:0.9603108763694763,acc:0.6127663956207483,recall:0.5045865971810877,f1:0.510464068001326,pre:0.6006075598658115
Stem term epoch 37 | train loss:0.9126246571540833,test loss:0.9784064292907715,acc:0.5995828018707483,recall:0.524769839691963,f1:0.5299090538021631,pre:0.5684031975370513
Stem term epoch 38 | train loss:0.9218935966491699,test loss:1.015378713607788,acc:0.6021869685374149,recall:0.5581858552425518,f1:0.5140935447936906,pre:0.5470160174020445
Stem term epoch 39 | train loss:0.9279057383537292,test loss:0.9670974016189575,acc:0.6156429368622449,recall:0.5642870436198401,f1:0.562729334453092,pre:0.5840825371997439
epoch 39 : weight has update
Stem term epoch 40 | train loss:0.9010194540023804,test loss:0.9677013754844666,acc:0.6128527582908163,recall:0.5358235524195365,f1:0.5347693761671511,pre:0.5784681948406203
Stem term epoch 41 | train loss:0.9040197134017944,test loss:0.9606006145477295,acc:0.6173469387755102,recall:0.5482673807338309,f1:0.5571724941537998,pre:0.6005183030526743
Stem term epoch 42 | train loss:0.9119680523872375,test loss:1.0021629333496094,acc:0.60915909332483,recall:0.5419445862491798,f1:0.5216682927641169,pre:0.5830005743928266
Stem term epoch 43 | train loss:0.8951596021652222,test loss:0.974429726600647,acc:0.6162939785289115,recall:0.5534501703889939,f1:0.5502221231567247,pre:0.5856217827897886
Stem term epoch 44 | train loss:0.9153984189033508,test loss:0.9711591005325317,acc:0.6152941645408163,recall:0.5378317384959699,f1:0.544308029465607,pre:0.5848076615302517
Stem term epoch 45 | train loss:0.894718587398529,test loss:0.9751806259155273,acc:0.5970018866921768,recall:0.524131405047556,f1:0.5320283769032229,pre:0.5701217004031263
Stem term epoch 46 | train loss:0.8892922401428223,test loss:0.9483391046524048,acc:0.6217780080782312,recall:0.5576609290520111,f1:0.556629064131652,pre:0.5854955517250429
Stem term epoch 47 | train loss:0.8848786354064941,test loss:0.9830106496810913,acc:0.6118496226615646,recall:0.5614268381429403,f1:0.5527351882357369,pre:0.5785313039727321
Stem term epoch 48 | train loss:0.8867245316505432,test loss:0.9474399089813232,acc:0.6216418207908163,recall:0.5601340086035306,f1:0.5587549541017726,pre:0.5895543721390948
epoch 48 : weight has update
Stem term epoch 49 | train loss:0.8991063833236694,test loss:0.9744240045547485,acc:0.612125318877551,recall:0.5618015043510137,f1:0.55250858391758,pre:0.5893331468447666
Stem term epoch 50 | train loss:0.8759146332740784,test loss:0.9458785057067871,acc:0.6213794111394558,recall:0.5560027341723945,f1:0.5534031188360474,pre:0.5839323141094743
Stem term epoch 51 | train loss:0.8774582147598267,test loss:0.9658083319664001,acc:0.6137662096088435,recall:0.5631745739205741,f1:0.5614743335874597,pre:0.5855415084320229
Stem term epoch 52 | train loss:0.8739571571350098,test loss:0.9643396735191345,acc:0.6144039647108843,recall:0.5585966129088576,f1:0.5528471698857975,pre:0.5812793441110418
Stem term epoch 53 | train loss:0.8678547143936157,test loss:0.9634131193161011,acc:0.6148191698554422,recall:0.5466577130895397,f1:0.5544303507236771,pre:0.5898340560471006
Stem term epoch 54 | train loss:0.8704783320426941,test loss:0.9675227999687195,acc:0.618472975127551,recall:0.5528518864927425,f1:0.555389188336117,pre:0.5810737437031441
Stem term epoch 55 | train loss:0.8682031035423279,test loss:0.9647893309593201,acc:0.6208147321428571,recall:0.5439600312094137,f1:0.5393339178066773,pre:0.5875026986655606
Stem term epoch 56 | train loss:0.8619480729103088,test loss:0.9932079315185547,acc:0.6055418261054422,recall:0.5481791203203015,f1:0.5394516601491252,pre:0.5615321775573971
Stem term epoch 57 | train loss:0.8634860515594482,test loss:0.9561969041824341,acc:0.6159319196428571,recall:0.527042261081187,f1:0.5342258044144422,pre:0.5904333767806328
Stem term epoch 58 | train loss:0.8655941486358643,test loss:0.9465422630310059,acc:0.6219308035714286,recall:0.5419897732556078,f1:0.5480443661061447,pre:0.5960998577627926
Stem term epoch 59 | train loss:0.8500387668609619,test loss:0.9590336680412292,acc:0.6135669111394558,recall:0.555828487592363,f1:0.5563060936265786,pre:0.5848432190511441
Stem term epoch 60 | train loss:0.8612000942230225,test loss:0.9559222459793091,acc:0.6179614423894558,recall:0.5337216153508648,f1:0.5363448879046485,pre:0.596847326546734
Stem term epoch 61 | train loss:0.8549473285675049,test loss:0.9531610012054443,acc:0.6166593590561225,recall:0.5302368565541938,f1:0.5375101160802135,pre:0.5866816939290022
Stem term epoch 62 | train loss:0.8553724884986877,test loss:0.9498536586761475,acc:0.6144039647108843,recall:0.5192713832870862,f1:0.5235741305235834,pre:0.587159120448013
Stem term epoch 63 | train loss:0.8490217328071594,test loss:0.956619143486023,acc:0.6256477200255102,recall:0.5761102782405788,f1:0.571511623124466,pre:0.5910537749773246
epoch 63 : weight has update
Stem term epoch 64 | train loss:0.8511927723884583,test loss:0.972527265548706,acc:0.6121651785714286,recall:0.5233828731533042,f1:0.5279214969756736,pre:0.5812820837369379
Stem term epoch 65 | train loss:0.8601574301719666,test loss:0.9644061923027039,acc:0.6175728103741497,recall:0.5592034767883473,f1:0.5496083217672217,pre:0.5768402429221365
Stem term epoch 66 | train loss:0.849696159362793,test loss:0.9534084796905518,acc:0.6168453709608843,recall:0.5520273669393321,f1:0.544571458898561,pre:0.5772713511958046
Stem term epoch 67 | train loss:0.8635757565498352,test loss:0.9688164591789246,acc:0.6208512701955783,recall:0.5423235179882044,f1:0.5397307157908527,pre:0.5862164509461245
Stem term epoch 68 | train loss:0.851266622543335,test loss:0.9651689529418945,acc:0.6176857461734694,recall:0.5468401135325945,f1:0.557370344193365,pre:0.5918327897231743
Stem term epoch 69 | train loss:0.8520542979240417,test loss:0.9516502618789673,acc:0.6167224702380952,recall:0.5532722335195063,f1:0.5551428864602262,pre:0.5885107122118393
Stem term epoch 70 | train loss:0.8451831340789795,test loss:0.9640982151031494,acc:0.6090959821428571,recall:0.5316493154229014,f1:0.5260314689126401,pre:0.5866163068598712
Stem term epoch 71 | train loss:0.8611724972724915,test loss:0.9670051336288452,acc:0.6137927827380952,recall:0.5278721321950575,f1:0.5394300012878362,pre:0.5995765925246085
Stem term epoch 72 | train loss:0.8462830781936646,test loss:0.9609712958335876,acc:0.610308381164966,recall:0.5183439048272834,f1:0.5303372682678341,pre:0.6041228012580693
Stem term epoch 73 | train loss:0.842175304889679,test loss:0.9552802443504333,acc:0.6192502391581632,recall:0.532359740847678,f1:0.5352542702913304,pre:0.5937776246941335
Stem term epoch 74 | train loss:0.8436891436576843,test loss:0.950809121131897,acc:0.6178850446428571,recall:0.5646475317775023,f1:0.5570762920195188,pre:0.5843852682382832
Stem term epoch 75 | train loss:0.8381096124649048,test loss:0.9446808099746704,acc:0.6265977093962585,recall:0.5445651510233865,f1:0.5482736062853756,pre:0.5951029148166106
Stem term epoch 76 | train loss:0.8455676436424255,test loss:0.9553494453430176,acc:0.6122150031887755,recall:0.5379768240195623,f1:0.5456845584192259,pre:0.579370982377562
Stem term epoch 77 | train loss:0.838036060333252,test loss:0.9680055379867554,acc:0.6138160342261905,recall:0.5198400601667533,f1:0.5329265549929915,pre:0.5987489489314373
Stem term epoch 78 | train loss:0.8330538868904114,test loss:0.9423331618309021,acc:0.6194893973214286,recall:0.5558587061051314,f1:0.5580368916077791,pre:0.5962745545958201
Stem term epoch 79 | train loss:0.8378322124481201,test loss:0.9522111415863037,acc:0.6145567602040817,recall:0.5589843218297885,f1:0.5593048036155006,pre:0.5843290961311938
Stem term epoch 80 | train loss:0.8338969349861145,test loss:0.9461456537246704,acc:0.6252491230867346,recall:0.5612501147928363,f1:0.5569147246228052,pre:0.5859663138512631
Stem term epoch 81 | train loss:0.8381387591362,test loss:0.9597636461257935,acc:0.6172838275935374,recall:0.5673784724878951,f1:0.555735704081118,pre:0.5689312123024077
Stem term epoch 82 | train loss:0.8302994966506958,test loss:0.9679645299911499,acc:0.61550674957483,recall:0.550129704475436,f1:0.5564125947572404,pre:0.5950278797504008
Stem term epoch 83 | train loss:0.8387694954872131,test loss:0.9436930418014526,acc:0.616885230654762,recall:0.5564553036623088,f1:0.5572439111025305,pre:0.5836681331596277
Stem term epoch 84 | train loss:0.8383875489234924,test loss:0.9440783858299255,acc:0.6260994632227891,recall:0.553446817063311,f1:0.5620890328394138,pre:0.6080278257649531
Stem term epoch 85 | train loss:0.8189391493797302,test loss:0.9454793930053711,acc:0.6247708067602041,recall:0.545064540937254,f1:0.5525563200098002,pre:0.5980490229114159
Stem term epoch 86 | train loss:0.8155989646911621,test loss:0.9479414820671082,acc:0.6208014455782312,recall:0.5487597897046486,f1:0.5492539493528855,pre:0.5836737620407371
Stem term epoch 87 | train loss:0.8305788636207581,test loss:0.9418785572052002,acc:0.6194628241921768,recall:0.5431352501826582,f1:0.5435589296030369,pre:0.5938092957093358
Stem term epoch 88 | train loss:0.8268858194351196,test loss:0.9688693284988403,acc:0.6051299426020408,recall:0.5330928686235501,f1:0.5437345177666645,pre:0.5932640298959297
Stem term epoch 89 | train loss:0.8184055685997009,test loss:0.9468905925750732,acc:0.61501846832483,recall:0.5359256520269674,f1:0.5376760539355764,pre:0.5776753708900147
Stem term epoch 90 | train loss:0.8232786059379578,test loss:0.9571248888969421,acc:0.6206519717261905,recall:0.5453579204267506,f1:0.5383082438462071,pre:0.5759333951586455
Stem term epoch 91 | train loss:0.8251317739486694,test loss:0.9446133971214294,acc:0.6265744579081632,recall:0.5588456032519218,f1:0.5612791156747332,pre:0.5955457024981641
Stem term epoch 92 | train loss:0.8151511549949646,test loss:0.9592872858047485,acc:0.6169948448129251,recall:0.5383392539853594,f1:0.5397517753681885,pre:0.5765334537050766
Stem term epoch 93 | train loss:0.8207786083221436,test loss:0.9406344890594482,acc:0.6251959768282312,recall:0.5624967199308121,f1:0.5641203272444092,pre:0.5970241880277468
Stem term epoch 94 | train loss:0.8045197129249573,test loss:0.967364490032196,acc:0.6108498086734694,recall:0.5474631536934657,f1:0.5455565342759586,pre:0.5776767608715443
Stem term epoch 95 | train loss:0.8204017281532288,test loss:0.9526538252830505,acc:0.6219540550595238,recall:0.5570596752694587,f1:0.5593116704540662,pre:0.5959718098566044
Stem term epoch 96 | train loss:0.808270275592804,test loss:0.979268491268158,acc:0.6180212319302721,recall:0.534636123173219,f1:0.5390104105370241,pre:0.5948809378472818
Stem term epoch 97 | train loss:0.8045070171356201,test loss:0.9662295579910278,acc:0.6279130792942177,recall:0.552276354963346,f1:0.559418684559984,pre:0.6104129307377769
Stem term epoch 98 | train loss:0.7993423342704773,test loss:0.9706689715385437,acc:0.608757174744898,recall:0.5398093362019973,f1:0.5483913867319457,pre:0.5914128271513662
Stem term epoch 99 | train loss:0.8229276537895203,test loss:0.9644752740859985,acc:0.6187486713435374,recall:0.5377424636217009,f1:0.5462420616399626,pre:0.5884660095653512
Stem term epoch 100 | train loss:0.8107170462608337,test loss:0.9581762552261353,acc:0.616885230654762,recall:0.5354147236889115,f1:0.5379993924976383,pre:0.5968986350453204
Stem term epoch 101 | train loss:0.8167821764945984,test loss:0.9558678865432739,acc:0.6167722948554422,recall:0.5347654492702777,f1:0.5329559476610259,pre:0.5746921238442265
Stem term epoch 102 | train loss:0.8213578462600708,test loss:1.011382818222046,acc:0.6194395727040817,recall:0.5645950822462198,f1:0.554688829812653,pre:0.5841205401802333
Stem term epoch 103 | train loss:0.8021030426025391,test loss:0.9514145851135254,acc:0.6152675914115646,recall:0.5612295794810589,f1:0.5656001272904277,pre:0.5960434372259095
Stem term epoch 104 | train loss:0.8072054982185364,test loss:0.9490994811058044,acc:0.6184264721513605,recall:0.5477333348560728,f1:0.5522033038605361,pre:0.5851991318597815
Stem term epoch 105 | train loss:0.8133403658866882,test loss:0.948316752910614,acc:0.6233458227040817,recall:0.5461793589348041,f1:0.5477438264799472,pre:0.5964518109759486
Stem term epoch 106 | train loss:0.808942437171936,test loss:0.9803411364555359,acc:0.6144703975340137,recall:0.5691548781818557,f1:0.5599102702330921,pre:0.5755221543317717
Stem term epoch 107 | train loss:0.8188592791557312,test loss:0.9789969325065613,acc:0.6155831473214286,recall:0.5518037714908016,f1:0.5430840753179631,pre:0.5737402568190376
Stem term epoch 108 | train loss:0.811381459236145,test loss:0.959248960018158,acc:0.6143308886054422,recall:0.5517078813177799,f1:0.5513133322777453,pre:0.5890832556136854
Stem term epoch 109 | train loss:0.8035510182380676,test loss:0.9391670227050781,acc:0.6271524234693878,recall:0.566112192967532,f1:0.5618277525492709,pre:0.5834390495986523
Stem term epoch 110 | train loss:0.7920772433280945,test loss:0.9760748147964478,acc:0.6167955463435374,recall:0.5641247648567328,f1:0.5455933009842932,pre:0.5694555701273843
Stem term epoch 111 | train loss:0.8113997578620911,test loss:0.9785922765731812,acc:0.6142810639880952,recall:0.551031816686787,f1:0.5501715373551929,pre:0.5853712605211524
Stem term epoch 112 | train loss:0.7910141348838806,test loss:0.9672910571098328,acc:0.6154801764455783,recall:0.5419718989777956,f1:0.5390493687511314,pre:0.5766446767762164
Stem term epoch 113 | train loss:0.8026799559593201,test loss:0.9858964681625366,acc:0.6114775988520408,recall:0.5607341408082395,f1:0.5552906891730848,pre:0.5787430936763193
Stem term epoch 114 | train loss:0.8085002303123474,test loss:0.9587209224700928,acc:0.6134639402636054,recall:0.541662003180814,f1:0.5484480508639837,pre:0.5915025979003684
Stem term epoch 115 | train loss:0.7949981093406677,test loss:1.00880765914917,acc:0.5972277582908163,recall:0.5029697475214415,f1:0.5107986995953108,pre:0.6080292660279923
Stem term epoch 116 | train loss:0.7908610701560974,test loss:0.962197482585907,acc:0.6137429581207483,recall:0.5385540287231682,f1:0.5426838519892438,pre:0.579768250679772
Stem term epoch 117 | train loss:0.7850652933120728,test loss:0.9480232000350952,acc:0.6170845291241497,recall:0.546906833590613,f1:0.5503681717765759,pre:0.5800102809314194
Stem term epoch 118 | train loss:0.7974700331687927,test loss:0.9403976798057556,acc:0.6207150829081632,recall:0.5531424617841615,f1:0.552665275395763,pre:0.5874227705260531
Stem term epoch 119 | train loss:0.7987073063850403,test loss:0.9552657008171082,acc:0.6180112670068028,recall:0.5583956188892193,f1:0.5593680449350712,pre:0.5917108004402014
Stem term epoch 120 | train loss:0.7955427169799805,test loss:0.9550939798355103,acc:0.6202633397108843,recall:0.5430415533940848,f1:0.5536132040547982,pre:0.6037761297851401
Stem term epoch 121 | train loss:0.8037155270576477,test loss:0.9557413458824158,acc:0.6171476403061225,recall:0.5256047309320446,f1:0.5331491605528346,pre:0.5947666746621977
Stem term epoch 122 | train loss:0.794823169708252,test loss:0.9591509699821472,acc:0.617861793154762,recall:0.5575171889973625,f1:0.5497616710928915,pre:0.5851116804856246
Stem term epoch 123 | train loss:0.7930516600608826,test loss:0.9558836817741394,acc:0.6220304528061225,recall:0.5610505040613861,f1:0.5590433058680505,pre:0.5877728930317837
Stem term epoch 124 | train loss:0.795920193195343,test loss:0.9658596515655518,acc:0.6199245323129251,recall:0.5617932824622565,f1:0.5485440009488707,pre:0.5775578332640456
Stem term epoch 125 | train loss:0.7990964651107788,test loss:1.0051487684249878,acc:0.6157093696853742,recall:0.5500169084398042,f1:0.5443963134937593,pre:0.5888010840528298
Stem term epoch 126 | train loss:0.8050135970115662,test loss:0.9458223581314087,acc:0.6188350340136054,recall:0.5510972617651217,f1:0.5478970465384689,pre:0.5938473697469391
Stem term epoch 127 | train loss:0.792839765548706,test loss:0.9460053443908691,acc:0.6199145673894558,recall:0.5544245159260723,f1:0.5500548451938904,pre:0.5882140517910964
Stem term epoch 128 | train loss:0.7831510305404663,test loss:0.9603369235992432,acc:0.6069302721088435,recall:0.5365870321461669,f1:0.5449303875471171,pre:0.5888284226925872
Stem term epoch 129 | train loss:0.7868210077285767,test loss:0.9539574384689331,acc:0.6219042304421768,recall:0.5594705987351174,f1:0.5603847058500436,pre:0.589619000310065
Stem term epoch 130 | train loss:0.7865839600563049,test loss:0.9530161619186401,acc:0.6193631749574829,recall:0.5451836244847718,f1:0.5501532074130656,pre:0.5970882251806697
Stem term epoch 131 | train loss:0.7918360233306885,test loss:0.9617153406143188,acc:0.6207416560374149,recall:0.562713752305605,f1:0.5458149345321135,pre:0.5829997909442701
Stem term epoch 132 | train loss:0.7947431206703186,test loss:0.9576267600059509,acc:0.6183002497874149,recall:0.5364544268051711,f1:0.5399794064000351,pre:0.6074485162712279
Stem term epoch 133 | train loss:0.7899543046951294,test loss:0.9539341330528259,acc:0.6112251541241497,recall:0.5297647782593604,f1:0.5355111235070696,pre:0.5960000386626048
Stem term epoch 134 | train loss:0.7894047498703003,test loss:0.965961217880249,acc:0.6230535182823129,recall:0.556715644231346,f1:0.5526723750653034,pre:0.5905383917102978
Stem term epoch 135 | train loss:0.7821158766746521,test loss:0.9559358954429626,acc:0.6233059630102041,recall:0.562939352609512,f1:0.557741887921853,pre:0.5791647475050171
Stem term epoch 136 | train loss:0.7900575995445251,test loss:0.964572548866272,acc:0.6164467740221088,recall:0.5531657158044071,f1:0.5570530823455289,pre:0.5926949312833245
Stem term epoch 137 | train loss:0.8041031360626221,test loss:0.9805869460105896,acc:0.612002418154762,recall:0.5520193071312822,f1:0.5417189523141456,pre:0.5613352496423094
Stem term epoch 138 | train loss:0.7975639700889587,test loss:0.969056248664856,acc:0.6036883503401361,recall:0.5530340406026948,f1:0.5551809236040762,pre:0.5757136732351906
Stem term epoch 139 | train loss:0.7921038866043091,test loss:0.9583497047424316,acc:0.6249701052295918,recall:0.5534261076063268,f1:0.5487172950183676,pre:0.5908490735510883
Stem term epoch 140 | train loss:0.7992932796478271,test loss:0.9740345478057861,acc:0.6254218484268708,recall:0.5502302969538004,f1:0.5546245770284107,pre:0.589641184606933
Stem term epoch 141 | train loss:0.777315080165863,test loss:0.9509847164154053,acc:0.61892471832483,recall:0.5442010120553044,f1:0.5470884408299627,pre:0.5927152452431105
Stem term epoch 142 | train loss:0.8029923439025879,test loss:0.9582118988037109,acc:0.6182869632227891,recall:0.5569370818372519,f1:0.5463228527319454,pre:0.5691336729743599
Stem term epoch 143 | train loss:0.7808306813240051,test loss:0.9655494689941406,acc:0.6142279177295918,recall:0.5448040824129152,f1:0.5471291156544356,pre:0.5949948272433468
Stem term epoch 144 | train loss:0.7874295711517334,test loss:0.9458824396133423,acc:0.6219806281887755,recall:0.5486025892793095,f1:0.5513435314345676,pre:0.5944088894670939
Stem term epoch 145 | train loss:0.7902202010154724,test loss:0.9534546732902527,acc:0.6206885097789115,recall:0.551901881198754,f1:0.5447897093117771,pre:0.5760270689894753
Stem term epoch 146 | train loss:0.7795583009719849,test loss:0.964773416519165,acc:0.6179116177721088,recall:0.5338495220047134,f1:0.5353750646382907,pre:0.5892211306152256
Stem term epoch 147 | train loss:0.7906685471534729,test loss:0.9597551822662354,acc:0.6104877497874149,recall:0.5295891388005135,f1:0.5373490036768437,pre:0.602737887057379
Stem term epoch 148 | train loss:0.7822037935256958,test loss:0.9535285830497742,acc:0.6173834768282312,recall:0.5429714995604419,f1:0.5468732356576177,pre:0.5923631209198064
Stem term epoch 149 | train loss:0.7815620303153992,test loss:0.9513620734214783,acc:0.621890943877551,recall:0.5555169822658499,f1:0.5477541162028816,pre:0.5766951843910334
Stem term epoch 150 | train loss:0.7786022424697876,test loss:0.9529556632041931,acc:0.62869034332483,recall:0.5571935551350834,f1:0.5573968268701229,pre:0.6027685974478539
training has finished used time : 3195.6274852752686
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (14651, 18)
trait shape (1, 14651)
df shape (20087, 42195)
(5000, 32032) (9651, 32032)
train dataset already completed!
5000
test dataset already completed!
9651
H_CLR epoch 1 | train loss:1.6057971715927124,test loss:1.8270223140716553,acc:0.21480545343137253,recall:0.18314927052730315,f1:0.07231431285199605,pre:0.059853993853455446
epoch 1 : weight has update
H_CLR epoch 2 | train loss:1.4007169008255005,test loss:1.697232961654663,acc:0.34119622355521156,recall:0.30042311500881097,f1:0.2196951511443167,pre:0.3201674384991412
epoch 2 : weight has update
H_CLR epoch 3 | train loss:1.286537528038025,test loss:1.1993545293807983,acc:0.4834780540505676,recall:0.45837673097652154,f1:0.4356259332102952,pre:0.5060976875232106
epoch 3 : weight has update
H_CLR epoch 4 | train loss:1.2228080034255981,test loss:1.2402675151824951,acc:0.492000048374613,recall:0.4561774483156025,f1:0.44529862581451707,pre:0.5179682645558138
epoch 4 : weight has update
H_CLR epoch 5 | train loss:1.1622170209884644,test loss:1.5095412731170654,acc:0.42389665570175444,recall:0.36799000119791353,f1:0.3393339998262109,pre:0.5196676033589404
H_CLR epoch 6 | train loss:1.1592097282409668,test loss:1.7345279455184937,acc:0.28763746452528377,recall:0.24843053357433317,f1:0.16742830018269755,pre:0.4274120002823897
H_CLR epoch 7 | train loss:1.0990139245986938,test loss:1.2386114597320557,acc:0.48778541021671823,recall:0.43369510911336673,f1:0.38208154101602726,pre:0.5229121784985192
H_CLR epoch 8 | train loss:1.0612796545028687,test loss:1.1119978427886963,acc:0.5804167472910217,recall:0.5045077625075176,f1:0.47804622565109345,pre:0.5167741905273988
epoch 8 : weight has update
H_CLR epoch 9 | train loss:0.9538178443908691,test loss:1.1437413692474365,acc:0.4969423213364293,recall:0.4603073015427994,f1:0.44741792404453024,pre:0.6806607049575809
epoch 9 : weight has update
H_CLR epoch 10 | train loss:0.920656144618988,test loss:0.9282529950141907,acc:0.6444143446852425,recall:0.6162438954109593,f1:0.6080482799788602,pre:0.6391095041902428
epoch 10 : weight has update
H_CLR epoch 11 | train loss:0.8759387135505676,test loss:0.914516031742096,acc:0.6679506095201239,recall:0.6177081089680762,f1:0.6111603693780762,pre:0.6687492241586286
epoch 11 : weight has update
H_CLR epoch 12 | train loss:0.8584355115890503,test loss:1.0167163610458374,acc:0.5809791021671827,recall:0.5409623178997878,f1:0.5214161879559124,pre:0.710520951783956
H_CLR epoch 13 | train loss:0.846019446849823,test loss:0.8579505085945129,acc:0.6930832365841073,recall:0.650990159518573,f1:0.6466066189310723,pre:0.6982061444440024
epoch 13 : weight has update
H_CLR epoch 14 | train loss:0.8294488191604614,test loss:0.8455437421798706,acc:0.6959635416666666,recall:0.6378465235799748,f1:0.6361964705072652,pre:0.7066579075640146
H_CLR epoch 15 | train loss:0.8105589747428894,test loss:0.7863247394561768,acc:0.7183226909184727,recall:0.677234628279262,f1:0.6771559769484522,pre:0.7014936326844561
epoch 15 : weight has update
H_CLR epoch 16 | train loss:0.7916234731674194,test loss:0.8083842992782593,acc:0.7096394478844169,recall:0.6608952405775246,f1:0.6644669399871311,pre:0.7266062005899311
H_CLR epoch 17 | train loss:0.7705093622207642,test loss:0.8895834684371948,acc:0.6499592847007224,recall:0.6203109653826756,f1:0.5980090924180835,pre:0.7030181022817996
H_CLR epoch 18 | train loss:0.7488210797309875,test loss:0.6970051527023315,acc:0.7523018253353972,recall:0.6979903342174335,f1:0.7028158423071731,pre:0.7496755608916265
epoch 18 : weight has update
H_CLR epoch 19 | train loss:0.7067882418632507,test loss:0.6794206500053406,acc:0.7650969104747162,recall:0.725660073260658,f1:0.7233482585348664,pre:0.73297184983861
epoch 19 : weight has update
H_CLR epoch 20 | train loss:0.6848306059837341,test loss:0.7118964791297913,acc:0.7482383578431373,recall:0.7030962106176878,f1:0.7087889375779222,pre:0.7602678912891577
H_CLR epoch 21 | train loss:0.6594483256340027,test loss:0.7270188331604004,acc:0.7514794569143447,recall:0.7156531041648178,f1:0.7107891346189655,pre:0.734243750518789
H_CLR epoch 22 | train loss:0.6586169004440308,test loss:0.7215485572814941,acc:0.7398635029669762,recall:0.6853228772337129,f1:0.6869292776663667,pre:0.7705470681279487
H_CLR epoch 23 | train loss:0.6670891642570496,test loss:0.6336379051208496,acc:0.7872484520123839,recall:0.728346030698502,f1:0.7387498942650048,pre:0.7940413445820605
epoch 23 : weight has update
H_CLR epoch 24 | train loss:0.6300012469291687,test loss:0.7040380835533142,acc:0.7512678179824561,recall:0.7117569913860313,f1:0.7089190200352329,pre:0.7419941579762913
H_CLR epoch 25 | train loss:0.6407869458198547,test loss:0.7209423780441284,acc:0.76828157249742,recall:0.740934501600799,f1:0.7355710704584792,pre:0.7480906525073152
H_CLR epoch 26 | train loss:0.6301170587539673,test loss:0.6458032727241516,acc:0.7771784700722394,recall:0.7636881680377391,f1:0.7427036963015317,pre:0.7402450827171569
H_CLR epoch 27 | train loss:0.6143592596054077,test loss:0.6364582777023315,acc:0.7841686016511867,recall:0.739876785674116,f1:0.7413920906443656,pre:0.7623556273496656
H_CLR epoch 28 | train loss:0.6159102916717529,test loss:0.618350625038147,acc:0.7916787603199174,recall:0.74690316914842,f1:0.7503471947499138,pre:0.7776255719342249
epoch 28 : weight has update
H_CLR epoch 29 | train loss:0.6182742714881897,test loss:0.6327638030052185,acc:0.7891511867905057,recall:0.7437959022904723,f1:0.74529047812686,pre:0.7687555517977044
H_CLR epoch 30 | train loss:0.6197961568832397,test loss:0.6212828755378723,acc:0.7903928018575851,recall:0.7530664017768082,f1:0.7518062961302275,pre:0.7617548377509582
H_CLR epoch 31 | train loss:0.6060441732406616,test loss:0.6167839169502258,acc:0.7926462525799793,recall:0.7443128329519725,f1:0.7488266976355503,pre:0.7738350339453927
H_CLR epoch 32 | train loss:0.6171863675117493,test loss:0.6186861395835876,acc:0.7940914441434469,recall:0.7417015620231049,f1:0.7499553411140626,pre:0.787074858412048
epoch 32 : weight has update
H_CLR epoch 33 | train loss:0.5986722707748413,test loss:0.6258761882781982,acc:0.7887460494066048,recall:0.7382542171688078,f1:0.7442958204826398,pre:0.782237740041362
H_CLR epoch 34 | train loss:0.6036271452903748,test loss:0.6077627539634705,acc:0.7998984133126935,recall:0.7526052708957783,f1:0.7547457469368377,pre:0.7764226407081815
epoch 34 : weight has update
H_CLR epoch 35 | train loss:0.5927715301513672,test loss:0.6087831258773804,acc:0.787609246001032,recall:0.7560294713988028,f1:0.7475621575779154,pre:0.7513456769087731
H_CLR epoch 36 | train loss:0.5784894227981567,test loss:0.6302609443664551,acc:0.7850453915118679,recall:0.744773398308125,f1:0.7429259959171145,pre:0.7588405444745985
H_CLR epoch 37 | train loss:0.6039365530014038,test loss:0.6473888158798218,acc:0.7857105424406604,recall:0.7485506383530381,f1:0.7448986985431127,pre:0.7599344649944516
H_CLR epoch 38 | train loss:0.581923246383667,test loss:0.6013057827949524,acc:0.7948634223426212,recall:0.7543642262122287,f1:0.7529258345139179,pre:0.7646258153181905
H_CLR epoch 39 | train loss:0.5761400461196899,test loss:0.6112744212150574,acc:0.7982012706398349,recall:0.7473042529982996,f1:0.7546676315370178,pre:0.7885771092954634
epoch 39 : weight has update
H_CLR epoch 40 | train loss:0.5834782719612122,test loss:0.5962631106376648,acc:0.7951153734520124,recall:0.757573953274856,f1:0.7567539339541438,pre:0.7758745113073694
H_CLR epoch 41 | train loss:0.5821319818496704,test loss:0.6428824067115784,acc:0.7779020736584107,recall:0.7467523938487776,f1:0.7374871018547112,pre:0.7478856039700364
H_CLR epoch 42 | train loss:0.5860275030136108,test loss:0.6031063795089722,acc:0.8004567369711042,recall:0.7559140685889603,f1:0.7592556464338184,pre:0.7795648733484266
epoch 42 : weight has update
H_CLR epoch 43 | train loss:0.5790372490882874,test loss:0.6289098262786865,acc:0.7854082011093911,recall:0.7198434843307929,f1:0.730330270500151,pre:0.8165243322986654
H_CLR epoch 44 | train loss:0.5786333084106445,test loss:0.6228122115135193,acc:0.7956837751547987,recall:0.7349475209552561,f1:0.7459579081883045,pre:0.8022653322062214
H_CLR epoch 45 | train loss:0.5848665833473206,test loss:0.6032803654670715,acc:0.7995900251547987,recall:0.746248460603039,f1:0.7573776965131921,pre:0.8126243878216906
epoch 45 : weight has update
H_CLR epoch 46 | train loss:0.567176878452301,test loss:0.6056540012359619,acc:0.8011803405572756,recall:0.7551697882274783,f1:0.7647525887635629,pre:0.8007409125994269
epoch 46 : weight has update
H_CLR epoch 47 | train loss:0.5929402709007263,test loss:0.6196370124816895,acc:0.7881796633126935,recall:0.7435390898520279,f1:0.7476101560719229,pre:0.7725365663116058
H_CLR epoch 48 | train loss:0.575485348701477,test loss:0.6163684725761414,acc:0.7960385223168215,recall:0.7552207516213657,f1:0.7594817313894144,pre:0.787281227299635
H_CLR epoch 49 | train loss:0.5809625387191772,test loss:0.5881236791610718,acc:0.8059633804179566,recall:0.7536375952377036,f1:0.75876013202979,pre:0.795459368371594
H_CLR epoch 50 | train loss:0.5679624080657959,test loss:0.6505376696586609,acc:0.7759973232714138,recall:0.7180396895232883,f1:0.7311331405951018,pre:0.8154696138693984
H_CLR epoch 51 | train loss:0.5731036067008972,test loss:0.5952000021934509,acc:0.7924950819143447,recall:0.749980618908217,f1:0.7473027107465973,pre:0.7627982607251423
H_CLR epoch 52 | train loss:0.5732061862945557,test loss:0.6218169927597046,acc:0.7929102973426212,recall:0.7482714454146573,f1:0.7491540998919074,pre:0.7700256607250658
H_CLR epoch 53 | train loss:0.5803409218788147,test loss:0.5826652646064758,acc:0.8063241744066048,recall:0.7557828629569473,f1:0.762640328329327,pre:0.7946775298862409
H_CLR epoch 54 | train loss:0.5740898847579956,test loss:0.6431188583374023,acc:0.7821146962074303,recall:0.7394561598102684,f1:0.7417705196037967,pre:0.7693006526062905
H_CLR epoch 55 | train loss:0.5535309910774231,test loss:0.5915169715881348,acc:0.7991808565531475,recall:0.7692939187355103,f1:0.7604428225037354,pre:0.767287919792316
H_CLR epoch 56 | train loss:0.5601032376289368,test loss:0.5786231160163879,acc:0.8071445272187823,recall:0.7661500137331878,f1:0.7673215389975784,pre:0.7799556146102927
H_CLR epoch 57 | train loss:0.5696962475776672,test loss:0.6266887784004211,acc:0.7904915666924665,recall:0.7472133487682485,f1:0.746475268748488,pre:0.7646472423333681
H_CLR epoch 58 | train loss:0.5517085194587708,test loss:0.6180040836334229,acc:0.7971753257223942,recall:0.7480488795082642,f1:0.7504740496599553,pre:0.7803400575050969
H_CLR epoch 59 | train loss:0.5696595311164856,test loss:0.6308581829071045,acc:0.7832434371775026,recall:0.7446983157029504,f1:0.7403321763290674,pre:0.7578269142421904
H_CLR epoch 60 | train loss:0.5529869198799133,test loss:0.6263929605484009,acc:0.7931582172342622,recall:0.7331809376440458,f1:0.7414271786991821,pre:0.8142679294838387
H_CLR epoch 61 | train loss:0.5538517832756042,test loss:0.5770483016967773,acc:0.8044698142414861,recall:0.743658685531212,f1:0.755577589084196,pre:0.8144738066475233
H_CLR epoch 62 | train loss:0.5570023655891418,test loss:0.5874047875404358,acc:0.8103836106811145,recall:0.7538847800515527,f1:0.7619705284139742,pre:0.8071957100103063
epoch 62 : weight has update
H_CLR epoch 63 | train loss:0.5456305146217346,test loss:0.5891297459602356,acc:0.8033410732714138,recall:0.7533240125253828,f1:0.7620047260317304,pre:0.7971647635325003
H_CLR epoch 64 | train loss:0.5626792907714844,test loss:0.5786870718002319,acc:0.8060661764705882,recall:0.746949165593489,f1:0.7546799111143531,pre:0.8029047366808806
H_CLR epoch 65 | train loss:0.5581029057502747,test loss:0.585020899772644,acc:0.8057053824819401,recall:0.7778386262550513,f1:0.7696462957061513,pre:0.7740441782649258
H_CLR epoch 66 | train loss:0.5528325438499451,test loss:0.5953294038772583,acc:0.8060641608617131,recall:0.7475134901505637,f1:0.7567284687902808,pre:0.8137306035088132
H_CLR epoch 67 | train loss:0.5351423025131226,test loss:0.6263337135314941,acc:0.7886896123581011,recall:0.7381841884535391,f1:0.7479202277538379,pre:0.8014586385830114
H_CLR epoch 68 | train loss:0.5566455721855164,test loss:0.6012474298477173,acc:0.7994348232714138,recall:0.7565556248731888,f1:0.7601898240620706,pre:0.7876930405526634
H_CLR epoch 69 | train loss:0.5581443309783936,test loss:0.5867341756820679,acc:0.8035990712074303,recall:0.7542588961505918,f1:0.7622321757009084,pre:0.7975688472709572
H_CLR epoch 70 | train loss:0.5594208836555481,test loss:0.5836678147315979,acc:0.801438338493292,recall:0.7544459752977627,f1:0.759737150310398,pre:0.785501712084472
H_CLR epoch 71 | train loss:0.5562001466751099,test loss:0.586193323135376,acc:0.8079668956398349,recall:0.7586031171553633,f1:0.7644270306088586,pre:0.7971736753993974
H_CLR epoch 72 | train loss:0.5548945069313049,test loss:0.6015244126319885,acc:0.799078060500516,recall:0.7468581308569427,f1:0.7564601080611191,pre:0.8065522611113153
H_CLR epoch 73 | train loss:0.5426040887832642,test loss:0.6317701935768127,acc:0.7884316144220846,recall:0.7538581091712747,f1:0.7468342969424032,pre:0.7592970367292351
H_CLR epoch 74 | train loss:0.5607271790504456,test loss:0.5861427187919617,acc:0.805141011996904,recall:0.7619330937124931,f1:0.7682742583130387,pre:0.7980556712730728
H_CLR epoch 75 | train loss:0.5453636050224304,test loss:0.5801709890365601,acc:0.8040062242002064,recall:0.7493406462084679,f1:0.7591242793165993,pre:0.8013681805960008
H_CLR epoch 76 | train loss:0.5595418214797974,test loss:0.5825932025909424,acc:0.8040566144220846,recall:0.777449502897835,f1:0.7693715307184922,pre:0.7701277392786161
H_CLR epoch 77 | train loss:0.5608676075935364,test loss:0.5836371779441833,acc:0.7982577076883385,recall:0.7649890439640677,f1:0.7557228624408349,pre:0.7625500821757705
H_CLR epoch 78 | train loss:0.5441486835479736,test loss:0.5702685713768005,acc:0.8076625386996904,recall:0.7457539203674346,f1:0.7535562488635026,pre:0.8051103153760716
H_CLR epoch 79 | train loss:0.5536683201789856,test loss:0.5750680565834045,acc:0.8020047245872033,recall:0.7588120862465066,f1:0.7583621323124575,pre:0.776037991412473
H_CLR epoch 80 | train loss:0.5575269460678101,test loss:0.6278236508369446,acc:0.7914187467750258,recall:0.7474364220761983,f1:0.7478522606549731,pre:0.7715728515097208
H_CLR epoch 81 | train loss:0.5411471724510193,test loss:0.5993882417678833,acc:0.7985600490196078,recall:0.7705533572134767,f1:0.760978161668334,pre:0.7619832636133408
H_CLR epoch 82 | train loss:0.5472936034202576,test loss:0.6469632387161255,acc:0.7860673052115583,recall:0.7449802958825557,f1:0.7475089252601258,pre:0.7822490205402751
H_CLR epoch 83 | train loss:0.5556666851043701,test loss:0.603334903717041,acc:0.8006159700722394,recall:0.7730090782173589,f1:0.7655454060890443,pre:0.7761029627132189
H_CLR epoch 84 | train loss:0.5226295590400696,test loss:0.5736346244812012,acc:0.8048789828431373,recall:0.7652762880607922,f1:0.7648922122403886,pre:0.7773550339336783
H_CLR epoch 85 | train loss:0.5505033731460571,test loss:0.5882725715637207,acc:0.8128003257223942,recall:0.7607626355517002,f1:0.7661970479766111,pre:0.7974934840866293
epoch 85 : weight has update
H_CLR epoch 86 | train loss:0.5419159531593323,test loss:0.5671693682670593,acc:0.8149550116099071,recall:0.779796139450253,f1:0.7785030793730964,pre:0.789062364113553
epoch 86 : weight has update
H_CLR epoch 87 | train loss:0.5342245697975159,test loss:0.5914769172668457,acc:0.7974837138802889,recall:0.7710456809428384,f1:0.7603987169777316,pre:0.7613167478182716
H_CLR epoch 88 | train loss:0.5328760743141174,test loss:0.5829374194145203,acc:0.8038026477038184,recall:0.7668458087441163,f1:0.7615258493005965,pre:0.7687464752863811
H_CLR epoch 89 | train loss:0.5251861214637756,test loss:0.593929648399353,acc:0.8052417924406604,recall:0.7672955692733759,f1:0.7625604626914168,pre:0.768329174822263
H_CLR epoch 90 | train loss:0.5454884767532349,test loss:0.5862625241279602,acc:0.8021579108617131,recall:0.7650816430756386,f1:0.7664754581596085,pre:0.7842037839736978
H_CLR epoch 91 | train loss:0.5580841302871704,test loss:0.5977867245674133,acc:0.8095048052115583,recall:0.7688735239097626,f1:0.7681395812794891,pre:0.7844904345018128
H_CLR epoch 92 | train loss:0.5411746501922607,test loss:0.5897054076194763,acc:0.8014927599329206,recall:0.7476802898559237,f1:0.7534684860258609,pre:0.7993469416421557
H_CLR epoch 93 | train loss:0.5384915471076965,test loss:0.6323496699333191,acc:0.775844136996904,recall:0.7307351837233267,f1:0.7374143347548372,pre:0.7881529725608519
H_CLR epoch 94 | train loss:0.5499785542488098,test loss:0.6044033169746399,acc:0.7935794794891641,recall:0.7468178451633563,f1:0.7495429341657002,pre:0.778727890849538
H_CLR epoch 95 | train loss:0.536095917224884,test loss:0.5661135315895081,acc:0.8070921213880289,recall:0.7602516198367592,f1:0.7662113803819693,pre:0.7928845585086503
H_CLR epoch 96 | train loss:0.5293443202972412,test loss:0.5752615928649902,acc:0.8093475877192983,recall:0.761002222349997,f1:0.7676183823523846,pre:0.8028058867052926
H_CLR epoch 97 | train loss:0.5213484764099121,test loss:0.5767086744308472,acc:0.8093999935500517,recall:0.7624147139302229,f1:0.7676048486368431,pre:0.794235812556983
H_CLR epoch 98 | train loss:0.5403035283088684,test loss:0.5875355005264282,acc:0.8040102554179566,recall:0.7737203956440716,f1:0.7688463993643176,pre:0.778281118292734
H_CLR epoch 99 | train loss:0.540296733379364,test loss:0.5821383595466614,acc:0.8075597426470589,recall:0.7796465718910724,f1:0.7719324137681368,pre:0.7751908338642762
H_CLR epoch 100 | train loss:0.5388396978378296,test loss:0.5654515027999878,acc:0.8082772994066048,recall:0.7687220718290415,f1:0.7723417109381447,pre:0.7962375226703235
H_CLR epoch 101 | train loss:0.531330406665802,test loss:0.56122225522995,acc:0.8157814112487101,recall:0.7655046803062864,f1:0.7711521412345751,pre:0.7996586545852137
H_CLR epoch 102 | train loss:0.5444855093955994,test loss:0.5851708054542542,acc:0.8062697529669762,recall:0.7544863041474378,f1:0.7625672690709899,pre:0.8005484738407365
H_CLR epoch 103 | train loss:0.5290767550468445,test loss:0.6079276204109192,acc:0.7963509416924665,recall:0.7704152543280043,f1:0.7545210576551613,pre:0.7579929767033253
H_CLR epoch 104 | train loss:0.5477026700973511,test loss:0.6072158217430115,acc:0.8005151896284829,recall:0.7414576162757069,f1:0.7501808881804969,pre:0.8019074133675761
H_CLR epoch 105 | train loss:0.5395811796188354,test loss:0.5898783206939697,acc:0.8105448593911249,recall:0.7782489671000926,f1:0.7703114048591496,pre:0.7764984037970917
H_CLR epoch 106 | train loss:0.5284591317176819,test loss:0.6057279109954834,acc:0.8052377612229101,recall:0.756066575896763,f1:0.76218171939157,pre:0.793861856742517
H_CLR epoch 107 | train loss:0.5513973832130432,test loss:0.6582465767860413,acc:0.770188338493292,recall:0.726789946838714,f1:0.7290169414251303,pre:0.7684477165375271
H_CLR epoch 108 | train loss:0.5318572521209717,test loss:0.5848187804222107,acc:0.8056529766511867,recall:0.7457851227722794,f1:0.7551718875897755,pre:0.8106800681060345
H_CLR epoch 109 | train loss:0.5438454747200012,test loss:0.5816879272460938,acc:0.8071908862229101,recall:0.7705967071237426,f1:0.7685355449366317,pre:0.7816795230708302
H_CLR epoch 110 | train loss:0.5260624289512634,test loss:0.5612305998802185,acc:0.8100228166924665,recall:0.7634471478502849,f1:0.7656714781515425,pre:0.7823822162821903
H_CLR epoch 111 | train loss:0.5465183258056641,test loss:0.5675864815711975,acc:0.8106919988390092,recall:0.7506858865320352,f1:0.7615040244813154,pre:0.8238784041167151
H_CLR epoch 112 | train loss:0.5228708982467651,test loss:0.5520681142807007,acc:0.8136710687564499,recall:0.7702828575026255,f1:0.7733922039401012,pre:0.7968294251761519
H_CLR epoch 113 | train loss:0.5231984257698059,test loss:0.5872530937194824,acc:0.8057073980908153,recall:0.7647407817187921,f1:0.7636379237825978,pre:0.7791791089967744
H_CLR epoch 114 | train loss:0.5430008769035339,test loss:0.5652997493743896,acc:0.8123851102941176,recall:0.7608087561397798,f1:0.7687457482656447,pre:0.8067842689686082
H_CLR epoch 115 | train loss:0.5294281244277954,test loss:0.5700671672821045,acc:0.8111051986584107,recall:0.7602667285732015,f1:0.7694056528460853,pre:0.8157360125522309
H_CLR epoch 116 | train loss:0.5382794737815857,test loss:0.6192336082458496,acc:0.8025751418988648,recall:0.7688346577296642,f1:0.7681808447976554,pre:0.7891556774049147
H_CLR epoch 117 | train loss:0.5288240313529968,test loss:0.6488630175590515,acc:0.7687451625386996,recall:0.7135961957208807,f1:0.7163114045448739,pre:0.7641979548344541
H_CLR epoch 118 | train loss:0.5228742957115173,test loss:0.5654941201210022,acc:0.815468991873065,recall:0.7600998203549515,f1:0.766228051646437,pre:0.7973481772390387
H_CLR epoch 119 | train loss:0.5241461396217346,test loss:0.5668457746505737,acc:0.8080717073013416,recall:0.7728098281293031,f1:0.7676076310396651,pre:0.7727776499305218
H_CLR epoch 120 | train loss:0.5328417420387268,test loss:0.5865904092788696,acc:0.803546665376677,recall:0.7382382575767207,f1:0.7477946442507278,pre:0.8033027417932724
H_CLR epoch 121 | train loss:0.5215535163879395,test loss:0.559080958366394,acc:0.8099704108617131,recall:0.7703822046063284,f1:0.7663503011392191,pre:0.7742363251795545
H_CLR epoch 122 | train loss:0.5487680435180664,test loss:0.5665144920349121,acc:0.8101739873581011,recall:0.7766115028375008,f1:0.7709897886231913,pre:0.7772813059040602
H_CLR epoch 123 | train loss:0.5240463018417358,test loss:0.5758641958236694,acc:0.8056046020381837,recall:0.7672433870567787,f1:0.7674162806225417,pre:0.7799549941543404
H_CLR epoch 124 | train loss:0.5237230658531189,test loss:0.5555649995803833,acc:0.8130039022187823,recall:0.7595846350134317,f1:0.7667529201557923,pre:0.7980212901915172
H_CLR epoch 125 | train loss:0.5366378426551819,test loss:0.5967364311218262,acc:0.8087408894478844,recall:0.7620106434391996,f1:0.7691054841238261,pre:0.8058409389529477
H_CLR epoch 126 | train loss:0.5114370584487915,test loss:0.5909278392791748,acc:0.8106899832301341,recall:0.768774384807791,f1:0.7699017038162812,pre:0.7870724215690772
H_CLR epoch 127 | train loss:0.5295432806015015,test loss:0.5867613554000854,acc:0.8111555888802889,recall:0.7710053576518933,f1:0.7741340324274706,pre:0.7931170481111716
H_CLR epoch 128 | train loss:0.5411946177482605,test loss:0.5640849471092224,acc:0.809250838493292,recall:0.7589829222435259,f1:0.761405932843055,pre:0.7876536202022105
H_CLR epoch 129 | train loss:0.524624228477478,test loss:0.5746108889579773,acc:0.8125947336171311,recall:0.7608583626871545,f1:0.7673100506602827,pre:0.7970093113498634
H_CLR epoch 130 | train loss:0.5259425044059753,test loss:0.5867732167243958,acc:0.8089484971620227,recall:0.7466149059689782,f1:0.7549332265601802,pre:0.8147620464882385
H_CLR epoch 131 | train loss:0.5222989916801453,test loss:0.6318150162696838,acc:0.784376209365325,recall:0.7496836414448753,f1:0.7416983184079943,pre:0.752442567137452
H_CLR epoch 132 | train loss:0.5411841869354248,test loss:0.5764604210853577,acc:0.8059089589783281,recall:0.7793235729268445,f1:0.7701469347631363,pre:0.7712387787814023
H_CLR epoch 133 | train loss:0.5211439728736877,test loss:0.5612871050834656,acc:0.8125927180082559,recall:0.7734437824801129,f1:0.7736158401270612,pre:0.7869133461242904
H_CLR epoch 134 | train loss:0.5319947004318237,test loss:0.5793288946151733,acc:0.8104803599071208,recall:0.7812686593434711,f1:0.7732092274463528,pre:0.7757484327757833
H_CLR epoch 135 | train loss:0.5274784564971924,test loss:0.5864474773406982,acc:0.8064269704592363,recall:0.7830993164551865,f1:0.7705754443717253,pre:0.7734279718784588
H_CLR epoch 136 | train loss:0.5241063237190247,test loss:0.5684647560119629,acc:0.8124899219556244,recall:0.7766446455026164,f1:0.774155995248261,pre:0.784265053082451
H_CLR epoch 137 | train loss:0.5156598091125488,test loss:0.5682021975517273,acc:0.8085836719556244,recall:0.781078679535407,f1:0.7697743687341362,pre:0.7742260693756506
H_CLR epoch 138 | train loss:0.5019189715385437,test loss:0.5953459143638611,acc:0.8041634416924665,recall:0.7715951120062056,f1:0.7637431902745483,pre:0.7690767450753199
H_CLR epoch 139 | train loss:0.5330663323402405,test loss:0.5970163941383362,acc:0.8019523187564499,recall:0.7723500741265145,f1:0.7685683325784353,pre:0.7844154984782318
H_CLR epoch 140 | train loss:0.5250638127326965,test loss:0.5884864330291748,acc:0.8015955559855521,recall:0.7428216600394709,f1:0.7513953646930417,pre:0.8024058471958634
H_CLR epoch 141 | train loss:0.5292128920555115,test loss:0.5732799768447876,acc:0.8084284700722394,recall:0.7649748486938583,f1:0.7680090278948749,pre:0.7872696710409152
H_CLR epoch 142 | train loss:0.5161518454551697,test loss:0.5660034418106079,acc:0.8107403734520124,recall:0.7603757661192212,f1:0.7684187193546864,pre:0.8029296568708105
H_CLR epoch 143 | train loss:0.5351218581199646,test loss:0.5730941891670227,acc:0.8126451238390092,recall:0.7526468753394998,f1:0.7618347276763604,pre:0.8153859691597409
H_CLR epoch 144 | train loss:0.5255689024925232,test loss:0.5568289756774902,acc:0.8102304244066048,recall:0.7585657527292856,f1:0.7626790507180768,pre:0.7928863631011241
H_CLR epoch 145 | train loss:0.5363878011703491,test loss:0.590687096118927,acc:0.8026718911248709,recall:0.7763494012401765,f1:0.7630075407019167,pre:0.7651910373172125
H_CLR epoch 146 | train loss:0.516726016998291,test loss:0.5618146061897278,acc:0.8158862229102167,recall:0.7540240208305612,f1:0.7634858289247757,pre:0.8276002435889425
H_CLR epoch 147 | train loss:0.5084595084190369,test loss:0.5649479627609253,acc:0.8158277702528379,recall:0.7712686366262522,f1:0.7749178234316897,pre:0.796735029113832
H_CLR epoch 148 | train loss:0.5250808596611023,test loss:0.5999515652656555,acc:0.8026275477296182,recall:0.7815063037525861,f1:0.767565687327213,pre:0.7696428511391286
H_CLR epoch 149 | train loss:0.5278382301330566,test loss:0.6096733808517456,acc:0.8074005095459236,recall:0.7582190691638933,f1:0.7652938397096977,pre:0.8030174341746864
H_CLR epoch 150 | train loss:0.5284404754638672,test loss:0.6066001653671265,acc:0.8030830753353972,recall:0.7567940612400065,f1:0.7645211810078522,pre:0.8025205787113675
training has finished used time : 4233.030346393585
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (8576, 18)
trait shape (1, 8576)
df shape (20087, 42195)
(5000, 32032) (3576, 32032)
train dataset already completed!
5000
test dataset already completed!
3576
PRR1 epoch 1 | train loss:0.96441650390625,test loss:0.8762708902359009,acc:0.5165364583333333,recall:0.3333333333333333,f1:0.2266350826775662,pre:0.17217881944444444
epoch 1 : weight has update
PRR1 epoch 2 | train loss:0.8897621035575867,test loss:0.9206060171127319,acc:0.5165550595238095,recall:0.3392857142857143,f1:0.2308866069391276,pre:0.17544022817460317
epoch 2 : weight has update
PRR1 epoch 3 | train loss:0.8877437710762024,test loss:0.8517815470695496,acc:0.43909970238095236,recall:0.3333333333333333,f1:0.20319093465486976,pre:0.14636656746031745
PRR1 epoch 4 | train loss:0.8945167660713196,test loss:0.9017296433448792,acc:0.5165736607142858,recall:0.3333333333333333,f1:0.2268394293892911,pre:0.17219122023809527
PRR1 epoch 5 | train loss:0.8927363753318787,test loss:0.8558313846588135,acc:0.5164620535714286,recall:0.3333333333333333,f1:0.22670683010872847,pre:0.17215401785714285
PRR1 epoch 6 | train loss:0.895596444606781,test loss:0.9262920022010803,acc:0.5166480654761905,recall:0.3333333333333333,f1:0.2265510975991895,pre:0.17221602182539683
PRR1 epoch 7 | train loss:0.9008213877677917,test loss:0.8559998273849487,acc:0.43880208333333337,recall:0.3333333333333333,f1:0.2026066518015783,pre:0.14626736111111113
PRR1 epoch 8 | train loss:0.8978490829467773,test loss:0.9199182391166687,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.22673275722919436,pre:0.17217261904761902
PRR1 epoch 9 | train loss:0.8822997808456421,test loss:0.8681114315986633,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.22680075203986758,pre:0.1721726190476191
PRR1 epoch 10 | train loss:0.8750638961791992,test loss:0.9297452569007874,acc:0.5166852678571429,recall:0.3333333333333333,f1:0.2267710683440038,pre:0.17222842261904767
PRR1 epoch 11 | train loss:0.8711250424385071,test loss:0.8867747187614441,acc:0.5164434523809524,recall:0.3392857142857143,f1:0.23075400573234559,pre:0.1752170138888889
PRR1 epoch 12 | train loss:0.8695628046989441,test loss:0.8950379490852356,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.226718693429848,pre:0.17216021825396827
PRR1 epoch 13 | train loss:0.8696262836456299,test loss:0.8472501635551453,acc:0.5165550595238095,recall:0.3333333333333333,f1:0.22658702437823108,pre:0.17218501984126983
PRR1 epoch 14 | train loss:0.8699612021446228,test loss:0.8495914340019226,acc:0.51640625,recall:0.3333333333333333,f1:0.22656475281378505,pre:0.17213541666666668
PRR1 epoch 15 | train loss:0.8711564540863037,test loss:0.8480579257011414,acc:0.5165550595238095,recall:0.3333333333333333,f1:0.22670063762584397,pre:0.17218501984126983
PRR1 epoch 16 | train loss:0.8707641363143921,test loss:0.8431236743927002,acc:0.5165364583333333,recall:0.3392857142857143,f1:0.23073621980075837,pre:0.17529451884920638
PRR1 epoch 17 | train loss:0.8701304197311401,test loss:0.841162919998169,acc:0.5164620535714286,recall:0.3333333333333333,f1:0.22657662078485194,pre:0.17215401785714285
PRR1 epoch 18 | train loss:0.8688702583312988,test loss:0.8423121571540833,acc:0.5165550595238095,recall:0.3333333333333333,f1:0.22675177572975982,pre:0.1721850198412698
PRR1 epoch 19 | train loss:0.868570864200592,test loss:0.8443958759307861,acc:0.5164248511904762,recall:0.3333333333333333,f1:0.22657131077907625,pre:0.1721416170634921
PRR1 epoch 20 | train loss:0.8693086504936218,test loss:0.8433526158332825,acc:0.5163318452380953,recall:0.3333333333333333,f1:0.22643007912598706,pre:0.17211061507936506
PRR1 epoch 21 | train loss:0.8689817786216736,test loss:0.8589787483215332,acc:0.43909970238095236,recall:0.3333333333333333,f1:0.20284459108432704,pre:0.14636656746031745
PRR1 epoch 22 | train loss:0.8726087808609009,test loss:0.8494576215744019,acc:0.516703869047619,recall:0.3333333333333333,f1:0.22669133787442144,pre:0.17223462301587297
PRR1 epoch 23 | train loss:0.8673072457313538,test loss:0.8491707444190979,acc:0.4390811011904762,recall:0.3333333333333333,f1:0.2029749429141832,pre:0.14636036706349206
PRR1 epoch 24 | train loss:0.8678718209266663,test loss:0.8455226421356201,acc:0.5163876488095238,recall:0.3333333333333333,f1:0.22655554823739985,pre:0.17212921626984135
PRR1 epoch 25 | train loss:0.8708034753799438,test loss:0.84393709897995,acc:0.5165550595238095,recall:0.3333333333333333,f1:0.22672881731144276,pre:0.17218501984126985
PRR1 epoch 26 | train loss:0.8688064217567444,test loss:0.8486806154251099,acc:0.5165736607142858,recall:0.3333333333333333,f1:0.22659478044679546,pre:0.17219122023809524
PRR1 epoch 27 | train loss:0.8688532710075378,test loss:0.8457186818122864,acc:0.5165922619047619,recall:0.3333333333333333,f1:0.22668579184892845,pre:0.1721974206349206
PRR1 epoch 28 | train loss:0.8699154853820801,test loss:0.8434773683547974,acc:0.5165550595238095,recall:0.3392857142857143,f1:0.23112524485266023,pre:0.1755797371031746
epoch 28 : weight has update
PRR1 epoch 29 | train loss:0.8678820729255676,test loss:0.8427446484565735,acc:0.5164806547619047,recall:0.3392857142857143,f1:0.23080192719853668,pre:0.17541542658730158
PRR1 epoch 30 | train loss:0.8703439235687256,test loss:0.8437033891677856,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.22665488704896913,pre:0.17216021825396824
PRR1 epoch 31 | train loss:0.8678209185600281,test loss:0.8422302603721619,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.22671505098725134,pre:0.17217261904761902
PRR1 epoch 32 | train loss:0.8684229850769043,test loss:0.8416170477867126,acc:0.5161644345238096,recall:0.3333333333333333,f1:0.22644570766429953,pre:0.1720548115079365
PRR1 epoch 33 | train loss:0.8688595294952393,test loss:0.842474639415741,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.22657622912238481,pre:0.17217261904761902
PRR1 epoch 34 | train loss:0.8682748079299927,test loss:0.8462951183319092,acc:0.5165922619047619,recall:0.3333333333333333,f1:0.22679342474476377,pre:0.17219742063492063
PRR1 epoch 35 | train loss:0.8687803149223328,test loss:0.8468096852302551,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.22677227298593025,pre:0.17216021825396824
PRR1 epoch 36 | train loss:0.8673532009124756,test loss:0.8497267961502075,acc:0.516499255952381,recall:0.3333333333333333,f1:0.2265993762148037,pre:0.17216641865079366
PRR1 epoch 37 | train loss:0.8665747046470642,test loss:0.8414178490638733,acc:0.5163690476190477,recall:0.3333333333333333,f1:0.2267305879510346,pre:0.17212301587301587
PRR1 epoch 38 | train loss:0.867949366569519,test loss:0.8448726534843445,acc:0.5163876488095238,recall:0.3333333333333333,f1:0.22653222045491303,pre:0.1721292162698413
PRR1 epoch 39 | train loss:0.8697619438171387,test loss:0.8446665406227112,acc:0.5164620535714286,recall:0.3333333333333333,f1:0.22674273554334604,pre:0.17215401785714285
PRR1 epoch 40 | train loss:0.8673411011695862,test loss:0.8521579504013062,acc:0.43891369047619044,recall:0.3333333333333333,f1:0.20309276164486958,pre:0.14630456349206347
PRR1 epoch 41 | train loss:0.8700889348983765,test loss:0.8423915505409241,acc:0.5166294642857142,recall:0.3333333333333333,f1:0.22654131395847113,pre:0.1722098214285714
PRR1 epoch 42 | train loss:0.8665125966072083,test loss:0.843254804611206,acc:0.516313244047619,recall:0.3333333333333333,f1:0.22664974447866962,pre:0.1721044146825397
PRR1 epoch 43 | train loss:0.8694880604743958,test loss:0.8460696339607239,acc:0.5164248511904762,recall:0.3333333333333333,f1:0.22672168547819743,pre:0.17214161706349212
PRR1 epoch 44 | train loss:0.8668729662895203,test loss:0.8415915966033936,acc:0.5162574404761905,recall:0.3392857142857143,f1:0.2304492167963367,pre:0.1750155009920635
PRR1 epoch 45 | train loss:0.8675654530525208,test loss:0.8432168364524841,acc:0.51640625,recall:0.3333333333333333,f1:0.22664456443684397,pre:0.17213541666666665
PRR1 epoch 46 | train loss:0.8675513863563538,test loss:0.8488113284111023,acc:0.51640625,recall:0.3333333333333333,f1:0.22676484412145287,pre:0.17213541666666668
PRR1 epoch 47 | train loss:0.8675227165222168,test loss:0.8433283567428589,acc:0.5166666666666667,recall:0.3333333333333333,f1:0.22665518255018993,pre:0.17222222222222222
PRR1 epoch 48 | train loss:0.8689590692520142,test loss:0.8448984026908875,acc:0.5165364583333333,recall:0.3333333333333333,f1:0.22669921211348296,pre:0.17217881944444446
PRR1 epoch 49 | train loss:0.866919994354248,test loss:0.8421825170516968,acc:0.5163876488095238,recall:0.3333333333333333,f1:0.22662754416163655,pre:0.1721292162698413
PRR1 epoch 50 | train loss:0.8670492172241211,test loss:0.8469159603118896,acc:0.4390811011904762,recall:0.3333333333333333,f1:0.20306251024708694,pre:0.14636036706349206
PRR1 epoch 51 | train loss:0.8684033155441284,test loss:0.843220055103302,acc:0.5163690476190477,recall:0.3333333333333333,f1:0.2267163626459201,pre:0.17212301587301584
PRR1 epoch 52 | train loss:0.867785632610321,test loss:0.8452126383781433,acc:0.5163876488095238,recall:0.3333333333333333,f1:0.22670820572196046,pre:0.1721292162698413
PRR1 epoch 53 | train loss:0.8680233955383301,test loss:0.8431349396705627,acc:0.5163690476190477,recall:0.3333333333333333,f1:0.22659565606340606,pre:0.17212301587301584
PRR1 epoch 54 | train loss:0.866910994052887,test loss:0.8454986214637756,acc:0.5165364583333333,recall:0.3333333333333333,f1:0.22667382852581364,pre:0.17217881944444444
PRR1 epoch 55 | train loss:0.8683457374572754,test loss:0.8432148098945618,acc:0.516499255952381,recall:0.3333333333333333,f1:0.22663132440933936,pre:0.17216641865079368
PRR1 epoch 56 | train loss:0.8670865893363953,test loss:0.8458988070487976,acc:0.5164620535714286,recall:0.3333333333333333,f1:0.22657724574296614,pre:0.17215401785714282
PRR1 epoch 57 | train loss:0.8665502667427063,test loss:0.8431379199028015,acc:0.5164620535714286,recall:0.3333333333333333,f1:0.2265783826120232,pre:0.17215401785714288
PRR1 epoch 58 | train loss:0.8668245077133179,test loss:0.8419448137283325,acc:0.5163876488095238,recall:0.3333333333333333,f1:0.2266305749369362,pre:0.1721292162698412
PRR1 epoch 59 | train loss:0.8666618466377258,test loss:0.8464087247848511,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.22671739457935283,pre:0.17217261904761902
PRR1 epoch 60 | train loss:0.8669569492340088,test loss:0.8425011038780212,acc:0.5165550595238095,recall:0.3392857142857143,f1:0.23097072553822082,pre:0.1754867311507937
PRR1 epoch 61 | train loss:0.8655472993850708,test loss:0.8480274677276611,acc:0.5165922619047619,recall:0.3333333333333333,f1:0.2268603648276569,pre:0.17219742063492063
PRR1 epoch 62 | train loss:0.8690679669380188,test loss:0.8421685099601746,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.22666099998696035,pre:0.1721602182539683
PRR1 epoch 63 | train loss:0.867899477481842,test loss:0.8422499299049377,acc:0.5166294642857142,recall:0.3333333333333333,f1:0.22671738517758253,pre:0.1722098214285714
PRR1 epoch 64 | train loss:0.8671325445175171,test loss:0.8427311182022095,acc:0.51640625,recall:0.3333333333333333,f1:0.22653207221255803,pre:0.17213541666666668
PRR1 epoch 65 | train loss:0.866044282913208,test loss:0.841560423374176,acc:0.5165364583333333,recall:0.3333333333333333,f1:0.22665805490041935,pre:0.17217881944444446
PRR1 epoch 66 | train loss:0.8665876984596252,test loss:0.8427675366401672,acc:0.5165922619047619,recall:0.3392857142857143,f1:0.23084336743549302,pre:0.17545262896825395
PRR1 epoch 67 | train loss:0.8671721816062927,test loss:0.8417413830757141,acc:0.5166480654761905,recall:0.3333333333333333,f1:0.22682219989907845,pre:0.17221602182539683
PRR1 epoch 68 | train loss:0.8682223558425903,test loss:0.8419812321662903,acc:0.5163876488095238,recall:0.3333333333333333,f1:0.22671383951877555,pre:0.17212921626984132
PRR1 epoch 69 | train loss:0.868724524974823,test loss:0.8449440598487854,acc:0.5163690476190477,recall:0.3333333333333333,f1:0.2267718600413869,pre:0.17212301587301587
PRR1 epoch 70 | train loss:0.8677021265029907,test loss:0.8427989482879639,acc:0.5162760416666666,recall:0.3333333333333333,f1:0.22624050777322724,pre:0.17209201388888892
PRR1 epoch 71 | train loss:0.8680619597434998,test loss:0.8415628671646118,acc:0.5166108630952381,recall:0.3333333333333333,f1:0.2266007494935751,pre:0.17220362103174605
PRR1 epoch 72 | train loss:0.8658067584037781,test loss:0.841963529586792,acc:0.5162760416666666,recall:0.3333333333333333,f1:0.2265504750910809,pre:0.17209201388888892
PRR1 epoch 73 | train loss:0.8666143417358398,test loss:0.8464820981025696,acc:0.5165364583333333,recall:0.34523809523809523,f1:0.23579454228382998,pre:0.1796192956349206
epoch 73 : weight has update
PRR1 epoch 74 | train loss:0.8680062890052795,test loss:0.8443202376365662,acc:0.5164248511904762,recall:0.3333333333333333,f1:0.22671084789626605,pre:0.17214161706349204
PRR1 epoch 75 | train loss:0.8671866059303284,test loss:0.8426574468612671,acc:0.5164434523809524,recall:0.3333333333333333,f1:0.22674072381186003,pre:0.17214781746031746
PRR1 epoch 76 | train loss:0.8669556975364685,test loss:0.8442988991737366,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.22680060207100555,pre:0.17217261904761907
PRR1 epoch 77 | train loss:0.8672099113464355,test loss:0.8464677333831787,acc:0.5164248511904762,recall:0.3333333333333333,f1:0.22680618604744188,pre:0.1721416170634921
PRR1 epoch 78 | train loss:0.866547703742981,test loss:0.8477950692176819,acc:0.5164620535714286,recall:0.3333333333333333,f1:0.2267588129538646,pre:0.17215401785714282
PRR1 epoch 79 | train loss:0.8685089349746704,test loss:0.8428595066070557,acc:0.5166108630952381,recall:0.3333333333333333,f1:0.22646363845207912,pre:0.17220362103174608
PRR1 epoch 80 | train loss:0.866059422492981,test loss:0.8459912538528442,acc:0.51640625,recall:0.3333333333333333,f1:0.22654359983909247,pre:0.1721354166666667
PRR1 epoch 81 | train loss:0.8695200681686401,test loss:0.8435612916946411,acc:0.5163690476190477,recall:0.3333333333333333,f1:0.226484418033636,pre:0.1721230158730159
PRR1 epoch 82 | train loss:0.8679533004760742,test loss:0.8432527780532837,acc:0.5163504464285714,recall:0.3333333333333333,f1:0.22664807567784928,pre:0.17211681547619048
PRR1 epoch 83 | train loss:0.8665100336074829,test loss:0.8443261384963989,acc:0.516499255952381,recall:0.3392857142857143,f1:0.23073807829807197,pre:0.17518911210317462
PRR1 epoch 84 | train loss:0.8661333918571472,test loss:0.8437126278877258,acc:0.5165364583333333,recall:0.3333333333333333,f1:0.22672700076046248,pre:0.17217881944444444
PRR1 epoch 85 | train loss:0.8672318458557129,test loss:0.8424500226974487,acc:0.5164248511904762,recall:0.3333333333333333,f1:0.22656059828224864,pre:0.17214161706349212
PRR1 epoch 86 | train loss:0.8677344918251038,test loss:0.8472455143928528,acc:0.4392485119047619,recall:0.3392857142857143,f1:0.2071806683258164,pre:0.14948536706349208
PRR1 epoch 87 | train loss:0.8673579692840576,test loss:0.843334436416626,acc:0.5163690476190477,recall:0.3333333333333333,f1:0.2265186305969075,pre:0.17212301587301596
PRR1 epoch 88 | train loss:0.8682425022125244,test loss:0.8424763083457947,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.22669640673238375,pre:0.17217261904761902
PRR1 epoch 89 | train loss:0.866522490978241,test loss:0.8433210253715515,acc:0.5164434523809524,recall:0.3333333333333333,f1:0.22665857903283465,pre:0.17214781746031746
PRR1 epoch 90 | train loss:0.8684353828430176,test loss:0.8423597812652588,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.22680529124276166,pre:0.17216021825396824
PRR1 epoch 91 | train loss:0.867356538772583,test loss:0.8435391783714294,acc:0.5165364583333333,recall:0.3333333333333333,f1:0.2266248492485148,pre:0.17217881944444444
PRR1 epoch 92 | train loss:0.8680903911590576,test loss:0.842052698135376,acc:0.5165550595238095,recall:0.3333333333333333,f1:0.22670697505513535,pre:0.1721850198412698
PRR1 epoch 93 | train loss:0.8661484718322754,test loss:0.8430384993553162,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.22675124232091723,pre:0.17217261904761907
PRR1 epoch 94 | train loss:0.867698073387146,test loss:0.846392810344696,acc:0.5163690476190477,recall:0.3333333333333333,f1:0.22651883484230334,pre:0.17212301587301582
PRR1 epoch 95 | train loss:0.8669410943984985,test loss:0.8443324565887451,acc:0.5164620535714286,recall:0.3333333333333333,f1:0.22674947664093073,pre:0.17215401785714288
PRR1 epoch 96 | train loss:0.8673089146614075,test loss:0.8451888561248779,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.2267260623890979,pre:0.17216021825396827
PRR1 epoch 97 | train loss:0.8673475384712219,test loss:0.8426238894462585,acc:0.5165364583333333,recall:0.3333333333333333,f1:0.22682672069304946,pre:0.17217881944444446
PRR1 epoch 98 | train loss:0.8659406900405884,test loss:0.8447943329811096,acc:0.5165550595238095,recall:0.3333333333333333,f1:0.22679464772387387,pre:0.17218501984126985
PRR1 epoch 99 | train loss:0.8661468029022217,test loss:0.842919111251831,acc:0.5163504464285714,recall:0.3333333333333333,f1:0.2266756200548742,pre:0.17211681547619048
PRR1 epoch 100 | train loss:0.8661958575248718,test loss:0.8437187671661377,acc:0.5162760416666666,recall:0.3333333333333333,f1:0.22652728502542493,pre:0.1720920138888889
PRR1 epoch 101 | train loss:0.8682227730751038,test loss:0.8436930775642395,acc:0.516499255952381,recall:0.3333333333333333,f1:0.22681742687589398,pre:0.17216641865079363
PRR1 epoch 102 | train loss:0.8699958920478821,test loss:0.8453640341758728,acc:0.5164620535714286,recall:0.3333333333333333,f1:0.226389957619428,pre:0.17215401785714285
PRR1 epoch 103 | train loss:0.867866039276123,test loss:0.8424168229103088,acc:0.5166108630952381,recall:0.3333333333333333,f1:0.226766944620668,pre:0.17220362103174605
PRR1 epoch 104 | train loss:0.8669262528419495,test loss:0.8419122099876404,acc:0.5165922619047619,recall:0.3333333333333333,f1:0.22650842209570768,pre:0.17219742063492063
PRR1 epoch 105 | train loss:0.8677364587783813,test loss:0.8450813889503479,acc:0.5165364583333333,recall:0.3392857142857143,f1:0.23014519471727254,pre:0.17455047123015874
PRR1 epoch 106 | train loss:0.8666534423828125,test loss:0.8465258479118347,acc:0.516499255952381,recall:0.3392857142857143,f1:0.23094951199934072,pre:0.17560763888888892
PRR1 epoch 107 | train loss:0.8666282892227173,test loss:0.8419557213783264,acc:0.5164620535714286,recall:0.3392857142857143,f1:0.2307363906758418,pre:0.1751767113095238
PRR1 epoch 108 | train loss:0.8660282492637634,test loss:0.8419708013534546,acc:0.5163690476190477,recall:0.3333333333333333,f1:0.22645176581077103,pre:0.17212301587301584
PRR1 epoch 109 | train loss:0.8667187094688416,test loss:0.8482418656349182,acc:0.516703869047619,recall:0.3333333333333333,f1:0.22669721528471978,pre:0.17223462301587303
PRR1 epoch 110 | train loss:0.8668444752693176,test loss:0.8445391058921814,acc:0.5163876488095238,recall:0.3333333333333333,f1:0.22665504838750938,pre:0.1721292162698413
PRR1 epoch 111 | train loss:0.8664451241493225,test loss:0.842245876789093,acc:0.5163504464285714,recall:0.3333333333333333,f1:0.22668811498726413,pre:0.17211681547619048
PRR1 epoch 112 | train loss:0.8666945099830627,test loss:0.8447232842445374,acc:0.51640625,recall:0.3333333333333333,f1:0.226663393070036,pre:0.17213541666666665
PRR1 epoch 113 | train loss:0.8662188649177551,test loss:0.8426603674888611,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.22641461808912292,pre:0.17216021825396827
PRR1 epoch 114 | train loss:0.8678945302963257,test loss:0.8419025540351868,acc:0.5163318452380953,recall:0.3333333333333333,f1:0.2266499438757348,pre:0.17211061507936512
PRR1 epoch 115 | train loss:0.8659615516662598,test loss:0.8455350399017334,acc:0.5162946428571429,recall:0.3333333333333333,f1:0.22635954412875164,pre:0.1720982142857143
PRR1 epoch 116 | train loss:0.8669022917747498,test loss:0.8430104851722717,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.22672975587377422,pre:0.17216021825396827
PRR1 epoch 117 | train loss:0.8664553761482239,test loss:0.8432972431182861,acc:0.516499255952381,recall:0.3333333333333333,f1:0.22687727782367453,pre:0.17216641865079363
PRR1 epoch 118 | train loss:0.8662699460983276,test loss:0.8447906970977783,acc:0.516703869047619,recall:0.3333333333333333,f1:0.2264962350054038,pre:0.17223462301587297
PRR1 epoch 119 | train loss:0.8665452599525452,test loss:0.8449485301971436,acc:0.5165550595238095,recall:0.3333333333333333,f1:0.22662296179037703,pre:0.17218501984126985
PRR1 epoch 120 | train loss:0.8669103980064392,test loss:0.8438534140586853,acc:0.5162946428571429,recall:0.3333333333333333,f1:0.22656280128159853,pre:0.17209821428571428
PRR1 epoch 121 | train loss:0.8680473566055298,test loss:0.8444276452064514,acc:0.516499255952381,recall:0.3392857142857143,f1:0.23079230209968155,pre:0.17518911210317464
PRR1 epoch 122 | train loss:0.8669036626815796,test loss:0.8412125706672668,acc:0.5164620535714286,recall:0.3333333333333333,f1:0.226773743790061,pre:0.17215401785714288
PRR1 epoch 123 | train loss:0.86722731590271,test loss:0.8429242372512817,acc:0.5163876488095238,recall:0.3333333333333333,f1:0.2266271385408746,pre:0.1721292162698413
PRR1 epoch 124 | train loss:0.8673980236053467,test loss:0.8431202173233032,acc:0.5165364583333333,recall:0.3333333333333333,f1:0.22676542028513938,pre:0.1721788194444445
PRR1 epoch 125 | train loss:0.8659449219703674,test loss:0.8436539173126221,acc:0.5164248511904762,recall:0.3333333333333333,f1:0.2266591335704553,pre:0.17214161706349201
PRR1 epoch 126 | train loss:0.8669105172157288,test loss:0.8440768122673035,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.2266308322593372,pre:0.17216021825396824
PRR1 epoch 127 | train loss:0.8699719309806824,test loss:0.8424264192581177,acc:0.5163690476190477,recall:0.3333333333333333,f1:0.22661527499164721,pre:0.1721230158730159
PRR1 epoch 128 | train loss:0.8669602870941162,test loss:0.8433706760406494,acc:0.516499255952381,recall:0.3333333333333333,f1:0.22661582542176892,pre:0.17216641865079366
PRR1 epoch 129 | train loss:0.8678746223449707,test loss:0.842884361743927,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.22683141299601592,pre:0.17217261904761907
PRR1 epoch 130 | train loss:0.8669399619102478,test loss:0.8452253937721252,acc:0.5162946428571429,recall:0.3333333333333333,f1:0.22656938219736517,pre:0.17209821428571434
PRR1 epoch 131 | train loss:0.8674492835998535,test loss:0.8443978428840637,acc:0.5163318452380953,recall:0.3333333333333333,f1:0.2265209726462029,pre:0.17211061507936512
PRR1 epoch 132 | train loss:0.8670182228088379,test loss:0.843298614025116,acc:0.5166108630952381,recall:0.33928571428571425,f1:0.23104594553174782,pre:0.17559833829365082
PRR1 epoch 133 | train loss:0.8665549755096436,test loss:0.8419376611709595,acc:0.5164248511904762,recall:0.3333333333333333,f1:0.22669163778616672,pre:0.17214161706349212
PRR1 epoch 134 | train loss:0.8672007918357849,test loss:0.8416900038719177,acc:0.51640625,recall:0.3333333333333333,f1:0.2267502704553492,pre:0.17213541666666668
PRR1 epoch 135 | train loss:0.8657274842262268,test loss:0.8444768190383911,acc:0.5165736607142858,recall:0.3333333333333333,f1:0.2267513262259814,pre:0.17219122023809524
PRR1 epoch 136 | train loss:0.8671137690544128,test loss:0.8442160487174988,acc:0.5165922619047619,recall:0.3333333333333333,f1:0.2267752288887282,pre:0.1721974206349206
PRR1 epoch 137 | train loss:0.867991030216217,test loss:0.8461251854896545,acc:0.4390438988095238,recall:0.3333333333333333,f1:0.20314641282390017,pre:0.1463479662698413
PRR1 epoch 138 | train loss:0.8666573762893677,test loss:0.8423629403114319,acc:0.5164248511904762,recall:0.3333333333333333,f1:0.22684126897760828,pre:0.17214161706349212
PRR1 epoch 139 | train loss:0.8676223754882812,test loss:0.8416326642036438,acc:0.5166480654761905,recall:0.3333333333333333,f1:0.2266406581238167,pre:0.1722160218253968
PRR1 epoch 140 | train loss:0.8663636445999146,test loss:0.8442651629447937,acc:0.5165736607142858,recall:0.3333333333333333,f1:0.2268956252057835,pre:0.17219122023809527
PRR1 epoch 141 | train loss:0.8671032190322876,test loss:0.8442094922065735,acc:0.5164248511904762,recall:0.3333333333333333,f1:0.22665338851670777,pre:0.17214161706349212
PRR1 epoch 142 | train loss:0.8677719235420227,test loss:0.8432152271270752,acc:0.51640625,recall:0.3333333333333333,f1:0.22670100224040804,pre:0.17213541666666665
PRR1 epoch 143 | train loss:0.8663846850395203,test loss:0.8486452698707581,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.22664271051073812,pre:0.17216021825396824
PRR1 epoch 144 | train loss:0.8670020699501038,test loss:0.84195476770401,acc:0.5165178571428571,recall:0.3333333333333333,f1:0.2267182973560978,pre:0.17217261904761902
PRR1 epoch 145 | train loss:0.8676774501800537,test loss:0.8444503545761108,acc:0.5163876488095238,recall:0.3333333333333333,f1:0.22676323805085596,pre:0.1721292162698413
PRR1 epoch 146 | train loss:0.8671543598175049,test loss:0.8450523018836975,acc:0.5164806547619047,recall:0.3333333333333333,f1:0.22683634633743338,pre:0.17216021825396827
PRR1 epoch 147 | train loss:0.8673141598701477,test loss:0.8483336567878723,acc:0.5166666666666667,recall:0.3333333333333333,f1:0.22657694346739116,pre:0.17222222222222225
PRR1 epoch 148 | train loss:0.8670154809951782,test loss:0.8445011973381042,acc:0.5165178571428571,recall:0.3392857142857143,f1:0.2304521427702167,pre:0.1749162946428571
PRR1 epoch 149 | train loss:0.8664713501930237,test loss:0.8435128331184387,acc:0.5165550595238095,recall:0.3333333333333333,f1:0.22681378286360912,pre:0.1721850198412698
PRR1 epoch 150 | train loss:0.8674233555793762,test loss:0.8445321917533875,acc:0.5166480654761905,recall:0.3333333333333333,f1:0.2268102060434348,pre:0.17221602182539683
training has finished used time : 3067.2452762126923
result has saved!
True
*---------------convert_trait---------------*
protein
oil
Palmitic
Steartic
Oleic
Linoleic
Linolenic
R1
R8
Hgt
SdWgt
Yield
convert trait has finished!
*---------------convert_trait---------------*
trait shape (10431, 18)
trait shape (1, 10431)
df shape (20087, 42195)
(5000, 32032) (5431, 32032)
train dataset already completed!
5000
test dataset already completed!
5431
SCN3 epoch 1 | train loss:0.5635181665420532,test loss:0.5468491315841675,acc:0.8301929175475686,recall:0.5,f1:0.45344541402291466,pre:0.4150964587737843
epoch 1 : weight has update
SCN3 epoch 2 | train loss:0.4815498888492584,test loss:0.6102719902992249,acc:0.8306752114164905,recall:0.5,f1:0.45356539954115216,pre:0.41533760570824524
epoch 2 : weight has update
SCN3 epoch 3 | train loss:0.47628045082092285,test loss:0.5556458234786987,acc:0.829469476744186,recall:0.5,f1:0.45325435885886195,pre:0.414734738372093
SCN3 epoch 4 | train loss:0.4887961447238922,test loss:0.4666377604007721,acc:0.8229320824524312,recall:0.5086843709852105,f1:0.4776931731631941,pre:0.5622414855862038
epoch 4 : weight has update
SCN3 epoch 5 | train loss:0.4957137405872345,test loss:0.48096194863319397,acc:0.829710623678647,recall:0.5,f1:0.453295765357422,pre:0.4148553118393235
SCN3 epoch 6 | train loss:0.49261853098869324,test loss:0.5004856586456299,acc:0.8040928911205074,recall:0.4945696394701666,f1:0.4652607896425757,pre:0.4729510339767155
SCN3 epoch 7 | train loss:0.48310646414756775,test loss:0.4559440016746521,acc:0.8299517706131078,recall:0.5,f1:0.4533469020260766,pre:0.4149758853065539
SCN3 epoch 8 | train loss:0.4848896861076355,test loss:0.4567320644855499,acc:0.829469476744186,recall:0.5,f1:0.45322772030294683,pre:0.414734738372093
SCN3 epoch 9 | train loss:0.47194749116897583,test loss:0.4665692448616028,acc:0.829710623678647,recall:0.5,f1:0.45329595197239264,pre:0.4148553118393235
SCN3 epoch 10 | train loss:0.4687731862068176,test loss:0.4796597361564636,acc:0.8292283298097252,recall:0.5,f1:0.4531310965650775,pre:0.4146141649048626
SCN3 epoch 11 | train loss:0.4652963876724243,test loss:0.4565897285938263,acc:0.829710623678647,recall:0.5,f1:0.4533026048974398,pre:0.4148553118393235
SCN3 epoch 12 | train loss:0.4637003242969513,test loss:0.5904282927513123,acc:0.8304340644820296,recall:0.5,f1:0.45350859051472264,pre:0.4152170322410148
SCN3 epoch 13 | train loss:0.46563759446144104,test loss:0.4804374873638153,acc:0.8289871828752643,recall:0.5,f1:0.45304168318484683,pre:0.41449359143763215
SCN3 epoch 14 | train loss:0.4669961631298065,test loss:0.45687150955200195,acc:0.8306752114164905,recall:0.5,f1:0.45352206631531594,pre:0.41533760570824524
SCN3 epoch 15 | train loss:0.46627381443977356,test loss:0.46418654918670654,acc:0.829710623678647,recall:0.5,f1:0.4533085092744228,pre:0.4148553118393235
SCN3 epoch 16 | train loss:0.46676579117774963,test loss:0.4628937244415283,acc:0.8282637420718817,recall:0.5,f1:0.4528037289457944,pre:0.41413187103594085
SCN3 epoch 17 | train loss:0.4643864333629608,test loss:0.46011924743652344,acc:0.8311575052854123,recall:0.5,f1:0.4537086093259967,pre:0.41557875264270616
SCN3 epoch 18 | train loss:0.46547192335128784,test loss:0.4556329548358917,acc:0.8301929175475686,recall:0.5,f1:0.45349422386010985,pre:0.4150964587737843
SCN3 epoch 19 | train loss:0.4637724757194519,test loss:0.4558384120464325,acc:0.8301929175475686,recall:0.5,f1:0.4534458822945401,pre:0.4150964587737843
SCN3 epoch 20 | train loss:0.4632624685764313,test loss:0.4650898873806,acc:0.829710623678647,recall:0.5,f1:0.453347159791869,pre:0.4148553118393235
SCN3 epoch 21 | train loss:0.46376675367355347,test loss:0.4578062891960144,acc:0.829469476744186,recall:0.5,f1:0.45318189573992135,pre:0.414734738372093
SCN3 epoch 22 | train loss:0.4635886251926422,test loss:0.458195298910141,acc:0.8299517706131078,recall:0.5,f1:0.4533591685913692,pre:0.4149758853065539
SCN3 epoch 23 | train loss:0.4633989632129669,test loss:0.45689353346824646,acc:0.8304340644820296,recall:0.5,f1:0.45352424309201816,pre:0.4152170322410148
SCN3 epoch 24 | train loss:0.46524742245674133,test loss:0.45778512954711914,acc:0.8304340644820296,recall:0.5,f1:0.4534976650879491,pre:0.4152170322410148
SCN3 epoch 25 | train loss:0.46230360865592957,test loss:0.4563447833061218,acc:0.829710623678647,recall:0.5,f1:0.45334062368224487,pre:0.4148553118393235
SCN3 epoch 26 | train loss:0.4647340178489685,test loss:0.45701083540916443,acc:0.8299517706131078,recall:0.5,f1:0.45342329609131077,pre:0.4149758853065539
SCN3 epoch 27 | train loss:0.46443450450897217,test loss:0.4594078063964844,acc:0.8292283298097252,recall:0.5,f1:0.45317881634281354,pre:0.4146141649048626
SCN3 epoch 28 | train loss:0.46420052647590637,test loss:0.45661091804504395,acc:0.829710623678647,recall:0.5,f1:0.45328350365523956,pre:0.4148553118393235
SCN3 epoch 29 | train loss:0.4630526602268219,test loss:0.45900726318359375,acc:0.829469476744186,recall:0.5,f1:0.4532534760028726,pre:0.414734738372093
SCN3 epoch 30 | train loss:0.46506309509277344,test loss:0.4551989436149597,acc:0.8304340644820296,recall:0.5,f1:0.4535259737840699,pre:0.4152170322410148
SCN3 epoch 31 | train loss:0.46297866106033325,test loss:0.4560222625732422,acc:0.8304340644820296,recall:0.5,f1:0.45352325961656265,pre:0.4152170322410148
SCN3 epoch 32 | train loss:0.46292129158973694,test loss:0.45684245228767395,acc:0.829469476744186,recall:0.5,f1:0.45324426776974275,pre:0.414734738372093
SCN3 epoch 33 | train loss:0.46442413330078125,test loss:0.4552032947540283,acc:0.8311575052854123,recall:0.5,f1:0.4536595558759784,pre:0.41557875264270616
SCN3 epoch 34 | train loss:0.463265985250473,test loss:0.4551185667514801,acc:0.8306752114164905,recall:0.5,f1:0.45349860672138825,pre:0.41533760570824524
SCN3 epoch 35 | train loss:0.4665032923221588,test loss:0.45686501264572144,acc:0.829710623678647,recall:0.5,f1:0.4532774599953964,pre:0.4148553118393235
SCN3 epoch 36 | train loss:0.46321502327919006,test loss:0.4547346532344818,acc:0.8309163583509513,recall:0.5,f1:0.4535984632214487,pre:0.4154581791754757
SCN3 epoch 37 | train loss:0.46421658992767334,test loss:0.45604440569877625,acc:0.8299517706131078,recall:0.5,f1:0.45339746993545715,pre:0.4149758853065539
SCN3 epoch 38 | train loss:0.4635653793811798,test loss:0.4563449025154114,acc:0.829710623678647,recall:0.5,f1:0.4533128328142179,pre:0.4148553118393235
SCN3 epoch 39 | train loss:0.4646838903427124,test loss:0.45496666431427,acc:0.8306752114164905,recall:0.5,f1:0.4536170809873512,pre:0.41533760570824524
SCN3 epoch 40 | train loss:0.46352478861808777,test loss:0.45663246512413025,acc:0.8299517706131078,recall:0.5,f1:0.45337779374870874,pre:0.4149758853065539
SCN3 epoch 41 | train loss:0.4622631072998047,test loss:0.4560505151748657,acc:0.8301929175475686,recall:0.5,f1:0.45343311415723464,pre:0.4150964587737843
SCN3 epoch 42 | train loss:0.46282514929771423,test loss:0.464433878660202,acc:0.8289871828752643,recall:0.5,f1:0.4531101326721202,pre:0.41449359143763215
SCN3 epoch 43 | train loss:0.4624960422515869,test loss:0.4574092924594879,acc:0.8299517706131078,recall:0.5,f1:0.45337405988746615,pre:0.4149758853065539
SCN3 epoch 44 | train loss:0.46361273527145386,test loss:0.456282377243042,acc:0.8301929175475686,recall:0.5,f1:0.4534765043634281,pre:0.4150964587737843
SCN3 epoch 45 | train loss:0.4631040096282959,test loss:0.4559710621833801,acc:0.8301929175475686,recall:0.5,f1:0.4534602546161742,pre:0.4150964587737843
SCN3 epoch 46 | train loss:0.46460920572280884,test loss:0.4557446837425232,acc:0.8304340644820296,recall:0.5,f1:0.4535134700458675,pre:0.4152170322410148
SCN3 epoch 47 | train loss:0.4652044475078583,test loss:0.45748886466026306,acc:0.8289871828752643,recall:0.5,f1:0.45298599018905517,pre:0.41449359143763215
SCN3 epoch 48 | train loss:0.4625455439090729,test loss:0.4547587037086487,acc:0.8309163583509513,recall:0.5,f1:0.453637317767332,pre:0.4154581791754757
SCN3 epoch 49 | train loss:0.4629915654659271,test loss:0.4574923813343048,acc:0.8289871828752643,recall:0.5,f1:0.4530654603122361,pre:0.41449359143763215
SCN3 epoch 50 | train loss:0.46186238527297974,test loss:0.4584311544895172,acc:0.829710623678647,recall:0.5,f1:0.4532587257738324,pre:0.4148553118393235
SCN3 epoch 51 | train loss:0.46131256222724915,test loss:0.45638009905815125,acc:0.829710623678647,recall:0.5,f1:0.45329147057959907,pre:0.4148553118393235
SCN3 epoch 52 | train loss:0.46206730604171753,test loss:0.4554697871208191,acc:0.8309163583509513,recall:0.5,f1:0.453543248414963,pre:0.4154581791754757
SCN3 epoch 53 | train loss:0.46348074078559875,test loss:0.4564160704612732,acc:0.8299517706131078,recall:0.5,f1:0.45337563409704235,pre:0.4149758853065539
SCN3 epoch 54 | train loss:0.4646206796169281,test loss:0.4562910199165344,acc:0.8306752114164905,recall:0.5,f1:0.45356131430323576,pre:0.41533760570824524
SCN3 epoch 55 | train loss:0.4612811207771301,test loss:0.45579829812049866,acc:0.8306752114164905,recall:0.5,f1:0.45358123728173555,pre:0.41533760570824524
SCN3 epoch 56 | train loss:0.4624057710170746,test loss:0.45482343435287476,acc:0.8306752114164905,recall:0.5,f1:0.45356238471275256,pre:0.41533760570824524
SCN3 epoch 57 | train loss:0.4609662592411041,test loss:0.4563450813293457,acc:0.829710623678647,recall:0.5,f1:0.45330636240563077,pre:0.4148553118393235
SCN3 epoch 58 | train loss:0.46207287907600403,test loss:0.4562574028968811,acc:0.8304340644820296,recall:0.5,f1:0.4534844105225368,pre:0.4152170322410148
SCN3 epoch 59 | train loss:0.46500954031944275,test loss:0.4567265212535858,acc:0.829469476744186,recall:0.5,f1:0.4532193491824298,pre:0.414734738372093
SCN3 epoch 60 | train loss:0.4630069434642792,test loss:0.45719894766807556,acc:0.829469476744186,recall:0.5,f1:0.4531466902096811,pre:0.414734738372093
SCN3 epoch 61 | train loss:0.4618372321128845,test loss:0.4564744234085083,acc:0.829710623678647,recall:0.5,f1:0.45329730517682576,pre:0.4148553118393235
SCN3 epoch 62 | train loss:0.462501585483551,test loss:0.4570706784725189,acc:0.8299517706131078,recall:0.5,f1:0.45329264114216694,pre:0.4149758853065539
SCN3 epoch 63 | train loss:0.4641638696193695,test loss:0.45750129222869873,acc:0.8289871828752643,recall:0.5,f1:0.4530529741311135,pre:0.41449359143763215
SCN3 epoch 64 | train loss:0.4629637598991394,test loss:0.4563816785812378,acc:0.829710623678647,recall:0.5,f1:0.4533175343494819,pre:0.4148553118393235
SCN3 epoch 65 | train loss:0.46476927399635315,test loss:0.45675450563430786,acc:0.829710623678647,recall:0.5,f1:0.4532889803829933,pre:0.4148553118393235
SCN3 epoch 66 | train loss:0.4628187417984009,test loss:0.4558428227901459,acc:0.8301929175475686,recall:0.5,f1:0.45342151837331357,pre:0.4150964587737843
SCN3 epoch 67 | train loss:0.46239224076271057,test loss:0.45517411828041077,acc:0.8306752114164905,recall:0.5,f1:0.45350076531968764,pre:0.41533760570824524
SCN3 epoch 68 | train loss:0.461781769990921,test loss:0.4560309052467346,acc:0.8299517706131078,recall:0.5,f1:0.4534069595628853,pre:0.4149758853065539
SCN3 epoch 69 | train loss:0.4633014500141144,test loss:0.4563533365726471,acc:0.8301929175475686,recall:0.5,f1:0.4534026213999971,pre:0.4150964587737843
SCN3 epoch 70 | train loss:0.4626278579235077,test loss:0.4563940167427063,acc:0.829710623678647,recall:0.5,f1:0.45324101074614054,pre:0.4148553118393235
SCN3 epoch 71 | train loss:0.46416687965393066,test loss:0.4592967927455902,acc:0.8282637420718817,recall:0.5,f1:0.4528073417670467,pre:0.41413187103594085
SCN3 epoch 72 | train loss:0.4622460901737213,test loss:0.4559246301651001,acc:0.8304340644820296,recall:0.5,f1:0.45352611403254584,pre:0.4152170322410148
SCN3 epoch 73 | train loss:0.4631177484989166,test loss:0.4563455879688263,acc:0.829710623678647,recall:0.5,f1:0.4533281494546033,pre:0.4148553118393235
SCN3 epoch 74 | train loss:0.4633145034313202,test loss:0.4573579728603363,acc:0.8301929175475686,recall:0.5,f1:0.4534574276027123,pre:0.4150964587737843
SCN3 epoch 75 | train loss:0.46379461884498596,test loss:0.458255797624588,acc:0.8285048890063424,recall:0.5,f1:0.4529107606513011,pre:0.4142524445031712
SCN3 epoch 76 | train loss:0.46131613850593567,test loss:0.4551998972892761,acc:0.8304340644820296,recall:0.5,f1:0.4534972441816847,pre:0.4152170322410148
SCN3 epoch 77 | train loss:0.46379056572914124,test loss:0.4559997320175171,acc:0.8299517706131078,recall:0.5,f1:0.4533713075977126,pre:0.4149758853065539
SCN3 epoch 78 | train loss:0.46244239807128906,test loss:0.45596614480018616,acc:0.8299517706131078,recall:0.5,f1:0.4534085611498217,pre:0.4149758853065539
SCN3 epoch 79 | train loss:0.4636685252189636,test loss:0.4560329020023346,acc:0.8306752114164905,recall:0.5,f1:0.45353990474558836,pre:0.41533760570824524
SCN3 epoch 80 | train loss:0.4615781903266907,test loss:0.4561796486377716,acc:0.8301929175475686,recall:0.5,f1:0.4534192434805196,pre:0.4150964587737843
SCN3 epoch 81 | train loss:0.4633502960205078,test loss:0.45492082834243774,acc:0.8306752114164905,recall:0.5,f1:0.45356083165052985,pre:0.41533760570824524
SCN3 epoch 82 | train loss:0.4633161723613739,test loss:0.4556327164173126,acc:0.8301929175475686,recall:0.5,f1:0.45341743883006663,pre:0.4150964587737843
SCN3 epoch 83 | train loss:0.4628959596157074,test loss:0.4571909010410309,acc:0.829469476744186,recall:0.5,f1:0.453285253952356,pre:0.414734738372093
SCN3 epoch 84 | train loss:0.4627237021923065,test loss:0.45457422733306885,acc:0.8309163583509513,recall:0.5,f1:0.45368080055759225,pre:0.4154581791754757
SCN3 epoch 85 | train loss:0.4618748426437378,test loss:0.4570770561695099,acc:0.8299517706131078,recall:0.5,f1:0.4533728107397026,pre:0.4149758853065539
SCN3 epoch 86 | train loss:0.46401214599609375,test loss:0.4563489854335785,acc:0.829710623678647,recall:0.5,f1:0.4532851551532777,pre:0.4148553118393235
SCN3 epoch 87 | train loss:0.4622858166694641,test loss:0.4580177068710327,acc:0.8299517706131078,recall:0.5,f1:0.45337368496034275,pre:0.4149758853065539
SCN3 epoch 88 | train loss:0.4627735912799835,test loss:0.4544532597064972,acc:0.8309163583509513,recall:0.5,f1:0.453630585407763,pre:0.4154581791754757
SCN3 epoch 89 | train loss:0.46256864070892334,test loss:0.4579031765460968,acc:0.8289871828752643,recall:0.5,f1:0.45307958582975044,pre:0.41449359143763215
SCN3 epoch 90 | train loss:0.46134138107299805,test loss:0.456981360912323,acc:0.8304340644820296,recall:0.5,f1:0.4534866273827317,pre:0.4152170322410148
SCN3 epoch 91 | train loss:0.46266791224479675,test loss:0.45563462376594543,acc:0.8301929175475686,recall:0.5,f1:0.4534648704428967,pre:0.4150964587737843
SCN3 epoch 92 | train loss:0.4615699052810669,test loss:0.4567297399044037,acc:0.829469476744186,recall:0.5,f1:0.4532186337944118,pre:0.414734738372093
SCN3 epoch 93 | train loss:0.4640175700187683,test loss:0.455211341381073,acc:0.8306752114164905,recall:0.5,f1:0.4536086970340589,pre:0.41533760570824524
SCN3 epoch 94 | train loss:0.4638597071170807,test loss:0.45547938346862793,acc:0.8304340644820296,recall:0.5,f1:0.4535413280286951,pre:0.4152170322410148
SCN3 epoch 95 | train loss:0.4621884226799011,test loss:0.45635321736335754,acc:0.829710623678647,recall:0.5,f1:0.45333203900865454,pre:0.4148553118393235
SCN3 epoch 96 | train loss:0.4619075655937195,test loss:0.4569149911403656,acc:0.829469476744186,recall:0.5,f1:0.45324825517547856,pre:0.414734738372093
SCN3 epoch 97 | train loss:0.46393051743507385,test loss:0.45863649249076843,acc:0.829710623678647,recall:0.5,f1:0.4532556605717075,pre:0.4148553118393235
SCN3 epoch 98 | train loss:0.4627358019351959,test loss:0.4555802345275879,acc:0.8301929175475686,recall:0.5,f1:0.4534311293066695,pre:0.4150964587737843
SCN3 epoch 99 | train loss:0.46312376856803894,test loss:0.45604032278060913,acc:0.8301929175475686,recall:0.5,f1:0.4534928790529562,pre:0.4150964587737843
SCN3 epoch 100 | train loss:0.46144741773605347,test loss:0.4573310613632202,acc:0.829469476744186,recall:0.5,f1:0.45322937857054874,pre:0.414734738372093
SCN3 epoch 101 | train loss:0.46255502104759216,test loss:0.45833951234817505,acc:0.8285048890063424,recall:0.5,f1:0.45287994310392315,pre:0.4142524445031712
SCN3 epoch 102 | train loss:0.4643945097923279,test loss:0.45521727204322815,acc:0.8306752114164905,recall:0.5,f1:0.45358291448016025,pre:0.41533760570824524
SCN3 epoch 103 | train loss:0.4666184186935425,test loss:0.4568406045436859,acc:0.829710623678647,recall:0.5,f1:0.45327512360220634,pre:0.4148553118393235
SCN3 epoch 104 | train loss:0.461300253868103,test loss:0.4583812654018402,acc:0.8306752114164905,recall:0.5,f1:0.4536164505083998,pre:0.41533760570824524
SCN3 epoch 105 | train loss:0.4644714295864105,test loss:0.4569455087184906,acc:0.829710623678647,recall:0.5,f1:0.4532081015313355,pre:0.4148553118393235
SCN3 epoch 106 | train loss:0.46166908740997314,test loss:0.45599475502967834,acc:0.8299517706131078,recall:0.5,f1:0.4532544615660201,pre:0.4149758853065539
SCN3 epoch 107 | train loss:0.4618154764175415,test loss:0.455793172121048,acc:0.8304340644820296,recall:0.5,f1:0.4534717598924294,pre:0.4152170322410148
SCN3 epoch 108 | train loss:0.4626449644565582,test loss:0.45483988523483276,acc:0.8313986522198732,recall:0.5,f1:0.45378401928965617,pre:0.4156993261099366
SCN3 epoch 109 | train loss:0.46228742599487305,test loss:0.4552237093448639,acc:0.8306752114164905,recall:0.5,f1:0.4535816856536412,pre:0.41533760570824524
SCN3 epoch 110 | train loss:0.46451646089553833,test loss:0.4569653272628784,acc:0.829469476744186,recall:0.5,f1:0.453200234339677,pre:0.414734738372093
SCN3 epoch 111 | train loss:0.4632090628147125,test loss:0.4572712779045105,acc:0.829710623678647,recall:0.5,f1:0.45328343867705334,pre:0.4148553118393235
SCN3 epoch 112 | train loss:0.4624704420566559,test loss:0.45676764845848083,acc:0.8306752114164905,recall:0.5,f1:0.45347627856710404,pre:0.41533760570824524
SCN3 epoch 113 | train loss:0.4612180292606354,test loss:0.4577637016773224,acc:0.8292283298097252,recall:0.5,f1:0.4531512085204331,pre:0.4146141649048626
SCN3 epoch 114 | train loss:0.46240025758743286,test loss:0.45570021867752075,acc:0.8301929175475686,recall:0.5,f1:0.4533879743599329,pre:0.4150964587737843
SCN3 epoch 115 | train loss:0.4617411494255066,test loss:0.45793160796165466,acc:0.8287460359408033,recall:0.5,f1:0.4529442820846052,pre:0.41437301797040166
SCN3 epoch 116 | train loss:0.462359219789505,test loss:0.4567583203315735,acc:0.829469476744186,recall:0.5,f1:0.453196176429503,pre:0.414734738372093
SCN3 epoch 117 | train loss:0.4647985100746155,test loss:0.454164981842041,acc:0.8311575052854123,recall:0.5,f1:0.45365081371224747,pre:0.41557875264270616
SCN3 epoch 118 | train loss:0.4620460271835327,test loss:0.45641806721687317,acc:0.829710623678647,recall:0.5,f1:0.45329213817990693,pre:0.4148553118393235
SCN3 epoch 119 | train loss:0.4616188704967499,test loss:0.45524322986602783,acc:0.8304340644820296,recall:0.5,f1:0.4535206513161356,pre:0.4152170322410148
SCN3 epoch 120 | train loss:0.46290940046310425,test loss:0.45602306723594666,acc:0.8299517706131078,recall:0.5,f1:0.4533135865131582,pre:0.4149758853065539
SCN3 epoch 121 | train loss:0.4625176191329956,test loss:0.45559099316596985,acc:0.8301929175475686,recall:0.5,f1:0.4534271157001239,pre:0.4150964587737843
SCN3 epoch 122 | train loss:0.4619978070259094,test loss:0.4563901126384735,acc:0.829710623678647,recall:0.5,f1:0.4532880387998664,pre:0.4148553118393235
SCN3 epoch 123 | train loss:0.46180716156959534,test loss:0.4564845860004425,acc:0.8301929175475686,recall:0.5,f1:0.4534222948405542,pre:0.4150964587737843
SCN3 epoch 124 | train loss:0.46224501729011536,test loss:0.45642009377479553,acc:0.8299517706131078,recall:0.5,f1:0.4533161711136698,pre:0.4149758853065539
SCN3 epoch 125 | train loss:0.4617653489112854,test loss:0.45722201466560364,acc:0.829710623678647,recall:0.5,f1:0.4532881137706821,pre:0.4148553118393235
SCN3 epoch 126 | train loss:0.4640231132507324,test loss:0.4581260681152344,acc:0.829469476744186,recall:0.5,f1:0.45321993741937994,pre:0.414734738372093
SCN3 epoch 127 | train loss:0.4638175666332245,test loss:0.46006250381469727,acc:0.8292283298097252,recall:0.5,f1:0.45314889000547864,pre:0.4146141649048626
SCN3 epoch 128 | train loss:0.46392202377319336,test loss:0.4559515416622162,acc:0.8301929175475686,recall:0.5,f1:0.4534343717903509,pre:0.4150964587737843
SCN3 epoch 129 | train loss:0.4626685380935669,test loss:0.4560074806213379,acc:0.8301929175475686,recall:0.5,f1:0.4534365762002899,pre:0.4150964587737843
SCN3 epoch 130 | train loss:0.4635781943798065,test loss:0.45672252774238586,acc:0.829710623678647,recall:0.5,f1:0.45325969589508236,pre:0.4148553118393235
SCN3 epoch 131 | train loss:0.4641062617301941,test loss:0.45635923743247986,acc:0.829710623678647,recall:0.5,f1:0.4532823888207854,pre:0.4148553118393235
SCN3 epoch 132 | train loss:0.46223118901252747,test loss:0.4568478465080261,acc:0.829710623678647,recall:0.5,f1:0.4532727908762881,pre:0.4148553118393235
SCN3 epoch 133 | train loss:0.46263065934181213,test loss:0.4572734832763672,acc:0.8292283298097252,recall:0.5,f1:0.453145858154718,pre:0.4146141649048626
SCN3 epoch 134 | train loss:0.4630536437034607,test loss:0.4964003562927246,acc:0.8304340644820296,recall:0.5,f1:0.45347913884447577,pre:0.4152170322410148
SCN3 epoch 135 | train loss:0.46420255303382874,test loss:0.4607813060283661,acc:0.8304340644820296,recall:0.5,f1:0.45349314501502075,pre:0.4152170322410148
SCN3 epoch 136 | train loss:0.4638441205024719,test loss:0.47479283809661865,acc:0.8299517706131078,recall:0.5,f1:0.45332547285434543,pre:0.4149758853065539
SCN3 epoch 137 | train loss:0.46265706419944763,test loss:0.4559952914714813,acc:0.8299517706131078,recall:0.5,f1:0.45332872896647436,pre:0.4149758853065539
SCN3 epoch 138 | train loss:0.46210792660713196,test loss:0.45869627594947815,acc:0.829710623678647,recall:0.5,f1:0.45329214755027575,pre:0.4148553118393235
SCN3 epoch 139 | train loss:0.46269911527633667,test loss:0.4575847387313843,acc:0.8301929175475686,recall:0.5,f1:0.453471196728831,pre:0.4150964587737843
SCN3 epoch 140 | train loss:0.46381545066833496,test loss:0.46244385838508606,acc:0.829710623678647,recall:0.5,f1:0.4533132916289595,pre:0.4148553118393235
SCN3 epoch 141 | train loss:0.46336403489112854,test loss:0.45802977681159973,acc:0.8299517706131078,recall:0.5,f1:0.45338771910999837,pre:0.4149758853065539
SCN3 epoch 142 | train loss:0.4634091854095459,test loss:0.45558351278305054,acc:0.8311575052854123,recall:0.5,f1:0.4536956570387964,pre:0.41557875264270616
SCN3 epoch 143 | train loss:0.4611849784851074,test loss:0.45486557483673096,acc:0.8306752114164905,recall:0.5,f1:0.45354553864803104,pre:0.41533760570824524
SCN3 epoch 144 | train loss:0.4613575041294098,test loss:0.456255704164505,acc:0.8299517706131078,recall:0.5,f1:0.4533029011945009,pre:0.4149758853065539
SCN3 epoch 145 | train loss:0.4654518663883209,test loss:0.45656150579452515,acc:0.8301929175475686,recall:0.5,f1:0.4534725076741843,pre:0.4150964587737843
SCN3 epoch 146 | train loss:0.46317747235298157,test loss:0.45444852113723755,acc:0.8309163583509513,recall:0.5,f1:0.4536181747101664,pre:0.4154581791754757
SCN3 epoch 147 | train loss:0.46174895763397217,test loss:0.4551979899406433,acc:0.8304340644820296,recall:0.5,f1:0.45350184313244113,pre:0.4152170322410148
SCN3 epoch 148 | train loss:0.4644094705581665,test loss:0.45636123418807983,acc:0.8299517706131078,recall:0.5,f1:0.45335211615249316,pre:0.4149758853065539
SCN3 epoch 149 | train loss:0.4644266963005066,test loss:0.4567687511444092,acc:0.829710623678647,recall:0.5,f1:0.4532036185185708,pre:0.4148553118393235
SCN3 epoch 150 | train loss:0.4617825448513031,test loss:0.45712289214134216,acc:0.8292283298097252,recall:0.5,f1:0.45314389437209235,pre:0.4146141649048626
training has finished used time : 3410.847358226776
result has saved!
